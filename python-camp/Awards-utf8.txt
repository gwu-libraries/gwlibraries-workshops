Award Number: 2123346
Title: Collaborative Research: HDR DSC: Infusing community-centered data science into undergraduate engineering curricula
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 05, 2021
Latest Amendment Date: August 05, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $130,000
ARRA Amount: $
Investigator(s): Fernando Moreu fmoreu@unm.edu (Principal Investigator) 
Organization: University of New Mexico
1700 LOMAS BLVD NE STE 2200, ALBUQUERQUE, NM 87106-3837, (505)277-4186
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a curricular framework for data science education and workforce development that is transferable between diverse institutions, so STEM-related programs can plug and play data science lessons with existing curricula without much overhead. These lessons will be created in conjunction with community stakeholders and industry partners to ensure a focus on real-world problem solving and include student organizations in course development to promote flexible learning pathways. The proposed additions to undergraduate STEM education will provide an evidence-based blueprint for best practices in integrating data science with existing engineering curricula. Implementation across multiple engineering departments will result in a significant impact on society through the training of a diverse, globally competitive STEM workforce with high data literacy. <br/><br/>The objectives of this project are to (1) facilitate data science education and workforce development for engineering and related topics, (2) provide opportunities for students to participate in practical experiences where they can learn new skills in a variety of environments, and (3) expand the data science talent pool by enabling the participation of undergraduate students with diverse backgrounds, experiences, skills, and technical maturity in the Data Science Corps. This work will support the Data Science Corps objective of building capacity for education and workforce development to harness the data revolution at local, state, and national levels. The institutions gathered for this project will develop training programs and curate datasets that will be made available so they can be included in undergraduate instruction nationwide. Furthermore, the training materials will be shared with industry partners, facilitating workforce development. The project team will develop a website to house data science training programs, didactic datasets, and other resources for educators. These resources are intended to reduce barrier to entry for faculty seeking to incorporate data science into their instruction, as recruiting and retaining faculty to create and teach integrated introductory courses in data science has been recognized as a significant hurdle by the National Academies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2126582
Title: Collaborative Research: From Brains to Society: Neural Underpinnings of Collective Behaviors Via Massive Data and Experiments
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: July 02, 2021
Latest Amendment Date: July 02, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: August 01, 2021
End Date: October 31, 2022
Awarded Amount to Date: $83,776
ARRA Amount: $
Investigator(s): Jie Gao jg1555@cs.rutgers.edu (Principal Investigator) 
Organization: Rutgers University New Brunswick
3 RUTGERS PLZA, NEW BRUNSWICK, NJ 08901-8559, (848)932-0150
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: Despite thousands of investigations on the neural basis of individual behaviors and even more studies on collective behaviors, a clear bridge between the organization of individual brains and their combinational impact on group behaviors, such as cooperation and conflict and ultimately collective action, is lacking. To address the grand challenge of inferring group cooperation from the functional neuroarchitecture of individual brains, this project will harness advances in data, experiment and computation. Specifically, it will integrate, for the first time, existing large-scale human functional neuroimaging data, prospectively collected individual and group behavioral data from a large cohort, with cutting-edge machine learning tools, hierarchical models and large-scale simulations. This is a collaborative effort between a team of neuroscientists, social scientists and data scientists, that aims to elucidate the neural basis of cooperation, a fundamental process in a functioning society and at the core of social environments. <br/><br/>The project will first harness the combined wealth of existing neuroimaging and behavioral data from large-scale studies, including the Human Connectome-Lifespan (HCP-L) and the Adolescent Brain Cognitive Development (ABCD) and will leverage recent breakthroughs in machine learning to characterize the diversity, individuality and commonality of neural circuits (the connectome) supporting cognitive function across the lifespan. It will then conduct large-scale (~10,000 individuals) online behavioral experiments to identify connections between individual behaviors, decisions and group behaviors during a Public Goods Game. The experiments will measure individual proclivity towards cooperation and the social welfare obtained by cooperation, leading to potentially transformative insights into the emergence of cooperation within groups via individual behaviors. The resulting first-of-its-kind dataset may become a very valuable resource to the research community. Large-scale simulations based on statistical models estimated from this and the assembled neuroimaging datasets will then assess the direct or indirect relationships between individual connectomes and cooperation in group settings, and will elucidate the role of group processes in amplifying or ameliorating individual differences towards collective outcomes. Findings from this project may have a transformative impact on the scientific community's currently incomplete understanding of how individual brains shape societal behavior via cognitive, social, and interactive mechanisms.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940696
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $240,032
ARRA Amount: $
Investigator(s): Wei Ren wei.ren@uky.edu (Principal Investigator) 
Organization: University of Kentucky Research Foundation
500 S LIMESTONE 109 KINKEAD HALL, LEXINGTON, KY 40526-0001, (859)257-9420
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231 9150
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1922851
Title: HDR DSC: Collaborative Research: The Data Science WAV: Experiential Learning with Local Community Organizations
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 17, 2019
Latest Amendment Date: August 31, 2020
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $13,989
ARRA Amount: $
Investigator(s): Eben Afarikumah AfarikumahE@gcc.mass.edu (Principal Investigator) Deidre Murphy (Former Principal Investigator) Alysha Putnam (Former Principal Investigator) 
Organization: Greenfield Community College
ONE COLLEGE DR, GREENFIELD, MA 01301-9755, (413)775-1000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099y
Abstract: This project simultaneously addresses two problems: 1) the inability of community-based and non-profit organizations to tackle data science problems; and 2) the lack of real world experience gained by students studying data science. The increased availability of data, combined with increased computing power at lower costs, has brought to the desktop tremendous analytical and problem solving capabilities. Yet many organizations are not able to take advantage of these developments because they often lack appropriate staffing to wrestle with complex data science problems. Meanwhile, as students increasingly gravitate toward data science programs, much of their course-based problem solving experience focuses on clean problems with simple data sets. This leaves them unprepared for the reality of the data science applications they will face in professional settings. This project addresses both issues by deploying teams of data science students to assist local organizations, thereby increasing the long-term capacity of the data science workforce.<br/><br/>This is a multifaceted project that will provide immediate impact to local organizations and long-term benefit for students through valuable hands-on data science experience. There are two major components of the proposed project. First, Data Science WAV teams of four specially-trained undergraduate students will be deployed to community-based organizations to Wrangle, Analyze, and Visualize their data. Second, this project will offer summer faculty development workshops designed to help new instructors, especially those at community colleges, teach data science at their institutions. Curricular innovations that bring experiential data science learning into the curriculum will lead to sustained impact at the partnering academic institutions and in the larger Pioneer Valley region. This proposal is diverse across both institutions and student populations. It comprises one major research university (The University of Massachusetts, Amherst), four liberal arts colleges (Amherst, Hampshire, Mount Holyoke, and Smith), and three local community colleges (Greenfield, Holyoke, and Springfield Technical). The inclusion of two women's colleges (Smith and Mount Holyoke) and two Hispanic-serving institutions (Holyoke and Springfield Technical) will help ensure that a diverse student population is engaged in the project. <br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1633381
Title: BIGDATA: Collaborative Research: F: Discovering Context-Sensitive Impact in Complex Systems
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 25, 2016
Latest Amendment Date: August 17, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2016
End Date: August 31, 2023
Awarded Amount to Date: $869,944
ARRA Amount: $
Investigator(s): K. Selcuk Candan candan@asu.edu (Principal Investigator) Ming Zhao (Co-Principal Investigator) Maria Luisa Sapino (Co-Principal Investigator) 
Organization: Arizona State University
660 S MILL AVE STE 312, TEMPE, AZ 85281-3670, (480)965-5479
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 9251
Program Element Code(s): 8083
Abstract: Successfully tackling many urgent challenges in socio-economically critical domains (such as sustainability, public health, and biology) requires obtaining a deeper understanding of complex relationships and interactions among a diverse spectrum of entities in different contexts. In complex systems, (a) it is critical to discover how one object influences others within specific contexts, rather than seeking an overall measure of impact, and (b) the context-aware understanding of impact has the potential to transform the way people explore, search, and make decisions in complex systems. This project establishes the foundations of big data driven Context-Sensitive Impact Discovery (CSID) in complex systems and fills an important hole in big data driven decision making in many critical application domains, including epidemic preparedness, biological pathway analysis, climate, and resilient water/energy infrastructures. Thus, it enables applications and services with significant economic and health impact. The educational impacts of this project include the mentoring of graduate and undergraduate students, and the enhancement of graduate and undergraduate Computer Science curricula at both Arizona State University (ASU) and New Mexico State University (NMSU) through the incorporation of research challenges and outcomes into existing classes. <br/><br/>The technical goal of this project is to establish the theoretical, algorithmic, and computational foundations of big data driven context-sensitive impact discovery in complex systems. This project develops probabilistic and tensor-based models to capture context-sensitive impact from complex systems, often modeled as graphs, and designs efficient learning algorithms that can capture both the contexts and the impact scores among entities within these different contexts. The modeling of the context sensitive impact considers dynamic nature of relevant contexts and the diverse applications. This requires addressing several major challenges, including latent contexts of impact, heterogeneous networks of entities, dynamicity of impact in varying contexts, and high computational and I/O costs of context-sensitive impact discovery. Therefore, this project designs novel scalable probabilistic and tensor-based algorithms to capture and represent context-sensitive impact. These algorithms and the novel data platforms they are deployed in are efficient and scalable in terms of off-line and on-line running times and their space requirements. To achieve necessary scalabilities, the developed platforms employ novel multi-resolution data partitioning and resource allocation strategies and the research enables massive parallelism and efficient data access through new non-volatile memory based data management techniques.

Award Number: 2123259
Title: Collaborative Research: HDR DSC: Increasing Accessibility through Building Alternative Data Science Pathways
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 12, 2021
Latest Amendment Date: August 12, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $199,734
ARRA Amount: $
Investigator(s): Monica Stephens mstephens@spelman.edu (Principal Investigator) Tiffany Oliver (Co-Principal Investigator) Marta Dark (Co-Principal Investigator) Jerry Volcy (Co-Principal Investigator) 
Organization: Spelman College
350 SPELMAN LN SW 589, ATLANTA, GA 30314-4395, (404)270-5897
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: As computers become faster and less expensive, huge amounts of data are being produced every day. Data scientists are trained to analyze this information and apply the results to scientific research, engineering challenges, business decisions, and other efforts to improve society. The demand for data scientists increased by 28 percent between 2019 and 2020, and the U.S. Bureau of Labor Statistics estimates that 11.5 million data science jobs will be created by 2026. This project will help meet this need by making data science education available to more diverse populations of students in STEM (science, technology, engineering, mathematics). This project will also develop flexible curriculum materials that can be used to add specialized data science coursework to undergraduate programs at other institutions, beginning with Spelman College and seeking to grow this to the Atlanta University Center and beyond. <br/>  <br/>In a combined synergistic effort, Spelman College, the Atlanta University Center Data Science Initiative and Michigan State University (MSU) seek to address issues of accessibility through a joint partnership focused on creating pathways to foster data science education across STEM (science, technology, engineering, mathematics) disciplines.  First, the proposed partnership seeks to build a 3+2 BS+MS program (BS-Bachelors of Science, MS-Masters of Science). This 3+2 program will allow students to complete their BS in a STEM field (e.g., Mathematics, Physics, Biology) at Spelman and complete a MS in Data Science at MSU, while also providing a strong foundation and clear trajectory for students interested in obtaining a PhD. Second, this partnership seeks to develop a minor in Data Science at Spelman, targeting students across STEM fields. In creating this minor, we will leverage work already done at MSU to create a data science program and the expertise of faculty at Spelman to develop curricula that serves the needs of undergraduates from diverse majors and backgrounds.   The new educational material we seek to create is based on an innovative one month one credit curriculum that was initially designed to develop skills in bio-informatics for students at MSU.  Harnessing these ideas and mapping them onto the needs of Spelman STEM students, we seek to create an accessible pathway into data science that meets students where they are in their educational journey.  These educational efforts will create pathways for STEM majors who seek to bring to bear the power of modern data science methods in their STEM field of study, both at MSU and Spelman.  The curriculum will serve as a model for creating accessible data science educational initiatives nationwide.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934932
Title: HDR TRIPODS: UT Austin Institute on the Foundations of Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 13, 2019
Latest Amendment Date: September 19, 2021
Award Instrument: Continuing Grant
Program Manager: Zhengdao Wang
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,499,999
ARRA Amount: $
Investigator(s): Sujay Sanghavi sanghavi@mail.utexas.edu (Principal Investigator) Rachel Ward (Co-Principal Investigator) Adam Klivans (Co-Principal Investigator) Purnamrita Sarkar (Co-Principal Investigator) 
Organization: University of Texas at Austin
110 INNER CAMPUS DR, AUSTIN, TX 78712-1139, (512)471-6424
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: This project establishes a new institute on the Foundations of Data Science at the University of Texas at Austin.  The Institute will be a collaboration between eight PIs in the electrical engineering, computer science, mathematics and statistics departments at UT Austin, as well as postdocs and graduate students from the new programs this Institute establishes.  It will form a central hub for theoretical research into machine learning and data science by looking at foundational approaches to analysis and design.  This is necessary to devise novel complex and sophisticated machine-learning and artificial-intelligence theory and algorithms that can handle the accelerating scale of received data and the faster computational speeds of computers.  The algorithms and systems will interpret and predict behavior from data and the environment with the goal towards better design methods performed in a principled way.  The research will also open avenues for applications in fields such as autonomous vehicles and personalized medicine.  The research and education will be integrated to create new inter-departmental postdoctoral and graduate research programs, establish a unified degree and portfolio program in data science at UT Austin, run dedicated seminar series and hold workshops, and partner with industry as well as domain experts in the sciences. It will significantly expand, via funded initiatives, the PIs' ongoing efforts to expand participation of under-represented groups in this important field.<br/><br/>Research focuses on fundamental mathematical theory of machine learning and optimization, including neural networks, robustness, and graphs. The research is organized around three themes: (a) developing an algorithmic theory for deep learning, with new and provable methods for training, doing hyper parameter optimization and developing confidence measures, (b) making machine learning robust to both adversarial and incidental errors in data, and (c) devising new methods for statistical inference using graph algorithms, including fast estimation of graph statistics, and their use in biological and vision applications.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1938734
Title: Collaborative Research: SSMCDAT2020: Solid-State and Materials Chemistry Data Science Hackathon
NSF Org: DMR Division Of Materials Research
Initial Amendment Date: August 23, 2019
Latest Amendment Date: August 16, 2022
Award Instrument: Standard Grant
Program Manager: Birgit Schwenzer
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $62,639
ARRA Amount: $
Investigator(s): Taylor Sparks sparks@eng.utah.edu (Principal Investigator) 
Organization: University of Utah
201 PRESIDENTS CIR, SALT LAKE CITY, UT 84112-9049, (801)581-6903
NSF Directorate: MPS
Program(s): SOLID STATE & MATERIALS CHEMIS CONDENSED MATTER & MAT THEORY Big Data Science &Engineering 
Program Reference Code(s): 054Z 7556 8083 8084
Program Element Code(s): 1762, 1765, 8083
Abstract: This award, with support from the Division of Materials Research, the Division of Mathematical Sciences and the Office of Multidisciplinary Activities, sponsors the organization of a "data science hackathon" for researchers in the fields of solid-state materials chemistry and data science. This event, SSMCDAT2020, bring together members from these fields to further science through data-intensive research in order to make advances toward solving challenging problems relevant to solid-state materials chemistry. Teams work together for a three-day event, working both as teams and as a large cohort on a set of research projects. The hackathon lays a foundation for long-lasting collaborations between materials and data scientists.<br/><br/>The Materials Genome Initiative (MGI) was introduced in 2011 with the goal of developing and deploying new materials at twice the speed and a fraction of the cost. Key tenets of the initiative are the ideas that (a) materials "genes" exist and skilled manipulation of the materials "genome" will lead to rapid discovery and deployment of advanced materials, and (b) experimental materials research has been far too costly and slow to be the primary vehicle for exploration and discovery. For these reasons, the MGI proposes that investigations should be minimized by judicious use of computational materials science. The development of such computational techniques has transformed the field, but unlocking the materials genome still faces major challenges. To address these challenges, this solid-state materials chemistry-focused "hackathon" is designed to broaden the approach laid out in the MGI to encompass the rapidly evolving field of data science. Indeed, early adopters of this approach have amassed numerous impressive proofs of concept. With strong partnerships between solid-state materials chemistry and data science researchers, significant advances toward accomplishing the goals of the MGI can be achieved.<br/><br/>This "data science hackathon" is a fundamentally interdisciplinary endeavor. Solid-state materials chemistry researchers are trained in the application of data science tools, becoming informed of the advantages and limitations of various approaches.  Data scientists are exposed to the breadth of materials data available, as well as the most pressing solid-state materials research challenges. Special attention is paid to have participation from promising graduate students and postdocs, as well as under-represented groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934712
Title: Collaborative Research: Near Term Forecasts of Global Plant Distribution, Community Structure, and Ecosystem Function
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: August 17, 2022
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $943,275
ARRA Amount: $
Investigator(s): Cory Merow cory.merow@gmail.com (Principal Investigator) Emmanouil Anagnostou (Co-Principal Investigator) Efthymios Nikolopoulos (Co-Principal Investigator) 
Organization: University of Connecticut
438 WHITNEY RD EXTENSION UNIT 11, STORRS, CT 06269-1133, (860)486-3622
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: This project is the first to explore how plant species distributions across the entire globe may respond to global change. The project brings together ecologists, environmental engineers, data scientists, and conservation stakeholders to determine optimal ways to integrate these data sources to make near term forecasts for all plants globally by addressing changes in (1) species' abundance and geographic distribution, (2) community structure, and (3) ecosystem function. This three-pronged approach is designed to span a range of approaches to understand the spectrum of possible futures consistent with current knowledge while integrating knowledge across scales of biological organization. These forecasts will be used along with input from conservation stakeholders to assess how differing conservation decisions can minimize the impacts of global change responses. An ultimate goal of the project is to automate a pipeline to ingest new incoming data, update forecasts, and serve these to end-users to enable a near-real time forecasting workflow to provide best-available predictions at any given time to inform conservation decisions. <br/><br/>A key aspect of these forecasts is their reliance on novel environmental information that better characterize the conditions that influence plant performance, including soil moisture and extreme weather events based on NASA satellite observations. These species-level predictions will be linked to community demography models that integrate a variety of relatively untapped data sources for understanding global change, including plant trait data, community plot data across the globe, highly detailed plot data from National Ecological Observatory Network (NEON) and Long Term Ecological Research (LTER) sites, and global biomass data from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. By integrating this wide variety of data sources, the mechanistic understanding needed to make robust near term forecasts can be made, to understand ecosystem properties like Net Primary productivity, Carbon stock, and resilience. Based on workshops with conservation stakeholders, researchers will determine how best to use this unique suite of forecasts to best inform different conservation questions in different regions of the world. The project will also result in an open, cleaned and curated database on global plant distributions. This will aid others in exploring data and predictions by delivering and visualizing complex future scenarios in an easy to use portal. All results of the project can be found at the website for the Biodiversity Informatics and Forecasting Institute or BIFI, at https://enquistlab.github.io/BIFI .<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934568
Title: HDR TRIPODS: UC Davis TETRAPODS Institute of Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 11, 2019
Latest Amendment Date: July 18, 2022
Award Instrument: Continuing Grant
Program Manager: Zhengdao Wang
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Naoki Saito saito@math.ucdavis.edu (Principal Investigator) Thomas Chun Man Lee (Co-Principal Investigator) Chen-Nee Chuah (Co-Principal Investigator) Annamaria Amenta (Co-Principal Investigator) 
Organization: University of California-Davis
1850 RESEARCH PARK DR, STE 300, DAVIS, CA 95618-6153, (530)754-7700
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The project at UC Davis will establish the UC Davis TETRAPODS Institute of Data Science (UCD4IDS), which will be composed of thirty-five researchers (four PIs and thirty-one senior personnel) coming from four departments (Computer Science, Electrical & Computer Engineering, Mathematics, and Statistics) and will break interdepartmental barriers and promote interdisciplinary research collaborations among faculty members, postdocs, and graduate students. The project will encourage innovative and robust research, and provide education and mentoring of graduate students and postdocs in data science. Students and postdocs engaged in this project will be trained to be the next generation of interdisciplinary data scientists: they will gain deep knowledge of some focused areas, and at the same time, broaden their perspectives in other diverse fields. The UCD4IDS will bring in the insights gained by the experience of the faculty members in the four primary departments as well as application fields such as neuroscience, medical and health sciences, and veterinary medicine. The UCD4IDS will organize: a) round-table discussions and breakout sessions after weekly seminars related to data science; b) quarterly colloquia on data science; and c) annual three-day workshops. The project will also coordinate and develop diverse courses at UC Davis, with graduate students involved in the project taking at least one course in each of the four departments. The PI team will also leverage local programs to recruit, support, and retain graduate students, postdocs, and new faculty members from underrepresented groups by matching them to appropriate mentors. For the dissemination of the research and educational results, the PI team plans to: 1) make colloquia and workshop talk slides, lecture notes, and codes available online, which will reach out to our current and future collaborators and the general public; and 2) organize mini-symposia and workshops on foundations of data science at targeted conferences.<br/><br/>Research at the UCD4IDS will focus on three broad themes: 1) Fundamentals of machine learning directed toward biological and medical applications; 2) Optimization theory and algorithms for machine learning including numerical solvers for large-scale nontrivial learning problems; and 3) High-dimensional data analysis on graphs and networks. The algorithms and software tools to be developed will make a positive impact in solving practical data-analysis and machine-learning problems in diverse fields, e.g., computer science (analyzing friendship relations in social networks); electrical engineering (monitoring and controlling sensor networks); civil engineering (monitoring traffic flow on a road network); and in particular, biology and medicine (analyzing data measured on real neural networks, detecting changes in the brain structures due to diseases, imaging live biological cells for analyzing their growth, etc.). The technical goals of this project are: 1) geometric understanding of high-dimensional data, which may allow efficient (re)sampling from manifolds representing certain phenomena of interest and classifying subtle yet critical differences that often appear in biological and medical applications; 2) providing theoretical guarantees and efficient numerical algorithms for non-convex optimization, which is crucial to machine learning; and 3) deepening understanding of how local interactions between individual entities (e.g., neurons) lead to global coordination and decision making. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1835643
Title: RUI: Framework: Data - An Open Semantic Data Framework for Data-Driven Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 07, 2018
Latest Amendment Date: August 17, 2022
Award Instrument: Standard Grant
Program Manager: Juan Li
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $605,849
ARRA Amount: $
Investigator(s): Stuart Chalk schalk@unf.edu (Principal Investigator) 
Organization: University of North Florida
1 UNF DR, JACKSONVILLE, FL 32224-7699, (904)620-2455
NSF Directorate: CSE
Program(s): Data Cyberinfrastructure Big Data Science &Engineering 
Program Reference Code(s): 026Z 062Z 077Z 7925 9229
Program Element Code(s): 7726, 8083
Abstract: The project makes contributions to the ease of annotating, sharing, and searching heterogeneous data sets.  It focuses upon undergraduate training, emphasizing data science capabilities applied to a range of science problems.  <br/><br/>The project enables aggregation, search, and inference with heterogeneous datasets using a structured framework allowing data and metadata to be linked by encoding the framework as a JavaScript Object Notation (JSON) for Linked Data (JSON-LD) document.  The approach builds on existing developments such as the Scientific Data (SciData) framework and associated ontology that has been developed by the PI, and Shape Constraint Language (SHACL) shapes to provide efficient searching, browsing, and visualization of data.  The result extends existing approaches to link data and metadata and make data easily discoverable.  The activity emphasizes Research in Undergraduate Institutions (RUI), training more than 30 undergraduates, graduate students and a post-doctoral student in the application of data science techniques to an array of science problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123247
Title: HDR DSC: Data Science for Energy Transition
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 09, 2021
Latest Amendment Date: August 09, 2021
Award Instrument: Continuing Grant
Program Manager: Raleigh Martin
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $607,010
ARRA Amount: $
Investigator(s): Mikyoung Jun mjun@central.uh.edu (Principal Investigator) Yun Wan (Co-Principal Investigator) Dvijesh Shastri (Co-Principal Investigator) Jiajia Sun (Co-Principal Investigator) Pablo Pinto (Co-Principal Investigator) 
Organization: University of Houston
4800 W CALHOUN ST STE 316, HOUSTON, TX 77004-, (713)743-5773
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: With the growing public awareness of climate change, Houston, the energy capital of the world, is undertaking efforts to lead the energy transition for a more sustainable and cleaner environment. There is urgent demand for a data science workforce equipped with broad understanding for optimizing conventional energy and leading the energy transition. This project focuses on training undergraduates and Masters-level students from diverse backgrounds to achieve a wide range of knowledge and skill sets essential for the future energy industry workforce. Five major public universities in greater Houston are teamed up with multiple energy industry partners, ranging from large oil and gas companies to startups on energy sector data analytics. Given the emphasis of participating universities on diversity and equity and the diverse student populations they serve, this project broadens training opportunities for groups historically underrepresented in science, technology, engineering, and mathematics (STEM).<br/><br/>Statisticians, computer scientists, geophysicists, and social scientists at the University of Houston (UH) main campus, UH-Downtown, UH-Victoria, UH-Clear Lake, and Sam Houston State University are collaborating to develop year-long educational activities under the theme of energy transition, from traditional oil- and gas-related problems to renewable energy. The curriculum contains an array of important topics including fundamental science and engineering understanding, essence of statistics and machine learning methods, and practical skill sets of programming and data visualization. Social science aspects on the energy transition and its implications for society are also included in the curriculum. The program consists of: (1) five-week summer boot camps with educational modules on statistics/machine learning, CS/programming, geophysics and earth sciences, public policy, and engineering; (2) advanced courses and micro-credential training offered by participating universities in the following fall semester; (3) semester-long team research projects on problems provided by industry partners in the spring semester; and (4) summer internships and/or conference presentation opportunities to conclude the program. Each year, about 40 students participate in the program, totaling about 120 student participants over 3 cohorts. A framework in which research projects can be carried out is developed. The project also promotes interaction and collaboration between academia and industry in the region, opening up more opportunities for education and research collaboration. All project data is well documented and made freely available. The student and program-level outcomes are formally assessed, with results disseminated through publication in peer-reviewed journals and conference presentations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2034479
Title: BigData:IA:Collaborative Research: TIMES: A tensor factorization platform for spatio-temporal data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: June 30, 2020
Latest Amendment Date: June 30, 2020
Award Instrument: Standard Grant
Program Manager: Wei-Shinn Ku
Start Date: January 16, 2020
End Date: September 30, 2023
Awarded Amount to Date: $755,110
ARRA Amount: $
Investigator(s): Jimeng Sun jimeng@illinois.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Spatio-temporal analyses can enable many discoveries including reducing traffic congestion, identifying hotspot areas to deploy mobile clinics, and urban planning. Unfortunately, the data poses many computational challenges.  Standard assumptions in machine learning and data mining algorithms are violated by the complex nature of spatio-temporal data.  These include spatial and temporal correlation of observations, dynamic and abrupt changes in observations, variability in measurements with respect to length and frequency, and multi-sourced data that spans multiple sources of information. In recognition of these challenges, various efforts have been undertaken to develop specialized spatiotemporal models. Yet, to date, these algorithms are predominately designed to analyze small- to medium-sized datasets. The goal of this project is to develop a comprehensive computational tensor platform to perform automated, data-driven discovery from spatio-temporal data across a broad range of applications. The project also includes a set of integrated educational activities such as a Massive Open Online Course that covers cross-disciplinary topics at the confluence of computer science and geospatial applications, annual spatio-temporal data challenges and hackathons, and an annual event at the Atlanta Science Festival to create public awareness and encourage participation by women and minorities.<br/><br/>The project will contain algorithmic innovations that reflect appropriate assumptions of spatio-temporal data without sacrificing real-time performance, computational scalability, and cross-site learning even under privacy constraints. The proposed platform will generalize tensor modeling to encompass the complex nature of spatio-temporal data including time irregularity, spatiotemporal correlations, and evolving distributions. It will enable the integration of multi-sourced data from heterogeneous sources to yield robust and cohesive learned patterns. The novel algorithms will also facilitate learning in decentralized settings while preserving privacy. The computational platform will contain interchangeable modules that can adapt to new spatio-temporal settings and incorporate additional contextual information.  The accompanying suite of algorithms will enable predictive learning, pattern mining, and change detection from large-sized spatio-temporal data.  The broad applicability of the project will be demonstrated on a diverse range of data including urban transportation services, real estate market transactions, and population health. The algorithmic innovations introduced can be used to scale other machine learning models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2022042
Title: Collaborative Research: Biology-guided neural networks for discovering phenotypic traits
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: March 25, 2020
Latest Amendment Date: October 13, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: January 15, 2020
End Date: September 30, 2023
Awarded Amount to Date: $424,386
ARRA Amount: $
Investigator(s): Paula Mabee mabee@battelleecology.org (Principal Investigator) 
Organization: Battelle Memorial Institute
505 KING AVE, Columbus, OH 43201-2696, (614)424-4873
NSF Directorate: CSE
Program(s): ICB: Infrastructure Capacity f HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 1165 7231 9150
Program Element Code(s): 085Y, 099Y, 7231
Abstract: Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. <br/><br/>This project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934904
Title: HDR Tripods: Texas A&M Research Institute for Foundations of Interdisciplinary Data Science (FIDS)
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 17, 2019
Latest Amendment Date: June 06, 2022
Award Instrument: Continuing Grant
Program Manager: Huixia Wang
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,416,522
ARRA Amount: $
Investigator(s): Bani Mallick bmallick@stat.tamu.edu (Principal Investigator) Ronald DeVore (Co-Principal Investigator) Panganamala Kumar (Co-Principal Investigator) Nicholas Duffield (Co-Principal Investigator) Dilma Da Silva (Former Co-Principal Investigator) 
Organization: Texas A&M University
400 HARVEY MITCHELL PKY S STE 30, COLLEGE STATION, TX 77845-4375, (979)862-6777
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: Data Science is rapidly evolving as an essential interdisciplinary field, where advances often result from a combination of ideas from several disciplines.  New types of data have emerged and present tremendous complexities and challenges that require a novel way of interdisciplinary thinking.  The Texas A&M Research Institute for Foundations of Interdisciplinary Data Science (FIDS) will bring together researchers from five disciplinary areas, Statistics, Electrical Engineering,  Mathematics, Computer Science and Industrial Engineering, to conduct research on the foundations of data science motivated by problems arising in bioinformatics, the energy arena, power systems, and transportation systems. The Institute for Foundations of Interdisciplinary Data Science will be well-positioned to develop rigorous theories, novel methodologies, and efficient computational techniques to solve data challenges in many application domains.<br/><br/>Modern large datasets are extremely complex and finding answers to seemingly simple questions often turns into an intractable problem. To address these challenges, FIDS will advance the foundations of data science through research on modeling complex data and developing related theory and algorithms. Development of efficient methods to identify low-dimensional structures in these high-dimensional complex data will be the key strategy to recovering high-dimensional signals with related uncertainties. Novel data-analysis models and algorithms will be developed for representation learning, information extraction, and knowledge discovery from complex data to enable better decision making.  To complement the research effort, FIDS will educate and train students and postdoctoral fellows in areas at the interface of engineering, mathematics, and statistics.  Targeted outreach programs will be developed to increase the pool of women and underrepresented minorities who pursue data-science careers.  An external engagement program will be designed to facilitate collaborations with domain scientists and external data scientists.   These programs will help to develop the intellectual foundation for a new generation of scientists poised to make novel breakthroughs in this exciting new field.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838024
Title: BIGDATA: IA: Collaborative Research: Protecting Yourself from Wildfire Smoke: Big Data Driven Adaptive Air Quality Prediction Methodologies
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: July 26, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2023
Awarded Amount to Date: $684,689
ARRA Amount: $
Investigator(s): Lei Yang leiy@unr.edu (Principal Investigator) Feng Yan (Former Principal Investigator) Heather Holmes (Co-Principal Investigator) Lei Yang (Former Co-Principal Investigator) 
Organization: Board of Regents, NSHE, obo University of Nevada, Reno
1664 N VIRGINIA ST, RENO, NV 89557-0001, (775)784-4040
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9150
Program Element Code(s): 8083
Abstract: The objective of this project is to develop a framework to achieve real-time smoke transport prediction and air quality forecasting.  Wildfire smoke can transport very fast and pose significant health hazards to communities.  State-of-the-art smoke forecasting models typically have infrequent updates and provide predictions with a coarse spatial resolution due to spatiotemporal resolution limitations of input data and the tremendous computational power required to simulate atmospheric conditions.  This project will develop real-time smoke transport and air quality prediction methodologies with better spatial resolution for improving the scalability and efficiency of the underlying data processing system to enable timely air quality alerts.  While this project is applied towards smoke transport and air quality prediction, this work can be generalized to solve many other big data problems that require such design. The principal investigators will use the materials and topics from this project to enhance education by creating new big data analytics related courses and developing a Big Data Minor program at the University of Nevada, Reno.  The project will also provide opportunities to engage more students from underrepresented groups and impact the education of several students, via K-12 outreach and mentoring undergraduate and graduate students.<br/><br/>The intellectual merit of this research is in establishing a novel big data driven air quality prediction for wildfire smoke to provide timely and effective health alerts. The planned new prediction methodology will integrate the novel Gaussian Markov Random Field based real-time spatiotemporal prediction with statistical-based long-term spatiotemporal prediction. To tackle the challenge of missing high-resolution data, a data fusion methodology is planned to integrate fine-grained image data collected from camera networks with air pollution monitoring data to increase data resolution. A Deep Neural Network based smoke density detection process will extract air quality information from camera image data. The planned novel signature time-series based prediction methodology will open opportunities to process larger amounts of spatiotemporal data using limited resources. By identifying critical data based on spatiotemporal properties, the project will develop a communication framework that enables efficient camera data transfer. Efficient parallel and distributed data processing is utterly important to support processing large scale data in real time. The planned decomposition-based parallelization methodology and a performance model driven scheduling framework will enable efficient dynamic computing resource management, which is key to the success of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940209
Title: Collaborative Research: Science-Aware Computational Methods for Accelerating Data-Intensive Discovery: Astroparticle Physics as a Test Case
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Vyacheslav (Slava) Lukin
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $345,962
ARRA Amount: $
Investigator(s): Christopher Tunnell tunnell+nsf@rice.edu (Principal Investigator) 
Organization: William Marsh Rice University
6100 MAIN ST, Houston, TX 77005-1827, (713)348-4820
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The rapid technological advances of the last two decades have ushered in an era of data-rich science for several disciplines.  One such discipline is astroparticle physics, where researchers aim to discover what our Universe is made of by trying to directly detect Dark Matter. This discovery can be hastened if data science tools are used to extract significant domain-specific information from data, and to reliably test scientific hypotheses at scale. The overarching goal of this two-year project is to lay the groundwork for incorporating scientific knowledge into machine learning and data science methods in the context of scientific disciplines in which discovery requires effective, efficient analysis of lots of noisy data gathered by multiple imperfect sensors. In doing so, it not only advances the state-of-the-art in data science, machine learning, and astrophysics, but it also has the potential to accelerate data-driven discoveries in other scientific disciplines where data shares similar characteristics.<br/><br/>This project will develop innovative domain-enhanced data science methods that will be based on probabilistic graphical models and graph-regularized inverse problems. Using the leading astroparticle experiment XENON as a test bed, the investigators will explore and demonstrate approaches for incorporating domain knowledge into machine learning and data science methods. In doing so, the investigators will address major data-analysis challenges in the context of dark matter identification. Additionally, the investigators will invest significant effort reaching out to other data-intensive science communities, such as materials science, oceanography, and meteorology, that can benefit from the new methods and ideas. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940080
Title: Collaborative Research: Science-Aware Computational Methods for Accelerating Data-Intensive Discovery: Astroparticle Physics as a Test Case
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: March 10, 2022
Award Instrument: Continuing Grant
Program Manager: Vyacheslav (Slava) Lukin
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $333,338
ARRA Amount: $
Investigator(s): Rudolf Eigenmann eigenman@udel.edu (Principal Investigator) Hagit Shatkay (Former Principal Investigator) 
Organization: University of Delaware
220 HULLIHEN HALL, NEWARK, DE 19716-0099, (302)831-2136
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9150
Program Element Code(s): 099Y
Abstract: The rapid technological advances of the last two decades have ushered in an era of data-rich science for several disciplines.  One such discipline is astroparticle physics, where researchers aim to discover what our Universe is made of by trying to directly detect Dark Matter. This discovery can be hastened if data science tools are used to extract significant domain-specific information from data, and to reliably test scientific hypotheses at scale. The overarching goal of this two-year project is to lay the groundwork for incorporating scientific knowledge into machine learning and data science methods in the context of scientific disciplines in which discovery requires effective, efficient analysis of lots of noisy data gathered by multiple imperfect sensors. In doing so, it not only advances the state-of-the-art in data science, machine learning, and astrophysics, but it also has the potential to accelerate data-driven discoveries in other scientific disciplines where data shares similar characteristics.<br/><br/>This project will develop innovative domain-enhanced data science methods that will be based on probabilistic graphical models and graph-regularized inverse problems. Using the leading astroparticle experiment XENON as a test bed, the investigators will explore and demonstrate approaches for incorporating domain knowledge into machine learning and data science methods. In doing so, the investigators will address major data-analysis challenges in the context of dark matter identification. Additionally, the investigators will invest significant effort reaching out to other data-intensive science communities, such as materials science, oceanography, and meteorology, that can benefit from the new methods and ideas. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934553
Title: HDR TRIPODS: Building the Foundation for a Data-Intensive Studies Center-
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 12, 2019
Latest Amendment Date: August 24, 2021
Award Instrument: Continuing Grant
Program Manager: Tracy Kimbrel
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,520,000
ARRA Amount: $
Investigator(s): Lenore Cowen cowen@eecs.tufts.edu (Principal Investigator) Eric Miller (Co-Principal Investigator) Misha Kilmer (Co-Principal Investigator) Bert Huang (Co-Principal Investigator) Kathleen Fisher (Former Co-Principal Investigator) 
Organization: Tufts University
169 HOLLAND ST FL 3, SOMERVILLE, MA 02144-2401, (617)627-3696
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu Special Projects - CCF 
Program Reference Code(s): 047Z 062Z 7926 9251
Program Element Code(s): 041Y, 099Y, 2878
Abstract: Tufts University is launching the T-TRIPODS institute, that will focus an interdisciplinary effort across multiple departments and campuses to advance the understanding of foundations of data science. The project seeks to support the first three years of the operation of the institute, and will support a culture of interdisciplinary research and learning in data sciences across multiple departments, fostering collaboration between mathematicians, computer scientists, and electrical engineers, as well as with scientists and scholars in a wide range of application domains. The model is built around overlapping three-year focused research topics, with an offset timeline, so that each year, the oldest research topic sunsets while a new research topic is added. For each focused research topic, the project will convene interdisciplinary teams of mathematicians, computer scientists, statisticians and electrical engineers to  address timely questions and solve important problems on the frontiers of data science. Complementing and completing the research effort are teaching and curriculum development efforts for data science at the undergraduate, graduate and professional levels. Furthermore, the structure of T-TRIPODS will foster specific and deep connections with application domain experts in several areas, leading to translational research. T-TRIPODS is strongly committed to Data Science for All, and will  partner closely with the Tufts Center for STEM Diversity to broaden participation in undergraduate research opportunities in data science at Tufts.<br/><br/>T-TRIPODS will address three research thrusts. Research Focus I (Graphs and Tensor Representations of Data) in the first year, which will be joined by Focus II (Collecting, Modeling, and Learning from Data with a Spatial or Temporal Dimension) in the second year, and Focus III (Data Guarantees: Analysis of Data with Assurances of Quality, Transparency, Fairness, Privacy, and Trust) in year three, which will bring the institute up to full capacity with three research foci running simultaneously. All research foci will include cross-disciplinary training of graduate students; workshops that bring together experts and early career scientists from math, computer science, and electrical engineering; training modules in application-specific concerns around ethical safeguards for data usage and analysis; and an Ideas Lab  activity to connect researchers from the core research topics to domain experts in four identified broad application areas: 1) Biological and Biomedical data, 2) Education and Cognitive Science, 3) Smart Cities, Development, and Design and 4) Computational Arts and Humanities (including Language and Music). T-TRIPODS will be integrated within Tufts' new Data Intensive Science Center (DISC) and will synergize with and enhance existing Tufts University degree programs in Data Science.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1918692
Title: Robust Diagnosis in Electronic Health Records Integrating Physics-based Missing Data Multiple Imputation, Fast Inference for Hemodynamic Models, and Differential Privacy.
NSF Org: DMS Division Of Mathematical Sciences
Initial Amendment Date: May 24, 2019
Latest Amendment Date: May 24, 2019
Award Instrument: Standard Grant
Program Manager: Christopher Stark
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $880,203
ARRA Amount: $
Investigator(s): Daniele Schiavazzi dschiavazzi@nd.edu (Principal Investigator) Alison Marsden (Co-Principal Investigator) Jonathan Hauenstein (Co-Principal Investigator) Fang Liu (Co-Principal Investigator) andrew kahn (Co-Principal Investigator) 
Organization: University of Notre Dame
940 Grace Hall, NOTRE DAME, IN 46556-5708, (574)631-7432
NSF Directorate: MPS
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z
Program Element Code(s): 8083
Abstract: This project will introduce new paradigms for dealing with missing values in electronic health record (EHR) data, with the objective of developing novel approaches for early diagnosis of diastolic ventricular dysfunction, a silent disease responsible for one-third of the total heart failure-related deaths worldwide. EHR are often messy and suffer from missing data problem for various reasons, for example more frequent clinical exams after the manifestation of the first symptoms of a certain disease and less frequent exams during routine screening. Missing data often limits the ability to extract useful information from these sources (e.g., early diagnosis). The goal of this project is to leverage the fact that missing information sometimes satisfies mathematical or physical principles to develop innovative model-based imputation approaches, combining models and efficient privacy-preserving learning techniques in large EHR datasets. Computationally efficient algorithms will be developed to train numerical models while preserving patient privacy, and the feasibility and practical usefulness of these approaches will be demonstrated at a scale that has not yet been addressed in the literature. The approaches for predictive numerical models developed for this project can be applied broadly in various fields. Additional project goals include development of infrastructure for research and education through freely available, open-source software libraries. This project will also provide invaluable multi-disciplinary skills to undergraduate and graduate students. Both research and outreach efforts focus on increasing the participation of women, people with disabilities, and of underrepresented groups.<br/><br/>The team will develop novel regularization approaches through numerical models, i.e., optimally trained models able to suggest distributions of missing data based on the underlying physics. For EHRs characterizing cardiovascular function, lumped parameter hemodynamic models offer an ideal regularizer. Parameter estimation for these models using Markov chain Monte Carlo is computationally expensive and therefore incompatible with fast application to large EHR collections. Additionally, optimally trained numerical models of the cardiovascular system can be thought as a type of query, rising issues of patient privacy. The proposed research tackles these issues through: (1) Acquisition and analysis of a large heart failure EHR dataset. (2) Development of privacy-preserving variational inference for hemodynamic models, enhanced using homotopy-based optimization. (3) Implementation and extensive testing of novel imputation approaches for missing data, combining uncertainty quantification and numerical models. (4) Demonstration on a large patient cohort.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838251
Title: BIGDATA: F: Collaborative Research: Mining for Patterns in Graphs and High-Dimensional Data: Achieving the Limits
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: September 10, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $737,645
ARRA Amount: $
Investigator(s): Cristopher Moore moore@santafe.edu (Principal Investigator) 
Organization: Santa Fe Institute
1399 HYDE PARK RD, SANTA FE, NM 87501-8943, (505)946-2727
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: While modern datasets are very large, the amount of information per variable is often relatively small. This includes datasets from genomics, social networks, and many applications in machine learning and artificial intelligence. For instance, in genomics we often track hundreds of thousands of genes, but only have a few hundred independent samples for each one. Similarly, online social networks are massive, but the structure of friendships only gives us a relatively small amount of data per individual. This kind of data is called "high-dimensional", and poses new challenges for mathematics, statistics, and computer science, especially when (as with all real data) they are noisy or incomplete. This project will identify exactly when and how it is mathematically possible to find patterns in these massive but noisy datasets, giving scientists across many fields a useful guide to how much data they need to draw reliable conclusions, and to develop new algorithms that will solve modern data science problems efficiently and optimally.<br/><br/>Through the study of community detection, noisy graph isomorphism, and matrix/tensor factorization, this project will develop a general framework to 1) locate the information-theoretic limit below which the observation is too noisy to detect the underlying pattern, or even to tell if a pattern exists; 2) devise efficient algorithms that succeed all the way down to the lowest possible signal-to-noise ratio; 3) prove that important classes of algorithms need super-polynomial time in certain hard regimes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934529
Title: Collaborative Research: Physics-Based Machine Learning for Sub-Seasonal Climate Forecasting
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $414,800
ARRA Amount: $
Investigator(s): Timothy Delsole tdelsole@gmu.edu (Principal Investigator) Benjamin Cash (Co-Principal Investigator) 
Organization: George Mason University
4400 UNIVERSITY DR, FAIRFAX, VA 22030-4422, (703)993-2295
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: While the past few decades have seen major advances in weather forecasting on time scales of days to about a week, making high quality forecasts of key climate variables such as temperature and precipitation on sub-seasonal time scales, the time range between 2 weeks and 2 months, continues to challenge operational forecasters. Skillful climate forecasts on sub-seasonal time scales would have immense societal value in areas such as agricultural productivity, hydrology and water resource management, transportation and aviation systems, and emergency planning for extreme events such as Atlantic hurricanes and midwestern tornadoes. In spite of the scientific, societal, and financial importance of sub-seasonal climate forecasting, progress on the problem has been limited. The project has initiated a systematic investigation of physics-based machine learning with specific focus on advancing sub-seasonal climate forecasting. In particular, this project is developing novel machine learning (ML) approaches for sub-seasonal forecasting by leveraging both limited observational data as well as vast amounts of dynamical climate model output data. Further, the project is focusing on improving the dynamical climate models themselves based on ML with specific emphasis on learning model parameterizations suitable for accurate sub-seasonal forecasting. The principles, models, and methodology for physics-based machine learning being developed in the project will benefit other scientific domains which rely on dynamical models. The project is establishing a public repository of a benchmark dataset for sub-seasonal forecasting to engage the wider data science community and accelerate progress in this critical area. The project is training a new generation of interdisciplinary scientists who can cross the traditional boundaries between computer science, statistics, and climate science.<br/><br/>The project works with two key sources of data for sub-seasonal forecasting: limited amounts of observational data and vast amounts of output data from dynamical model simulations, which capture physical laws and dynamics based on large coupled systems of partial differential equations (PDEs). The project is investigating the following central question: what is the best way to learn simultaneously from limited observational data and imperfect dynamical models for improving sub-seasonal forecasts? The project is building a framework for physics-based machine that has two inter-linked components: (1) deduction, in which ML models are trained on dynamical model outputs as well as limited observations, and (2) induction, in which ML models are used to improve dynamical models. Across the two components, the project is making fundamental advances in learning representations, functional gradient descent, transfer learning, derivative-free optimization and multi-armed bandits, Monte Carlo tree search, and block coordinate descent. On the climate side, the project is building an idealized dynamical climate model and doing an in depth investigation on learning suitable parameterizations for the dynamical model with ML methods to improve forecast accuracy in the sub-seasonal time scales. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934876
Title: HDR TRIPODS: Penn Institute for Foundations of Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 13, 2019
Latest Amendment Date: September 13, 2021
Award Instrument: Continuing Grant
Program Manager: Tracy Kimbrel
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,310,524
ARRA Amount: $
Investigator(s): Shivani Agarwal ashivani@seas.upenn.edu (Principal Investigator) Weijie Su (Co-Principal Investigator) AARON ROTH (Co-Principal Investigator) Sanjeev Khanna (Co-Principal Investigator) Hamed Hassani (Co-Principal Investigator) 
Organization: University of Pennsylvania
3451 WALNUT ST STE 440A, PHILADELPHIA, PA 19104-6205, (215)898-7293
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The growing field of data science promises to bring many benefits to society: personalized knowledge and services; improved healthcare; improved decision-making at individual, organizational, national, and international levels; a safer and possibly fairer society; and many others. The ability to realize these promises, however, depends critically on building the right foundational principles for the field. This project establishes an NSF TRIPODS Institute, termed the Penn Institute for Foundations of Data Science (PIFODS), at the University of Pennsylvania, with the goal of bringing together scientists and ideas from multiple disciplines, including computer science, electrical engineering, statistics, and mathematics, in order to collectively develop long-lasting principles for data science that can serve the field for decades to come. The main activities of the Institute will include transdisciplinary research, education and training, engagement with the broader research community through invited seminars and workshops, and engagement with applied scientists and practitioners. <br/><br/>The PIFODS team seeks to develop principles for the following five thrusts: principles for complex learning tasks; principles for efficient optimization (convex, non-convex, and submodular); principles for streaming, distributed, and massively parallel data analysis; principles for privacy-preserving and fairness-preserving data analysis; and principles for reproducible data analysis. Each of these thrusts addresses an important foundational need in data science. These needs range from designing learning algorithms with stronger performance guarantees, and developing principles for optimization in adaptive settings, to developing a fundamental understanding of the tradeoffs between various modern computational resources in data science, as well as developing data science algorithms that guarantee meaningful notions of privacy, fairness, and reproducibility. Each thrust requires interactions among several of the TRIPODS disciplines; several of these thrusts also naturally interact with each other. On the education and training side, the PIFODS team has already initiated several new transdisciplinary courses related to data science that are aimed at developing a common language across disciplines; under the aegis of the Institute, the team will continue to further develop and refine these courses, and will incorporate feedback from these courses to inform the university's emerging transdisciplinary data science curriculum. On the applications side, the PIFODS team will actively engage with applied scientists and practitioners of data science, including both members of the broader university community and selected industry practitioners; these engagements will both help to inform possible additional research thrusts in the future, and help to solve important data-driven problems in society. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1923982
Title: HDR DSC: Collaborative Research: Creating and Integrating Data Science Corps to Improve the Quality of Life in Urban Areas
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $858,229
ARRA Amount: $
Investigator(s): Aryya Gangopadhyay gangopad@umbc.edu (Principal Investigator) Tim Oates (Co-Principal Investigator) Nirmalya Roy (Co-Principal Investigator) Sanjay Purushotham (Co-Principal Investigator) Anupam Joshi (Co-Principal Investigator) 
Organization: University of Maryland Baltimore County
1000 HILLTOP CIR, BALTIMORE, MD 21250-0001, (410)455-3140
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Special Projects - CNS Special Projects - CCF IIS Special Projects 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1714, 2878, 7484
Abstract: The goal of this project is to develop a team-based data science corps program for undergraduate students from Computer Science, Information Systems, and Business integrating both academic training as well as hands-on experience through real-world data science projects. This project is a collaborative effort with the University of Maryland Baltimore County as the coordinating as well as an implementing organization, and the University of Baltimore, Towson University, and Bowie State University as implementing organizations.  This project focuses on the city of Baltimore as an exemplar for other cities in the US and across the globe.   The project team will collaborate with a number of communities in the city of Baltimore to integrate real-world data science projects into classroom instruction in data science. The specific objectives of this project are as follows: (i) Develop the technical, analytical, modeling, and critical thinking skills that are key to success as a data science professional; (ii) Connect a cohort of students to communities, organizations, and projects that can benefit from the power of data science; (iii) Nurture and support innovative thinking in solving some of the key challenges facing the real world; (iv) Promote a better understanding of the power and pitfalls of data-driven discoveries to improve the quality of life in urban communities; (v) Increase the data science workforce capacity to support this critical area that is of growing importance in society; and finally, (vi) Evaluate the effect of the proposed data science corps on student learning. <br/><br/>This project will create a core set of knowledge that will be valuable in developing solutions for real-world urban settings with the understanding that not all projects will require the application or use of every topic covered in the data science corps program. The core set of knowledge includes data collection and cleaning, data analysis using machine learning and deep learning techniques, data visualization including geospatial data and virtual reality, data privacy and security, and infrastructure for smart cities including IoT-based sensor networks.   The proposed data science corps program will have two main phases: instructional phase (10 modules in total) and real-world team projects (5 modules in total). The project teams consist of students who have taken a course in at least one of the following areas: data collection and analysis, big data, machine learning including deep learning, smart cities, cybersecurity, geospatial data analysis and visualization, and virtual reality. Examples of team projects include: (i) developing community-based indicators that are compiled from open data portals and parametric and non-parametric statistical techniques to understand the relationship between urban sustainability and a range of factors including cleanliness and environment, crime and safety, business and economics, social and political, housing, health, and education; (ii) combining deep learning models such as convolutional neural networks (CNN) and long term short term memory recurrent neural networks (LSTM-RNN) to develop prediction models for derelict buildings that are likely to become vacant; (iii) combining sensor data and social media for automated information extraction, validation, and quality checks that can be beneficial to both citizens and emergency managers in crisis situations such as flash floods; (iv) developing smart streetlights that are networked LED systems that can be adjusted based on time of day and motion and can report outages back to central operations; and (v) developing augmented reality-based systems that leverage systems such as Microsoft HoloLens and mobile devices for building evacuation.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940233
Title: Biology-guided Neural Networks for Discovering Phenotypic Traits
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $245,818
ARRA Amount: $
Investigator(s): Jane Greenberg janeg@drexel.edu (Principal Investigator) 
Organization: Drexel University
3141 CHESTNUT ST, PHILADELPHIA, PA 19104-2816, (215)895-6342
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099y, 7231
Abstract: Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. <br/><br/>This project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123285
Title: Collaborative Research: HDR DSC: Infusion of Data Science and Computation into Engineering Curricula
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 05, 2021
Latest Amendment Date: April 19, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $15,000
ARRA Amount: $
Investigator(s): Lin Li lli1@tnstate.edu (Principal Investigator) Wentao Wu (Former Principal Investigator) 
Organization: Tennessee State University
3500 JOHN A MERRITT BLVD, NASHVILLE, TN 37209-1500, (615)963-7631
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a curricular framework for data science education and workforce development that is transferable between diverse institutions, so STEM-related programs can plug and play data science lessons with existing curricula without much overhead. These lessons will be created in conjunction with community stakeholders and industry partners to ensure a focus on real-world problem solving and include student organizations in course development to promote flexible learning pathways. The proposed additions to undergraduate STEM education will provide an evidence-based blueprint for best practices in integrating data science with existing engineering curricula. Implementation across multiple engineering departments will result in a significant impact on society through the training of a diverse, globally competitive STEM workforce with high data literacy. <br/><br/>The objectives of this project are to (1) facilitate data science education and workforce development for engineering and related topics, (2) provide opportunities for students to participate in practical experiences where they can learn new skills in a variety of environments, and (3) expand the data science talent pool by enabling the participation of undergraduate students with diverse backgrounds, experiences, skills, and technical maturity in the Data Science Corps. This work will support the Data Science Corps objective of building capacity for education and workforce development to harness the data revolution at local, state, and national levels. The institutions gathered for this project will develop training programs and curate datasets that will be made available so they can be included in undergraduate instruction nationwide. Furthermore, the training materials will be shared with industry partners, facilitating workforce development. The project team will develop a website to house data science training programs, didactic datasets, and other resources for educators. These resources are intended to reduce barrier to entry for faculty seeking to incorporate data science into their instruction, as recruiting and retaining faculty to create and teach integrated introductory courses in data science has been recognized as a significant hurdle by the National Academies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2217069
Title: Collaborative Research: EnCORE: Institute for Emerging CORE Methods in Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Phillip Regalia
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $986,186
ARRA Amount: $
Investigator(s): Rachel Ward rward@math.utexas.edu (Principal Investigator) Shuchi Chawla (Co-Principal Investigator) Sujay Sanghavi (Co-Principal Investigator) Purnamrita Sarkar (Co-Principal Investigator) 
Organization: University of Texas at Austin
110 INNER CAMPUS DR, AUSTIN, TX 78712-1139, (512)471-6424
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The proliferation of data-driven decision making, and its increased popularity, has fueled rapid emergence of data science as a new scientific discipline. Data science is seen as a key enabler of future businesses, technologies, and healthcare that can transform all aspects of socioeconomic lives. Its fast adoption, however, often comes with ad hoc implementation of techniques with suboptimal, and sometimes unfair and potentially harmful, results. The time is ripe to develop principled approaches to lay solid foundations of data science. This is particularly challenging as real-world data is highly complex with intricate structures, unprecedented scale, rapidly evolving characteristics, noise, and implicit biases. Addressing these challenges requires a concerted effort across multiple scientific disciplines such as statistics for robust decision making under uncertainty; mathematics and electrical engineering for enabling data-driven optimization beyond worst case; theoretical computer science and machine learning for new algorithmic paradigms to deal with dynamic and sensitive data in an ethical way; and basic sciences to bring the technical developments to the forefront of health sciences and society. The proposed institute for emerging CORE methods in data science (EnCORE) brings together a diverse team of researchers spanning the afore-mentioned disciplines from the University of California San Diego, University of Texas Austin, University of Pennsylvania, and the University of California Los Angeles. It presents an ambitious vision to transform the landscape of the four CORE pillars of data science: C for complexities of data, O for optimization, R for responsible learning, and E for education and engagement. Along with its transformative research vision, the institute fosters a bold plan for outreach and broadening participation by engaging students of diverse backgrounds at all levels from K-12 to postdocs and junior faculty. The project aims to impact a wide demography of students by offering collaborative courses across its partner universities and a flexible co-mentorship plan for truly multidisciplinary research. With regular organization of workshops, summer schools, and seminars, the project aims to engage the entire scientific community to become the new nexus of research and education on foundations of data science. To bring the fruit of theoretical development to practice, EnCORE will continuously work with industry partners, domain scientists, and will forge strong connections with other National Science Foundation Harnessing Data Revolution institutes across the nation.<br/><br/>EnCORE as an institute embodies intellectual merit that has the potential to lead ground-breaking research to shape the foundations of data science in the United States. Its research mission is organized around three themes. The first theme on data complexity addresses the complex characteristics of data such as massive size, huge feature space, rapid changes, variety of sources, implicit dependence structures, arbitrary outliers, and noise. A major overhaul of the core concepts of algorithm design is needed with a holistic view of different computational complexity measures. Faced with noise and outliers, uncertainty estimation is both necessary, and at the same time difficult, due to dynamic and changing data. Data heterogeneity poses major challenges even in basic classification tasks. The structural relationships hidden inside such data are crucial in the understanding and processing, and for downstream data analysis tasks such as in visualization and neuroscience. The second theme of EnCORE aims to transform the classical area of optimization where adaptive methods and human intervention can lead to major advances. It plans to revisit the foundations of distributed optimization to include heterogeneity, robustness, safety, and communication; and address statistical uncertainty due to distributional shift in dynamic data in control and reinforcement learning. The third and final theme of EnCORE proposes to build the foundations of responsible learning. Applications of machine learning in human-facing systems are severely hampered when the learned models are hard for users to understand and reproduce, may give biased outcomes, are easily changeable by an adversary, and reveal sensitive information. Thus, interpretability, reproducibility, fairness, privacy, and robustness must be incorporated in any data-driven decision making. The experience and dedication to mentoring and outreach, collaborative curriculum design, socially aware responsible research program, extensive institute activities, and industrial partnerships would pave the way for a substantial broader impact for EnCORE. Summer schools with year-long mentoring will take place in three states involving a large demography. Joint courses with hybrid, and fully online offerings will be developed. Utilizing prior experience of running Thinkabit lab that has impacted over 74,000 K-12 students so far, EnCORE will embark on an ambitious and thoughtful outreach program to improve the representation of under-represented groups and help create a future generation of workforce that is diverse, responsible, and has solid foundations in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2217033
Title: Collaborative Research: EnCORE: Institute for Emerging CORE Methods in Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Phillip Regalia
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $365,413
ARRA Amount: $
Investigator(s): Raghu Meka raghum@cs.ucla.edu (Principal Investigator) Alyson Fletcher (Co-Principal Investigator) 
Organization: University of California-Los Angeles
10889 WILSHIRE BLVD STE 700, LOS ANGELES, CA 90024-4201, (310)794-0102
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The proliferation of data-driven decision making, and its increased popularity, has fueled rapid emergence of data science as a new scientific discipline. Data science is seen as a key enabler of future businesses, technologies, and healthcare that can transform all aspects of socioeconomic lives. Its fast adoption, however, often comes with ad hoc implementation of techniques with suboptimal, and sometimes unfair and potentially harmful, results. The time is ripe to develop principled approaches to lay solid foundations of data science. This is particularly challenging as real-world data is highly complex with intricate structures, unprecedented scale, rapidly evolving characteristics, noise, and implicit biases. Addressing these challenges requires a concerted effort across multiple scientific disciplines such as statistics for robust decision making under uncertainty; mathematics and electrical engineering for enabling data-driven optimization beyond worst case; theoretical computer science and machine learning for new algorithmic paradigms to deal with dynamic and sensitive data in an ethical way; and basic sciences to bring the technical developments to the forefront of health sciences and society. The proposed institute for emerging CORE methods in data science (EnCORE) brings together a diverse team of researchers spanning the afore-mentioned disciplines from the University of California San Diego, University of Texas Austin, University of Pennsylvania, and the University of California Los Angeles. It presents an ambitious vision to transform the landscape of the four CORE pillars of data science: C for complexities of data, O for optimization, R for responsible learning, and E for education and engagement. Along with its transformative research vision, the institute fosters a bold plan for outreach and broadening participation by engaging students of diverse backgrounds at all levels from K-12 to postdocs and junior faculty. The project aims to impact a wide demography of students by offering collaborative courses across its partner universities and a flexible co-mentorship plan for truly multidisciplinary research. With regular organization of workshops, summer schools, and seminars, the project aims to engage the entire scientific community to become the new nexus of research and education on foundations of data science. To bring the fruit of theoretical development to practice, EnCORE will continuously work with industry partners, domain scientists, and will forge strong connections with other National Science Foundation Harnessing Data Revolution institutes across the nation.<br/><br/>EnCORE as an institute embodies intellectual merit that has the potential to lead ground-breaking research to shape the foundations of data science in the United States. Its research mission is organized around three themes. The first theme on data complexity addresses the complex characteristics of data such as massive size, huge feature space, rapid changes, variety of sources, implicit dependence structures, arbitrary outliers, and noise. A major overhaul of the core concepts of algorithm design is needed with a holistic view of different computational complexity measures. Faced with noise and outliers, uncertainty estimation is both necessary, and at the same time difficult, due to dynamic and changing data. Data heterogeneity poses major challenges even in basic classification tasks. The structural relationships hidden inside such data are crucial in the understanding and processing, and for downstream data analysis tasks such as in visualization and neuroscience. The second theme of EnCORE aims to transform the classical area of optimization where adaptive methods and human intervention can lead to major advances. It plans to revisit the foundations of distributed optimization to include heterogeneity, robustness, safety, and communication; and address statistical uncertainty due to distributional shift in dynamic data in control and reinforcement learning. The third and final theme of EnCORE proposes to build the foundations of responsible learning. Applications of machine learning in human-facing systems are severely hampered when the learned models are hard for users to understand and reproduce, may give biased outcomes, are easily changeable by an adversary, and reveal sensitive information. Thus, interpretability, reproducibility, fairness, privacy, and robustness must be incorporated in any data-driven decision making. The experience and dedication to mentoring and outreach, collaborative curriculum design, socially aware responsible research program, extensive institute activities, and industrial partnerships would pave the way for a substantial broader impact for EnCORE. Summer schools with year-long mentoring will take place in three states involving a large demography. Joint courses with hybrid, and fully online offerings will be developed. Utilizing prior experience of running Thinkabit lab that has impacted over 74,000 K-12 students so far, EnCORE will embark on an ambitious and thoughtful outreach program to improve the representation of under-represented groups and help create a future generation of workforce that is diverse, responsible, and has solid foundations in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2217058
Title: Collaborative Research: EnCORE: Institute for Emerging CORE Methods in Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Phillip Regalia
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $1,919,261
ARRA Amount: $
Investigator(s): Barna Saha barnas@ucsd.edu (Principal Investigator) Kamalika Chaudhuri (Co-Principal Investigator) Yusu Wang (Co-Principal Investigator) Sanjoy Dasgupta (Co-Principal Investigator) Arya Mazumdar (Co-Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The proliferation of data-driven decision making, and its increased popularity, has fueled rapid emergence of data science as a new scientific discipline. Data science is seen as a key enabler of future businesses, technologies, and healthcare that can transform all aspects of socioeconomic lives. Its fast adoption, however, often comes with ad hoc implementation of techniques with suboptimal, and sometimes unfair and potentially harmful, results. The time is ripe to develop principled approaches to lay solid foundations of data science. This is particularly challenging as real-world data is highly complex with intricate structures, unprecedented scale, rapidly evolving characteristics, noise, and implicit biases. Addressing these challenges requires a concerted effort across multiple scientific disciplines such as statistics for robust decision making under uncertainty; mathematics and electrical engineering for enabling data-driven optimization beyond worst case; theoretical computer science and machine learning for new algorithmic paradigms to deal with dynamic and sensitive data in an ethical way; and basic sciences to bring the technical developments to the forefront of health sciences and society. The proposed institute for emerging CORE methods in data science (EnCORE) brings together a diverse team of researchers spanning the afore-mentioned disciplines from the University of California San Diego, University of Texas Austin, University of Pennsylvania, and the University of California Los Angeles. It presents an ambitious vision to transform the landscape of the four CORE pillars of data science: C for complexities of data, O for optimization, R for responsible learning, and E for education and engagement. Along with its transformative research vision, the institute fosters a bold plan for outreach and broadening participation by engaging students of diverse backgrounds at all levels from K-12 to postdocs and junior faculty. The project aims to impact a wide demography of students by offering collaborative courses across its partner universities and a flexible co-mentorship plan for truly multidisciplinary research. With regular organization of workshops, summer schools, and seminars, the project aims to engage the entire scientific community to become the new nexus of research and education on foundations of data science. To bring the fruit of theoretical development to practice, EnCORE will continuously work with industry partners, domain scientists, and will forge strong connections with other National Science Foundation Harnessing Data Revolution institutes across the nation.<br/><br/>EnCORE as an institute embodies intellectual merit that has the potential to lead ground-breaking research to shape the foundations of data science in the United States. Its research mission is organized around three themes. The first theme on data complexity addresses the complex characteristics of data such as massive size, huge feature space, rapid changes, variety of sources, implicit dependence structures, arbitrary outliers, and noise. A major overhaul of the core concepts of algorithm design is needed with a holistic view of different computational complexity measures. Faced with noise and outliers, uncertainty estimation is both necessary, and at the same time difficult, due to dynamic and changing data. Data heterogeneity poses major challenges even in basic classification tasks. The structural relationships hidden inside such data are crucial in the understanding and processing, and for downstream data analysis tasks such as in visualization and neuroscience. The second theme of EnCORE aims to transform the classical area of optimization where adaptive methods and human intervention can lead to major advances. It plans to revisit the foundations of distributed optimization to include heterogeneity, robustness, safety, and communication; and address statistical uncertainty due to distributional shift in dynamic data in control and reinforcement learning. The third and final theme of EnCORE proposes to build the foundations of responsible learning. Applications of machine learning in human-facing systems are severely hampered when the learned models are hard for users to understand and reproduce, may give biased outcomes, are easily changeable by an adversary, and reveal sensitive information. Thus, interpretability, reproducibility, fairness, privacy, and robustness must be incorporated in any data-driven decision making. The experience and dedication to mentoring and outreach, collaborative curriculum design, socially aware responsible research program, extensive institute activities, and industrial partnerships would pave the way for a substantial broader impact for EnCORE. Summer schools with year-long mentoring will take place in three states involving a large demography. Joint courses with hybrid, and fully online offerings will be developed. Utilizing prior experience of running Thinkabit lab that has impacted over 74,000 K-12 students so far, EnCORE will embark on an ambitious and thoughtful outreach program to improve the representation of under-represented groups and help create a future generation of workforce that is diverse, responsible, and has solid foundations in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1633755
Title: BIGDATA: F: Bringing Interactive Data Management to Scientists, Analysts, and the Masses: A Holistic Unification of Spreadsheets and Databases
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2016
Latest Amendment Date: September 19, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $1,795,429
ARRA Amount: $
Investigator(s): Kevin Chang kcchang@illinois.edu (Principal Investigator) Kevin Chang (Former Principal Investigator) Karrie Karahalios (Former Principal Investigator) Aditya Parameswaran (Former Co-Principal Investigator) Kevin Chang (Former Co-Principal Investigator) Karrie Karahalios (Former Co-Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: With the proliferation of datasets in many spheres of our everyday life, including science, finance, and commerce, managing tabular data, i.e., data represented by a set of tables or relations, has become increasingly essential. The state of the art in tabular data management spans two distinct paradigms with a sharp divide--spreadsheets and databases--with drastically different strengths and weaknesses; both enjoying tremendous successes but facing fundamental limitations. To date, interactive ad-hoc management of large data remains cumbersome and difficult. This project aims to holistically unify database and spreadsheet technology, and thus bring to scientists, analysts, and lay users, the ease of use and interactivity of spreadsheets with the scalability, expressiveness, and collaboration capabilities of databases.<br/><br/>The project develops DataSpread, a system to holistically unify databases with spreadsheets--to marry the traditional strengths of scalability, expressiveness, and consistency of databases with the interactivity of spreadsheets that billions of end-users are so familiar with, and in the process rethink user-facing interactions beyond spreadsheets which the project will develop and evaluate via extensive user studies. The research team studies the development of new models, algorithms, structures, and interaction primitives to make the unification practical. Specifically, this research develops new methods for compactly representing spreadsheet data and computing over queries on a spreadsheet, positionally aware indexing structures, and mechanisms for efficiently propagating updates to the user viewport. The project also studies the design of new interaction primitives to replace full-fledged SQL, which is more conducive to a spreadsheet interface, and in support for user-centric transactions. While aiming at developing general techniques to advance the state of the art in data management, the project will be driven by the collaborators' real-world challenges--for use cases, pain points, practical deployment, joint open-source development, and critical evaluation and feedback.

Award Number: 1939951
Title: Collaborative Proposal: Accelerating Synthetic Biology Discovery & Exploration through Knowledge Integration
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: January 24, 2020
Award Instrument: Standard Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $155,766
ARRA Amount: $
Investigator(s): Bridget McInnes btmcinnes@vcu.edu (Principal Investigator) Jeff Elhai (Former Principal Investigator) 
Organization: Virginia Commonwealth University
912 W FRANKLIN ST, RICHMOND, VA 23284-9040, (804)828-6772
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165
Program Element Code(s): 099Y, 7231
Abstract: The scientific challenge for this project is to accelerate discovery and exploration of the synthetic biology design space.  In particular, many parts used in synthetic biology come from or are initially tested in a simple bacteria, E. coli, but many potential applications in energy, agriculture, materials, and health require either different bacteria or higher level organisms (yeast for example). Currently, researchers use a trial-and-error approach because they cannot find reliable information about prior experiments with a given part of interest. This process simply cannot scale. Therefore, to achieve scale, a wide range of data must be harnessed to allow confidence to be determined about the likelihood of success. The quantity of data and the exponential increase in the publications generated by this field is creating a tipping point, but this data is not readily accessible to practitioners. To address this challenge, our multidisciplinary team of biological engineers, machine learning experts, data scientists, library scientists, and social scientists will build a knowledge system integrating disparate data and publication repositories in order to deliver effective and efficient access to collectively available information; doing so will enable expedited, knowledge-based synthetic biology design research.<br/><br/>This project will develop an open and integrated synthetic biology knowledge system (SBKS) that leverages existing data repositories and publications to create a single interface that transforms the way researchers access this information. Access to up-to-date information in multiple, heterogeneous sources will be provided via a federated approach. New methods based on machine learning will be developed to automatically generate ontology annotations in order to create connections between data in various repositories and information extracted from publications.  Provenance for each entity in SBKS will be tracked, and it will be utilized by new methods that are developed to assess bias and assign confidence scores to knowledge returned for each entity. An intuitive, natural-language-based interface and visualization functionality will be implemented for users to easily access and explore SBKS contents.  Additionally, as ethics is necessarily a part of synthetic biology research, data from text sources related to ethical concerns in synthetic biology will also be incorporated to inform researchers about ethical debates relevant to their search queries.  Finally, to test the SBKS API, a new genetic design tool, Kimera, will be developed that leverages the knowledge in SBKS to produce better designs.  The proposed SBKS will accelerate discovery and innovation by enabling researchers to learn from others' past experiences and to maximize the productivity of valuable experimental time on testing designs that have a higher likelihood of working when transformed to a new organism.  This research thus provides the potential for transformative research outcomes in the field of synthetic biology by leveraging data science to improve the field's epistemic culture. For more information please see https://synbioks.github.io.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838193
Title: BIGDATA: IA: Multiplatform, Multilingual, and Multimodal Tools for Analyzing Public Communication in over 100 Languages
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: September 07, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: September 15, 2018
End Date: August 31, 2023
Awarded Amount to Date: $1,000,000
ARRA Amount: $
Investigator(s): Margrit Betke betke@cs.bu.edu (Principal Investigator) Derry Wijaya (Co-Principal Investigator) Prakash Ishwar (Co-Principal Investigator) Lei Guo (Co-Principal Investigator) 
Organization: Trustees of Boston University
1 SILBER WAY, BOSTON, MA 02215-1703, (617)353-4365
NSF Directorate: CSE
Program(s): HCC-Human-Centered Computing Big Data Science &Engineering Data Infrastructure 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 7367, 8083, 8294
Abstract: In today's information age, understanding public communication flows around the world is important to United States policy and diplomacy. The challenge for research is to collect, analyze, and interpret information as it is presented worldwide, creating big data that is flowing at high velocity, in large volumes, with much variety in perspective, language, and platforms. Analytic methods for studying textual and visual public information worldwide are limited by language hurdles. This project aims to solve data analytics problems in the domain of international public information flows by developing methods that effectively leverage natural language processing, machine learning, and computer vision tools.<br/>    <br/>This research will involve collecting multilingual, multiplatform, and multimodal corpora of text and images originating in the U.S. and reported worldwide, developing an interactive budget-efficient methodology for annotation by experts and crowdworkers that scales effectively, using machine learning and deep learning techniques that exploit multilingual and multimodal representations to develop data analytics tools for entity and frame recognition, sentiment analysis of entities and frames, and curating balanced real-time content collections for many languages. This project is expected to generate analytical tools for social scientists and others to better examine the international flow of public communications. The annotated data will provide training and benchmark datasets that can propel research in entity and frame recognition, sentiment analysis, and other related natural language processing tasks for many languages.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2217062
Title: Collaborative Research: EnCORE: Institute for Emerging CORE Methods in Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Phillip Regalia
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $729,140
ARRA Amount: $
Investigator(s): Hamed Hassani hassani@seas.upenn.edu (Principal Investigator) Eric Tchetgen Tchetgen (Co-Principal Investigator) Rajiv Gandhi (Co-Principal Investigator) AARON ROTH (Co-Principal Investigator) George Pappas (Co-Principal Investigator) 
Organization: University of Pennsylvania
3451 WALNUT ST STE 440A, PHILADELPHIA, PA 19104-6205, (215)898-7293
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The proliferation of data-driven decision making, and its increased popularity, has fueled rapid emergence of data science as a new scientific discipline. Data science is seen as a key enabler of future businesses, technologies, and healthcare that can transform all aspects of socioeconomic lives. Its fast adoption, however, often comes with ad hoc implementation of techniques with suboptimal, and sometimes unfair and potentially harmful, results. The time is ripe to develop principled approaches to lay solid foundations of data science. This is particularly challenging as real-world data is highly complex with intricate structures, unprecedented scale, rapidly evolving characteristics, noise, and implicit biases. Addressing these challenges requires a concerted effort across multiple scientific disciplines such as statistics for robust decision making under uncertainty; mathematics and electrical engineering for enabling data-driven optimization beyond worst case; theoretical computer science and machine learning for new algorithmic paradigms to deal with dynamic and sensitive data in an ethical way; and basic sciences to bring the technical developments to the forefront of health sciences and society. The proposed institute for emerging CORE methods in data science (EnCORE) brings together a diverse team of researchers spanning the afore-mentioned disciplines from the University of California San Diego, University of Texas Austin, University of Pennsylvania, and the University of California Los Angeles. It presents an ambitious vision to transform the landscape of the four CORE pillars of data science: C for complexities of data, O for optimization, R for responsible learning, and E for education and engagement. Along with its transformative research vision, the institute fosters a bold plan for outreach and broadening participation by engaging students of diverse backgrounds at all levels from K-12 to postdocs and junior faculty. The project aims to impact a wide demography of students by offering collaborative courses across its partner universities and a flexible co-mentorship plan for truly multidisciplinary research. With regular organization of workshops, summer schools, and seminars, the project aims to engage the entire scientific community to become the new nexus of research and education on foundations of data science. To bring the fruit of theoretical development to practice, EnCORE will continuously work with industry partners, domain scientists, and will forge strong connections with other National Science Foundation Harnessing Data Revolution institutes across the nation.<br/><br/>EnCORE as an institute embodies intellectual merit that has the potential to lead ground-breaking research to shape the foundations of data science in the United States. Its research mission is organized around three themes. The first theme on data complexity addresses the complex characteristics of data such as massive size, huge feature space, rapid changes, variety of sources, implicit dependence structures, arbitrary outliers, and noise. A major overhaul of the core concepts of algorithm design is needed with a holistic view of different computational complexity measures. Faced with noise and outliers, uncertainty estimation is both necessary, and at the same time difficult, due to dynamic and changing data. Data heterogeneity poses major challenges even in basic classification tasks. The structural relationships hidden inside such data are crucial in the understanding and processing, and for downstream data analysis tasks such as in visualization and neuroscience. The second theme of EnCORE aims to transform the classical area of optimization where adaptive methods and human intervention can lead to major advances. It plans to revisit the foundations of distributed optimization to include heterogeneity, robustness, safety, and communication; and address statistical uncertainty due to distributional shift in dynamic data in control and reinforcement learning. The third and final theme of EnCORE proposes to build the foundations of responsible learning. Applications of machine learning in human-facing systems are severely hampered when the learned models are hard for users to understand and reproduce, may give biased outcomes, are easily changeable by an adversary, and reveal sensitive information. Thus, interpretability, reproducibility, fairness, privacy, and robustness must be incorporated in any data-driven decision making. The experience and dedication to mentoring and outreach, collaborative curriculum design, socially aware responsible research program, extensive institute activities, and industrial partnerships would pave the way for a substantial broader impact for EnCORE. Summer schools with year-long mentoring will take place in three states involving a large demography. Joint courses with hybrid, and fully online offerings will be developed. Utilizing prior experience of running Thinkabit lab that has impacted over 74,000 K-12 students so far, EnCORE will embark on an ambitious and thoughtful outreach program to improve the representation of under-represented groups and help create a future generation of workforce that is diverse, responsible, and has solid foundations in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934846
Title: HDR TRIPODS: Institute for Integrated Data Science: A Transdisciplinary Approach to Understanding Fundamental Trade-offs and Theoretical Foundations
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 18, 2019
Latest Amendment Date: August 23, 2021
Award Instrument: Continuing Grant
Program Manager: Tracy Kimbrel
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Andrew McGregor mcgregor@cs.umass.edu (Principal Investigator) Markos Katsoulakis (Co-Principal Investigator) Arya Mazumdar (Co-Principal Investigator) Patrick Flaherty (Co-Principal Investigator) Barna Saha (Co-Principal Investigator) 
Organization: University of Massachusetts Amherst
COMMONWEALTH AVE, AMHERST, MA 01003-, (413)545-0698
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z 9102 9251
Program Element Code(s): 041Y, 099Y
Abstract: Many areas of science, engineering, and industry are already being revolutionized by the adoption of tools and techniques from data science. However, a rigorous analysis of existing approaches together with the development of new ideas is necessary to a) ensure the optimal use of available computational and statistical resources and b) develop a principled and systematic approach to the relevant problems rather than relying on a collection of ad hoc solutions. In particular, there are many interrelated questions that arise in a typical data science project. First is the acquisition of relevant data: Can data be collected interactively and might this reduce the costs of data acquisition? Is the data noisy and how might this impact the results? Second is the processing of data: If the data cannot fit in the memory of a single machine, how can we minimize the communication costs within a cluster of machines? When are approximate answers sufficient and how does the required accuracy trade off with the computational resources available? Third is the prediction value of the available data: Can the uncertainty of the final results be quantified? How can the modeling assumptions used by our algorithms be efficiently evaluated? This award supports a data science institute with the main goal of developing an understanding of the fundamental mathematical and computational issues underlying the aforementioned questions. Ultimately, this will enable practitioners to make more informed decisions when investing time and money across the life cycle of their data science project. Achieving this goal necessitates a transdisciplinary approach and the team of investigators includes experts in theoretical computer science; applied and computational mathematics; machine learning and statistics; and coding and information theory. In addition to pursuing the above research goals, the institute will coordinate education and training activities and develop resources for the research community.<br/><br/>Specific research goals explored in this project include: 1) Understanding the trade-off between rounds of interactive data acquisition and statistical and computational efficiency. 2) Minimizing query complexity in interactive unsupervised learning problems. 3) Understanding space/sample complexity trade-offs when processing stochastic data. 4) Developing fine-grained approximation algorithms relevant to core data science tasks. 5) Using coding theory to enable communication-efficient distributed machine learning. 6) Designing variational inference methods with statistical guarantees given limited resources. 7) Developing a principled approach to exploiting trade-offs between bias, model complexity, and computational budget. Specific institute activities include: 1) Technical workshops and training activities for researchers in domain sciences. 2) A virtual speaker series. 3) Education initiatives including the development of new courses that will teach foundational topics in data science and  resources that can be used across different institutions. The grant will also train postdoctoral scholars and undergraduate researchers.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838131
Title: BIGDATA: F: Collaborative Research: Theory and Practice of Randomized Algorithms for Ultra-Large-Scale Signal Processing
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: September 10, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: December 01, 2018
End Date: November 30, 2022
Awarded Amount to Date: $400,000
ARRA Amount: $
Investigator(s): Michael Mahoney mmahoney@icsi.berkeley.edu (Principal Investigator) 
Organization: International Computer Science Institute
1947 CENTER ST, BERKELEY, CA 94704-1159, (510)666-2900
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: The dramatic increases in our abilities to observe massive amounts of measurements coming from distributed and disparate high-resolution sensors have been instrumental in enhancing our understanding of many physical phenomena. Signal processing has been the primary driving force in this knowledge of the unseen from observed measurements. However, in the last decade, the exponential increase in observations has outpaced our computing abilities to process, understand, and organize this massive but useful information. In this project the investigators plan to blend efficient hashing algorithms with Randomized Numerical Linear Algebra, which can overcome these computational barriers. The project will engage diverse graduate and undergraduate students in computer science, statistics, ECE, and applied mathematics both at UCB and Rice. The efforts of this project will also be utilized to push data science for social good, through collaborations with a human rights data analysis group in leveraging hashing algorithms to reduce human efforts in estimating the extent of war crimes. The results of the project will be made available to a wide audience through OpenStax CNX, which will to disseminate course materials free-of-charge to anyone in the world and thereby foster the growth of vibrant communities around the subject.<br/><br/>This project will achieve two complementary goals: first, extend the foundations of RandNLA by tailoring randomization directly towards downstream end goals provided by the underlying problem, rather than intermediate matrix approximations goals; and second, use the statistical and optimization insights obtained from these downstream applications to transform and extend the foundations of RandNLA. The investigators will propose and extend several fundamental ideas, including probabilistic hashing, sketching, streaming, sampling, leverage scores, and random projections, to make SP significantly resource-frugal. Precise mathematical quantification of these tradeoffs will be provided.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837931
Title: BIGDATA: F: Computationally Efficient Algorithms for Large-Scale Crossed Random Effects Models
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Pena Edsel
Start Date: September 15, 2018
End Date: August 31, 2023
Awarded Amount to Date: $800,000
ARRA Amount: $
Investigator(s): Art Owen owen@stat.stanford.edu (Principal Investigator) Trevor Hastie (Co-Principal Investigator) 
Organization: Stanford University
450 Jane Stanford Way, Stanford, CA 94305-2004, (650)723-2300
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: The problems of deciding what to buy, where to eat, which movie to watch, and so forth are of enormous economic value to consumers, sellers, and the people employed making those goods and services. Companies try to match people and products using vast data sets recording purchases and opinions. Even with a large data set it is a challenge to get reliable results. Measurements on the same or similar products are correlated, as are measurements by the same or similar people; however, correlated data yield less information than uncorrelated data.  Properly accounting for the correlation requires too much computation, even on modern large computers, because the amount of computation grows as a power of the size of the data.  Ignoring those correlations will produce an analysis that becomes overconfident and findings that are not reproducible, leading to inefficiency and wasteful decisions.  This project will develop computationally efficient and reliable methods to handle data of this kind as well as more complicated data structures.  The results of this research will benefit both industry and individuals making purchasing decisions.<br/><br/>The problems described above are known as crossed random effects in the statistical literature.  The statistically proper tools are linear mixed models and generalized linear mixed models.  The usual ways to fit linear mixed models have a cost that grows faster than linearly in the size of the data set.  The exponent is three halves.  The same cost arises in a Bayesian approach. With large modern data sets these costs are completely out of reach. Some recent solutions work with the method of moments at a cost that scales linearly with the data size.  This project will develop a backfitting method that starts with the moment method and then iterates towards the maximum likelihood solution.  It will also extend to the generalized linear mixed model case in order to handle binary outcomes, such as whether the customer did or did not buy a particular item.   While crossed random effects are prevalent in electronic commerce, they can arise in any setting where there are many to many relationships connecting one sort of entity to another.  Any place where we have observations on the edges of a bipartite graph is a place where crossed random effects may arise.   This work will also include random slope models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1923986
Title: HDR DSC: Collaborative Research: Creating and Integrating Data Science Corps to Improve the Quality of Life in Urban Areas
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2019
Latest Amendment Date: September 19, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $180,000
ARRA Amount: $
Investigator(s): Sharad Sharma ssharma@bowiestate.edu (Principal Investigator) 
Organization: Bowie State University
14000 JERICHO PARK ROAD, RM 115, BOWIE, MD 20715-3319, (301)860-4399
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a team-based data science corps program for undergraduate students from Computer Science, Information Systems, and Business integrating both academic training as well as hands-on experience through real-world data science projects. This project is a collaborative effort with the University of Maryland Baltimore County as the coordinating as well as an implementing organization, and the University of Baltimore, Towson University, and Bowie State University as implementing organizations.  This project focuses on the city of Baltimore as an exemplar for other cities in the US and across the globe.   The project team will collaborate with a number of communities in the city of Baltimore to integrate real-world data science projects into classroom instruction in data science. The specific objectives of this project are as follows: (i) Develop the technical, analytical, modeling, and critical thinking skills that are key to success as a data science professional; (ii) Connect a cohort of students to communities, organizations, and projects that can benefit from the power of data science; (iii) Nurture and support innovative thinking in solving some of the key challenges facing the real world; (iv) Promote a better understanding of the power and pitfalls of data-driven discoveries to improve the quality of life in urban communities; (v) Increase the data science workforce capacity to support this critical area that is of growing importance in society; and finally, (vi) Evaluate the effect of the proposed data science corps on student learning. <br/><br/>This project will create a core set of knowledge that will be valuable in developing solutions for real-world urban settings with the understanding that not all projects will require the application or use of every topic covered in the data science corps program. The core set of knowledge includes data collection and cleaning, data analysis using machine learning and deep learning techniques, data visualization including geospatial data and virtual reality, data privacy and security, and infrastructure for smart cities including IoT-based sensor networks.   The proposed data science corps program will have two main phases: instructional phase (10 modules in total) and real-world team projects (5 modules in total). The project teams consist of students who have taken a course in at least one of the following areas: data collection and analysis, big data, machine learning including deep learning, smart cities, cybersecurity, geospatial data analysis and visualization, and virtual reality. Examples of team projects include: (i) developing community-based indicators that are compiled from open data portals and parametric and non-parametric statistical techniques to understand the relationship between urban sustainability and a range of factors including cleanliness and environment, crime and safety, business and economics, social and political, housing, health, and education; (ii) combining deep learning models such as convolutional neural networks (CNN) and long term short term memory recurrent neural networks (LSTM-RNN) to develop prediction models for derelict buildings that are likely to become vacant; (iii) combining sensor data and social media for automated information extraction, validation, and quality checks that can be beneficial to both citizens and emergency managers in crisis situations such as flash floods; (iv) developing smart streetlights that are networked LED systems that can be adjusted based on time of day and motion and can report outages back to central operations; and (v) developing augmented reality-based systems that leverage systems such as Microsoft HoloLens and mobile devices for building evacuation.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940276
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $734,697
ARRA Amount: $
Investigator(s): David Matteson dm484@cornell.edu (Principal Investigator) Remi Cousin (Co-Principal Investigator) 
Organization: Cornell University
341 PINE TREE RD, ITHACA, NY 14850-2820, (607)255-5014
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE Big Data Science &Engineering 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231, 8083
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838159
Title: BIGDATA: F: Advancing Deep Learning to Monitor Global Change
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: May 26, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: November 01, 2018
End Date: October 31, 2023
Awarded Amount to Date: $1,478,398
ARRA Amount: $
Investigator(s): Vipin Kumar kumar001@umn.edu (Principal Investigator) Michael Steinbach (Co-Principal Investigator) Philip Pardey (Co-Principal Investigator) James Wilgenbusch (Co-Principal Investigator) Senait Senay (Co-Principal Investigator) 
Organization: University of Minnesota-Twin Cities
200 OAK ST SE # 224, MINNEAPOLIS, MN 55455-2009, (612)624-5599
NSF Directorate: CSE
Program(s): IIS Special Projects Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9251
Program Element Code(s): 7484, 8083
Abstract: Growth in the world's population and the acceleration of industrialization and urbanization are straining already scarce natural resources and food supplies, which must scale up to keep pace with growing demand. The consequences of the resulting large-scale changes include tremendous stresses on the environment, as well as challenges to our ability to feed the world's population, which could be calamitous at the current rate of change if not managed sustainably. Meeting this challenge will require timely information on global changes; for example, the changing productivity performance of land in agriculture; the conversion of forest to farmland or plantations, and the loss of productive farmland due to urbanization; and soil and water degradation. To address these challenges in monitoring global change, this project will develop advanced machine learning techniques, especially deep learning. The project's primary focus will be on the analysis of remote sensing data, available from a variety of instruments and sensors aboard satellites through United States and international agencies. These rich datasets capture multiple facets of the natural processes and human activities that shape the physical landscape and environmental quality of our planet, and thus offer an opportunity to study and better shape the nature and impact of global changes.<br/><br/>This project seeks to greatly advance the state-of-the-art in machine learning techniques for analyzing the multi-scale, multi-source, spatio-temporal data about earth system processes. Specifically, this project will advance deep learning techniques to meet the challenges involved in using remote sensing data for global change monitoring. Deep learning has been successful in addressing problems in a number of domains involving complex data sets with spatial and temporal (sequential) information such as vision, video, and natural language processing. The promise of deep learning mainly stems from its capacity to exploit complex mapping relationships and extract discriminative features over space and time using large volumes of training data. Consequently, there has been a flurry of activity in applying deep learning techniques to remote sensing data. However, due to challenges that are unique to environmental applications, off-the-shelf deep learning techniques developed for related applications such as computer vision have limited utility. This research will address these challenges and advance the state-of-the-art in deep learning techniques by developing techniques that can make use of the underlying complex, multi-scale, spatio-temporal earth system processes for global change monitoring. Methods developed in this project are expected to also have an impact across many disciplines that deal with large-scale time-varying data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123444
Title: Collaborative Research: HDR DSC: DS-PATH: Data Science Career Pathways in the Inland Empire
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 17, 2021
Latest Amendment Date: August 05, 2022
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $604,395
ARRA Amount: $
Investigator(s): Mariam Salloum msalloum@cs.ucr.edu (Principal Investigator) Vassilis Tsotras (Co-Principal Investigator) Xinping Cui (Co-Principal Investigator) Paea LePendu (Co-Principal Investigator) Analisa Flores (Co-Principal Investigator) 
Organization: University of California-Riverside
900 UNIVERSITY AVE, RIVERSIDE, CA 92521-9800, (951)827-5535
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu IIS Special Projects 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 7484
Abstract: This project brings together six partnering institutions to advance Data Science education in the Inland Empire, one of the most populous and diverse regions in California and the nation. The partnership includes the University of California Riverside, California State University San Bernardino, the three community colleges of the Riverside Community College District, and San Bernardino Valley College. All six partners are Hispanic Serving Institutions. The objective is develop and deploy ?The Data Science Career Pathways in the Inland Empire? (DS-PATH), a DSC program that aims to: (i) create flexible pathways for Data Science education in the Inland Empire region of Southern California, (ii) provide students with experiential learning opportunities, (iii) develop a community of partners that will provide local, tangible, and impactful Data Science projects, and (iv) broaden participation of females and under-represented minorities in Data Science.<br/><br/>The team of diverse PIs and co-PIs puts forward a program centered around more flexible educational pathways, along with course alignments, articulations, and shared experiential learning opportunities. DS-PATH will create a pipeline that starts with outreach opportunities at the high-school level, continues<br/>with undergraduate experiences and innovative bridge pathways from other majors, and culminates in professional Master?s degrees. Bridging these together is a Summer Fellowship program that will train 120 student participants at all levels. These pathways and the long-lasting relationships developed with local industry and community partners will continue to offer workforce development, educational advancement, and project-based learning opportunities not only for DS-PATH fellows but for all future aspiring Data Scientists in the region. Moreover, a workshop focused on Data Science pedagogy will<br/>offer best and inclusive teaching strategies to Inland Empire teachers/faculty.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2118285
Title: HDR Institute: HARP- Harnessing Data and Model Revolution in the Polar Regions
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2021
Latest Amendment Date: May 24, 2022
Award Instrument: Cooperative Agreement
Program Manager: Amy Walton
Start Date: January 01, 2022
End Date: December 31, 2026
Awarded Amount to Date: $5,000,000
ARRA Amount: $
Investigator(s): Vandana Janeja vjaneja@umbc.edu (Principal Investigator) Maryam Rahnemoonfar (Former Principal Investigator) Jan Lenaerts (Co-Principal Investigator) Jianwu Wang (Co-Principal Investigator) Shashi Shekhar (Co-Principal Investigator) Mathieu Morlighem (Co-Principal Investigator) 
Organization: University of Maryland Baltimore County
1000 HILLTOP CIR, BALTIMORE, MD 21250-0001, (410)455-3140
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu ANT Integrated System Science Polar Cyberinfrastructure CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 1079 5294 7231 9102
Program Element Code(s): 099Y, 5292, 5407, 7231
Abstract: Climate-change induced loss of polar ice sheets impacts many lives and increases coastal flooding by rising sea level and affecting ocean circulation. However, it remains difficult to accurately predict how quickly the ice sheets will continue to shrink. In particular, we are still challenged by a limited understanding of transdisciplinary processes that determine ice sheet change, such as the role of subglacial topography and ice-atmosphere-ocean interactions. Timely investment in machine learning and data intensive research can revolutionize the way that scientists currently answer questions related to ice dynamics. This HDR Institute serves as a research hub where experts in data science, Arctic and Antarctic science, and cyberinfrastructure in academia, government, and private sectors come together to develop transformative and integrative data science solutions to reduce uncertainties in projecting future sea-level rise and climate change. i-HARP researchers investigate the potential of novel physics-aware data science and machine learning approaches to address national priorities and challenges on Navigating the New Arctic, climate change, and sea-level rise.<br/><br/>The HDR Institute aims to harness massive heterogeneous, noisy, and discontinuous data in space and time and integrate data with numerical and physical models. Researchers at i-HARP are investigating novel data science techniques including deep generative adversarial networks, graph neural networks, meta learning, hybrid networks, physics-informed machine learning, causal artificial intelligence, data assimilation, spatiotemporal deep learning, and scalable algorithms. Due to the fundamental nature of data science problems that i-HARP addresses, the solutions can be translated to other disciplines such as remote sensing, medicine, and autonomous driving. Moreover, the convergence team champions multiple clusters of research-integrated educational initiatives, with a specific focus on facilitating cross-disciplinary collaborations, training next-generation multi-disciplinary researchers and engaging the public in scientific inquiry as related to climate change and data science. In partnership with related communities, i-HARP designs curricula, and offers hands-on community workshops, lecture series, conference tutorials, and training. i-HARP engages students from underrepresented minority groups by leveraging several existing organizations for underrepresented minorities.<br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR).  This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Section for Antarctic Sciences and the Section for Arctic Sciences within the NSF Office of Polar Programs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741490
Title: BIGDATA: IA: Collaborative Research: Parsimonious Anomaly Detection in Sequencing Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 03, 2017
Latest Amendment Date: August 27, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2022
Awarded Amount to Date: $420,273
ARRA Amount: $
Investigator(s): Roummel Marcia rmarcia@ucmerced.edu (Principal Investigator) Suzanne Sindi (Co-Principal Investigator) 
Organization: University of California - Merced
5200 N LAKE RD, MERCED, CA 95343-5001, (209)201-2039
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 9102 9251
Program Element Code(s): 8083
Abstract: Genomes contain the complete set of instructions for building an organism.  Structural variants are rearrangements in the genome such as insertions and deletions, whose discovery advances the understanding of the evolution and the adaptability of species.  Recent advances in high-throughput sequencing technologies have led to the collection of vast quantities of genomic data.  Because of this, fast and robust algorithms are needed to identify structural variants, which are rare and are prone to noise.   This research will contribute fundamentally to optimization methods for large-scale problems in computational genomics.  The algorithms will be disseminated publicly for use within and outside the biology, mathematics, and computer science community. Graduate students will be trained in scientific research and programming through this interdisciplinary research, and the participation of students from under-represented backgrounds will be highly encouraged. <br/><br/>The research objective of this award is to develop computational tools for large-scale data-driven problems arising in computational genomics.  These problems are especially difficult to solve since they are high-dimensional and the data are noisy and inexact.  This study will take advantage of known relationships in sequenced genomes to improve the accuracy of identifying genomic variants in population studies when there is both low coverage in the data and multiple related individuals are sequenced.  Specifically, the proposed research will (i) explore statistical models for describing the presence of structural variants in genomes, (ii) develop and implement novel sparse optimization methods for genomic structural variant detection, and (iii) validate on existing genomic data sets and predict on new data.

Award Number: 1741197
Title: BIGDATA: F: Collaborative Research: Design and Computation of Scalable Graph Distances in Metric Spaces: A Unified Multiscale Interpretable Perspective
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 05, 2017
Latest Amendment Date: September 05, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2023
Awarded Amount to Date: $1,023,986
ARRA Amount: $
Investigator(s): Stratis Ioannidis IOANNIDIS@ECE.NEU.EDU (Principal Investigator) Tina Eliassi-Rad (Co-Principal Investigator) 
Organization: Northeastern University
360 HUNTINGTON AVE, BOSTON, MA 02115-5005, (617)373-3004
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Representations of real-world phenomena as graphs (a.k.a. networks) are ubiquitous, ranging from social and information networks, to technological, biological, chemical, and brain networks. Many graph mining tasks -- including clustering, anomaly detection, nearest neighbor, similarity search, pattern recognition, and transfer learning -- require a distance measure between graphs to be computed efficiently. The existing distance measures between graphs leave a lot to be desired. They are overwhelmingly based on heuristics.  Many do not scale to graphs with millions of nodes; others do not satisfy the metric properties of non-negativity, positive definiteness, symmetry, and triangle inequality. This project studies a formal mathematical foundation covering a family of graph distances that overcome these limitations, focusing on real-world applications in biology and social network analysis. It also provides a universal methodology for parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes, and scaling it over cloud computing resources.<br/><br/>This project studies, designs, and evaluates graph distances that satisfy the following six properties: (1) They are scalable -- i.e., they are strictly subquadratic in runtime and achieve a speedup when computed in parallel. (2) They are metrics -- i.e., they satisfy<br/>non-negativity, positive definiteness, symmetry, and triangle inequality. (3) They are discriminative, as measured by comparisons to the "chemical distance", which finds the optimal mapping between two graphs that minimizes edge discrepancies. (4) They are statistically<br/>robust -- i.e., they have confidence intervals. (5) They can incorporate auxiliary information available on nodes and links. (6) They are interpretable to subject matter experts. Rather than providing a single metric, this project explores a family of such graph distance metrics. It also provides a universal methodology, using the Alternating Directions Method of Multipliers (ADMM), to parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes. The proposed metrics are evaluated over massive real-world graphs using Apache Spark on a cloud computing infrastructure.

Award Number: 2123440
Title: HDR DSC: AI across the statewide curriculum
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 02, 2021
Latest Amendment Date: March 28, 2022
Award Instrument: Continuing Grant
Program Manager: Chou, Y. Kevin
Start Date: January 01, 2022
End Date: December 31, 2024
Awarded Amount to Date: $726,184
ARRA Amount: $
Investigator(s): Jennifer Drew jdrew@ufl.edu (Principal Investigator) Bryan Kolaczkowski (Former Principal Investigator) Christina Gardner-McCune (Co-Principal Investigator) Aavudai Anandhi Swamy (Co-Principal Investigator) Satyanarayan Dev (Co-Principal Investigator) James Hoover (Co-Principal Investigator) 
Organization: University of Florida
1523 UNION RD RM 207, GAINESVILLE, FL 32611-1941, (352)392-3516
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Artificial Intelligence (AI) is reshaping the society we live in a profound manner. AI is changing how a nation protects its homeland and population, manages its natural resources and infrastructure, diagnoses and treats diseases, travel, communicates and creates artistic works, etc. AI has the potential to generate tremendous benefits for the society and people. However, the future AI workforce must represent the diversity of racial, ethnic, gender-identity and socioeconomic backgrounds reflective of the nation as a whole, otherwise, an AI-enabled future society could exacerbate existing disparities and benefit just a few, at the expense of too many. To address such a grand challenge, this DSC award is to train a diverse workforce capable of integrating AI equitably across a broad range of disciplines. The project provides unique AI training to students from any discipline using an approach that integrates classroom education in AI fundamentals, applications and ethics with real-world case studies and research experiences spanning the undergraduate curriculum with a focus on enhancing diversity. By recruiting and retaining historically underrepresented minorities in AI-related education and research, this project helps ensure that a diversity of backgrounds and opinions are included at all levels of future AI developments and applications, so the AI-enabled society can broadly benefit everyone.<br/><br/>To achieve the goal of educating a diverse next-generation AI workforce, this project develops a vertically-integrated curriculum in which students from outside traditional computer-science fields can learn AI-related concepts, skills and AI applications to address critical emerging problems in one?s field. Over 250 undergraduate fellowships will be created to help eliminate or lessen financial barriers to education. Further, between a research university and a historically black college, a strategic partnership provides flexible avenues to engage diverse undergraduates in AI-related education and research. This project develops a core curriculum covering AI fundamentals, ethics and discipline-specific applications that can be deployed across traditional university disciplines and leverages distance-learning to enable students to participate on their own schedule from anywhere with internet. The award also provides unprecedented access to some of the most advanced computational resources in the world while maintaining the flexibility to adapt to a rapidly-changing field by providing financial assistance supporting the development of new courses and undergraduate research in academic, industry and community studies. It is expected that this approach of integrating "AI across the curriculum" will equip all interested students to equitably engage AI in their chosen discipline.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934721
Title: Collaborative Research: Knowledge Guided Machine Learning: A Framework for Accelerating Scientific Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: July 10, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $663,777
ARRA Amount: $
Investigator(s): Vipin Kumar kumar001@umn.edu (Principal Investigator) John Nieber (Co-Principal Investigator) Michael Steinbach (Co-Principal Investigator) 
Organization: University of Minnesota-Twin Cities
200 OAK ST SE # 224, MINNEAPOLIS, MN 55455-2009, (612)624-5599
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The success of machine learning (ML) in many applications where large-scale data is available has led to a growing anticipation of similar accomplishments in scientific disciplines. The use of data science is particularly promising in scientific problems involving processes that are not completely understood. However, a purely data-driven approach to modeling a physical process can be problematic. For example, it can create a complex model that is neither generalizable beyond the data on which it was trained nor physically interpretable. This problem becomes worse when there is not enough training data, which is quite common in science and engineering domains.  A machine learning model that is grounded by explainable theories stands a better chance at safeguarding against learning spurious patterns from the data that lead to non-generalizable performance. This is especially important when dealing with problems that are critical and associated with high risks (e.g., extreme weather or collapse of an ecosystem).  Hence, neither an ML-only nor a scientific knowledge-only approach can be considered sufficient for knowledge discovery in complex scientific and engineering applications. This project is developing novel techniques to explore the continuum between knowledge-based and ML models, where both scientific knowledge and data are integrated synergistically. Such integrated methods have the potential for accelerating discovery in a range of scientific and engineering disciplines. This project will train interdisciplinary scientists who are well versed in such methods and will disseminate results of the project via peer-reviewed publications, open-source software, and a series of workshops to engage the broader scientific community.<br/><br/>This project aims to develop a framework that uses the unique capability of data science models to automatically learn patterns and models from data, without ignoring the treasure of accumulated scientific knowledge. Specifically, the project builds the foundations of knowledge-guided machine learning (KGML) by exploring several ways of bringing scientific knowledge and machine learning models together using pilot applications from four domains: aquatic ecodynamics, climate and weather, hydrology, and translational biology. These pilot applications were selected because they are at tipping points where knowledge-guided machine learning can have a transformative effect.  KGML has the potential for providing scientists and engineers with new insights into their domains of interest and will require the development of innovative new machine learning approaches and architectures that can incorporate scientific principles. Scientific knowledge, KGML methods, and software developed in this project could potentially be extended to a wide range of scientific applications where mechanistic (also known as process-based) models are used.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2118240
Title: HDR Institute: Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2021
Latest Amendment Date: September 15, 2021
Award Instrument: Cooperative Agreement
Program Manager: Amy Walton
Start Date: October 01, 2021
End Date: September 30, 2026
Awarded Amount to Date: $4,000,000
ARRA Amount: $
Investigator(s): Tanya Berger-Wolf berger-wolf.1@osu.edu (Principal Investigator) Henry Bart (Co-Principal Investigator) Hilmar Lapp (Co-Principal Investigator) Charles Stewart (Co-Principal Investigator) Anuj Karpatne (Co-Principal Investigator) 
Organization: Ohio State University
1960 KENNY RD, COLUMBUS, OH 43210-1016, (614)688-8735
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 1165 9102
Program Element Code(s): 099Y
Abstract: The traits that characterize living organisms, in particular, their morphology, physiology, behavior and genetic make-up, enable them to cope with forces of the physical as well as the biological and social environments that impinge on them. Moreover, since function follows form, traits provide the raw material upon which natural selection operates, thus shaping evolutionary trajectories and the history of life. Interestingly, most living organisms, from microscopic microbes to charismatic megafauna, reveal themselves visually and are routinely captured in copious images taken by humans from all walks of life.   The resulting massive amount of image data has the potential to further understanding of how multifaceted traits of organisms shape the behavior of individuals, collectives, populations, and the ecological communities they live in, as well as the evolutionary trajectories of the species they comprise. Images are increasingly the currency for documenting the details of life on the planet, and yet traits of organisms, known or novel, cannot be readily extracted from them. Just like with genomic data two decades ago, our ability to collect data far outstrips our ability to extract biological insight from it. The Institute will establish a new field of Imageomics, in which biologists utilize machine learning (ML) algorithms to analyze vast stores of existing image data?especially publicly funded digital collections from national centers, field stations, museums and individual laboratories?to characterize patterns and gain novel insights on how function follows form in all areas of biology to expand our understanding of the rules of life on Earth and how it evolves. <br/><br/>This Institute will introduce structured knowledge from the biological sciences to guide and structure ML algorithms to enable biological trait discovery from images, establishing the field of Imageomics. With images captured and annotated by scientists and the public serving as the basis for the work, the Institute?s convergent approach uses structured biological knowledge to provide scientifically validated inductive biases and rich supervision for ML, and ML will in turn enrich the body of biological knowledge. The resulting ML models and tools will help to make what was hidden visible, so that scientists from a wide range of biological communities can discover and infer the traits of organisms; assess shared similarities and differences between individuals, populations, and species; and come to see the world in new ways. Imageomics will accelerate and transform the biomedical, agricultural, and basic biological sciences as they seek to understand and control genes that relate to specific phenotypes and enable an overarching understanding of how the genome evolved in tandem with the organismal phenome. Because traits are the essential links between genes and the environment, using ML to help characterize them will lead to emergent understandings of how they function.  Harnessing the insights that arise from these new visualizations will stimulate the use of new genetic technologies, such as CRISPR gene editing, and more nuanced ecological practices, such as modified land use schemes that emerge from better understanding the connections between individual decision-making within species and their impact on their population dynamics.  With the emergence of new and better targeted practices that generate fewer unintended consequences, the new linkages resulting from a better understanding of traits and their consequences will bolster the nation?s bioeconomy. In addition, by leveraging and expanding existing diverse, inclusive and intellectually wide-ranging collaborative networks, the Institute will also educate the next generation of scientists and engage the broader public in scientific inquiry and knowledge discovery so that Imageomics can transform and democratize science for public good.<br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR).  This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Biological Infrastructure within the NSF Directorate for Biological Sciences, and by the Division of Information and Intelligent Systems within the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741306
Title: BIGDATA: IA: Predictive Analytics of Driver's Engagement for Injury Prevention
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 17, 2017
Latest Amendment Date: June 13, 2022
Award Instrument: Standard Grant
Program Manager: Wendy Nilsen
Start Date: January 01, 2018
End Date: December 31, 2023
Awarded Amount to Date: $1,015,993
ARRA Amount: $
Investigator(s): Bhupesh Shetty bhupesh.shetty@drexel.edu (Principal Investigator) Christopher Yang (Former Principal Investigator) Helen Loeb (Co-Principal Investigator) Weimao Ke (Co-Principal Investigator) Santiago Ontanon (Co-Principal Investigator) Sheila Klauer (Co-Principal Investigator) Jonathan Antin (Former Co-Principal Investigator) 
Organization: Drexel University
3141 CHESTNUT ST, PHILADELPHIA, PA 19104-2816, (215)895-6342
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7364 7433 8083 9251
Program Element Code(s): 8083
Abstract: Over 30,000 people are killed in motor vehicle crashes on US roadways every year. Driver distraction from secondary in-vehicle activities, particularly among young drivers, has emerged as a major cause of motor vehicle crashes. A substantial amount of research has been focused on analyzing small sets of naturalistic driving or simulated data to study a small number of features for detecting the driver's engagement. However, many meaningful dependencies and patterns can only be discovered by large collections of data. In this project, the goal is leveraging the two petabytes federal database of naturalistic driving data to develop predictive analytics for detecting a driver's disengagement from the driving tasks in order to provide alerts to drivers and reduce the risk of motor vehicle crashes. <br/><br/>In this project, data pre-processing techniques are investigated for the large volume of heterogeneous data with over 100 variables in Strategic Highway Research Program 2 (SHRP 2). Two scalable predictive analytics algorithm families based on instance-based learning and heterogeneous network mining for predictive modeling are developed. In addition, a novel distributed computing infrastructure to support the scalable predictive analytics in performing pattern mining of driving behavior analysis, modeling, and prediction are developed. The research outcomes of this project shed a significant amount insight into current work of injury prevention due to motor vehicle crashes. The project extends the capability of machine learning, sensor informatics, and driving behavior analytics. The integrated education plan includes incorporating the research findings in courses offered at the Master of Science program in Health Informatics. The outreach plan involves organizing workshops, conferences, and seminars to disseminate the research outcomes.

Award Number: 2023755
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: March 16, 2020
Latest Amendment Date: March 16, 2020
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: January 20, 2020
End Date: September 30, 2022
Awarded Amount to Date: $254,633
ARRA Amount: $
Investigator(s): Lan Wang lanwang@mbs.miami.edu (Principal Investigator) 
Organization: University of Miami
1320 S DIXIE HWY STE 650, CORAL GABLES, FL 33146-2919, (305)284-3924
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939945
Title: Collaborative Research: Converging Genomics, Phenomics, and Environments Using Interpretable Machine Learning Models
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $299,520
ARRA Amount: $
Investigator(s): Remco Chang remco@cs.tufts.edu (Principal Investigator) 
Organization: Tufts University
169 HOLLAND ST FL 3, SOMERVILLE, MA 02144-2401, (617)627-3696
NSF Directorate: CSE
Program(s): ICB: Infrastructure Capacity f HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 1165
Program Element Code(s): 085Y, 099Y
Abstract: Mitigating the effects of climate change on public health and conservation calls for a better understanding of the dynamic interplay between biological processes and environmental effects. The state-of-the-art, which has led to many important discoveries, utilizes numerical or statistical models for making predictions or performing in silico experimentation, but these techniques struggle to capture the nonlinear response of natural systems. Machine learning (ML) methods are better able to cope with nonlinearity and have been used successfully in biological applications, but several barriers still exist, including the opaque nature of the algorithm output and the absence of ML-ready data. This project seeks to significantly advance technologies in ML and create a new interdisciplinary field, computational ecogenomics. This will be accomplished by designing ML techniques for encoding heterogeneous genomic and environmental data and mapping them to multi-level phenotypic traits, reducing the amount of necessary training data, and then developing interactive visualizations to better interpret ML models and their outputs.  These advances will responsibly and transparently inform policy to maximize resources during this crucial window for planetary health, while revealing underlying biological mechanisms of response to stress and evolutionary pressure.<br/><br/>The long-term vision for this project is to develop predictive analytics for organismal response to environmental perturbations using innovative data science approaches and change the way scientists think about gene expression and the environment. The goal for this two-year award is to develop a proof-of-concept for an institute focused on predicting emergent properties of complex systems; an institute that would itself foster the development of many new sub-disciplines.  The core of this activity is developing a machine learning framework capable of predicting phenotypes based on multi-scale data about genes and environments.  Available data, ranging from simple vectors to complex images to sequences, will be ingested into this framework by applying proven semantic data integration tools and algorithmic data transformation methods.  The central hypothesis of this research is that deep learning algorithms and biological knowledge graphs will predict phenotypes more accurately across more taxa and more ecosystems than do current numerical and traditional statistical modeling methods.  The rationale for this project is that a timely investment in data science will push through a bottleneck in life science, accelerating discovery of gene-phenotype-environment relationships, and catalyzing a new computational discipline to uncover the complex "rules of life."<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1947584
Title: BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 23, 2019
Latest Amendment Date: September 23, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $589,294
ARRA Amount: $
Investigator(s): Maryam Rahnemoonfar maryam@umbc.edu (Principal Investigator) 
Organization: University of Maryland Baltimore County
1000 HILLTOP CIR, BALTIMORE, MD 21250-0001, (410)455-3140
NSF Directorate: CSE
Program(s): Polar Cyberinfrastructure EarthCube Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9102
Program Element Code(s): 5407, 8074, 8083
Abstract: The objective of this research is to investigate artificial intelligence (AI) solutions for data collected by the Center for Remote Sensing of Ice Sheets (CReSIS) in order to provide an intelligent data understanding to automatically mine and analyze the heterogeneous dataset collected by CReSIS. Significant resources have been and will be spent in collecting and storing large and heterogeneous datasets from expensive Arctic and Antarctic fieldwork (e.g. through NSF Big Idea: Navigating the New Arctic). While traditional analyses provide some insight, the complexity, scale, and multidisciplinary nature of the data necessitate advanced intelligent solutions. This project will allow domain scientists to automatically answer questions about the properties of the data, including ice thickness, ice surface, ice bottom, internal layers, ice thickness prediction, and bedrock visualization. The planned approach will advance the broader big data research community by improving the efficiency of deep learning methods and in the investigation of methods to merge data-driven AI approaches with application-specific domain knowledge. Special attention will be given to women and minority involvement in the research and the project will develop new course materials for several classes in AI at a Hispanic and minority serving institute.<br/><br/>In polar radar sounder imagery, the delineation of the ice top and ice bottom and layering within the ice is essential for monitoring and modeling the growth of ice sheets and sea ice. The optimal approach to this problem should merge the radar sounder data with physical ice models and related datasets such as ice coverage and concentration maps, spatiotemporal meteorological maps, and ice velocity. Rather than directly engineering specific relations into the image analysis that require many parameters to be defined and tuned, data-dependent approaches let the machine learn these relationships. To devise intelligent solutions for navigating the big data from the Arctic and Antarctic and to scale up the current and traditional techniques to big data, this project plans several approaches for detecting ice surface, bottom, internal layers, 3D modeling of bedrock and spatial-temporal monitoring of the ice surface: 1) Devise new methodologies based on hybrid networks combining machine learning with traditional domain specific knowledge and transforming the entire deep learning network to the time-frequency domain. 2) Equip the machine with information that is not visible to the human eye or that is hard for a human operator to consider simultaneously, to be able to detect internal layers and 3D basal topography on a large scale. Using the results of the feature tracking of the ice surface in radar altimetry, the research effort will also develop new data-dependent techniques for predicting the ice thickness for following years based on deep recurrent neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934584
Title: Collaborative Research: Physics-Based Machine Learning for Sub-Seasonal Climate Forecasting
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $297,347
ARRA Amount: $
Investigator(s): Pradeep Ravikumar pradeepr@cs.cmu.edu (Principal Investigator) 
Organization: Carnegie-Mellon University
5000 FORBES AVE, PITTSBURGH, PA 15213-3815, (412)268-8746
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: While the past few decades have seen major advances in weather forecasting on time scales of days to about a week, making high quality forecasts of key climate variables such as temperature and precipitation on sub-seasonal time scales, the time range between 2 weeks and 2 months, continues to challenge operational forecasters. Skillful climate forecasts on sub-seasonal time scales would have immense societal value in areas such as agricultural productivity, hydrology and water resource management, transportation and aviation systems, and emergency planning for extreme events such as Atlantic hurricanes and midwestern tornadoes. In spite of the scientific, societal, and financial importance of sub-seasonal climate forecasting, progress on the problem has been limited. The project has initiated a systematic investigation of physics-based machine learning with specific focus on advancing sub-seasonal climate forecasting. In particular, this project is developing novel machine learning (ML) approaches for sub-seasonal forecasting by leveraging both limited observational data as well as vast amounts of dynamical climate model output data. Further, the project is focusing on improving the dynamical climate models themselves based on ML with specific emphasis on learning model parameterizations suitable for accurate sub-seasonal forecasting. The principles, models, and methodology for physics-based machine learning being developed in the project will benefit other scientific domains which rely on dynamical models. The project is establishing a public repository of a benchmark dataset for sub-seasonal forecasting to engage the wider data science community and accelerate progress in this critical area. The project is training a new generation of interdisciplinary scientists who can cross the traditional boundaries between computer science, statistics, and climate science.<br/><br/>The project works with two key sources of data for sub-seasonal forecasting: limited amounts of observational data and vast amounts of output data from dynamical model simulations, which capture physical laws and dynamics based on large coupled systems of partial differential equations (PDEs). The project is investigating the following central question: what is the best way to learn simultaneously from limited observational data and imperfect dynamical models for improving sub-seasonal forecasts? The project is building a framework for physics-based machine that has two inter-linked components: (1) deduction, in which ML models are trained on dynamical model outputs as well as limited observations, and (2) induction, in which ML models are used to improve dynamical models. Across the two components, the project is making fundamental advances in learning representations, functional gradient descent, transfer learning, derivative-free optimization and multi-armed bandits, Monte Carlo tree search, and block coordinate descent. On the climate side, the project is building an idealized dynamical climate model and doing an in depth investigation on learning suitable parameterizations for the dynamical model with ML methods to improve forecast accuracy in the sub-seasonal time scales. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940263
Title: Collaborative Research:  Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $325,000
ARRA Amount: $
Investigator(s): Peter Crozier crozier@asu.edu (Principal Investigator) 
Organization: Arizona State University
660 S MILL AVE STE 312, TEMPE, AZ 85281-3670, (480)965-5479
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2118329
Title: HDR Institute: Geospatial Understanding through an Integrative Discovery Environment
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2021
Latest Amendment Date: September 15, 2021
Award Instrument: Cooperative Agreement
Program Manager: Amy Walton
Start Date: October 01, 2021
End Date: September 30, 2026
Awarded Amount to Date: $6,845,994
ARRA Amount: $
Investigator(s): Shaowen Wang shaowen@illinois.edu (Principal Investigator) Mohan Ramamurthy (Co-Principal Investigator) Deanna Hence (Co-Principal Investigator) Xiaohui Carol Song (Co-Principal Investigator) David Tarboton (Co-Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Hydrologic Sciences XC-Crosscutting Activities Pro CYBERINFRASTRUCTURE Info Integration & Informatics CZO-Critical Zone Obsrvatories 
Program Reference Code(s): 054Z 062Z 5294 7231 8400 9102
Program Element Code(s): 099Y, 1579, 7222, 7231, 7364, 7693
Abstract: This project establishes the Institute for Geospatial Understanding through an Integrative Discovery Environment (I-GUIDE). In today?s interconnected world, disasters such as floods and droughts are rarely isolated events, and their cascading effects are often felt far beyond their locations of origin. I-GUIDE creates an integrative discovery environment that enables the harnessing of geospatial data for understanding interconnected interactions across diverse socioeconomic-environmental systems to enhance community resilience and environmental sustainability. I-GUIDE nurtures a diverse and inclusive geospatial discovery community across many disciplines by bridging disciplinary digital data divides with broader impacts amplified through a well-trained and diverse workforce and proactive engagement of minority and underrepresented groups. The project leverages existing collaborations with its diverse member and partner organizations, representing academic, governmental, and industrial institutions, thereby extending its reach across the U.S. and the globe. The influence of I-GUIDE?s new knowledge frontiers impact solutions to real-world problems and geospatial decisions, with significance ranging from the nation?s economic development to security. I-GUIDE builds upon relationships with the museum and informal science education communities as well as libraries and news media to raise public awareness about the contributions of the geospatial data revolution to society. <br/><br/>Globalization has intensified and extended the impacts of socioeconomic-environmental interactions across long distances, a process known as telecoupling. I-GUIDE?s integrative discovery environment is vital to transform innovative theories, concepts, methods, and tools focusing geospatial synthesis that drive novel capabilities for addressing scientific questions of how to harness geospatial data for multi-scale and telecoupling discoveries to enhance community resilience and environmental sustainability. Two substantive and convergent scientific problems are addressed: (1) Water security, to evaluate geospatial and socioeconomic impacts of hydroclimatic extremes that are related to environmental and infrastructure sustainability, and (2) Biodiversity and food security, to enhance basic understanding of biodiversity dynamics in the face of nearby and distant disasters, global changes, international trade, and dynamic land use transitions. Transformative geospatial understanding gained from solving these interrelated problems are translated into digital resources and tools made available online through an open I-GUIDE platform for a variety of educational and training activities to serve a broad and diverse audience. Through this platform, the next-generation workforce can acquire geospatial knowledge coupled with data-driven technological skills for decision-making and problem-solving experiences. <br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR).  The award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Behavioral and Cognitive Sciences, the Division of Social and Economic Sciences, and the Office of Multidisciplinary Activities within the Directorate for Social, Behavioral and Economic Sciences; the Division of Earth Sciences within the Directorate for Geosciences; the Division of Mathematical Sciences within the Directorate for Mathematical and Physical Sciences, and by the Division of Information and Intelligent Systems within the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838139
Title: BIGDATA: F: Privacy in Unsupervised Learning
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 11, 2018
Latest Amendment Date: November 23, 2020
Award Instrument: Standard Grant
Program Manager: Ralph Wachter
Start Date: October 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $911,398
ARRA Amount: $
Investigator(s): Raman Arora arora@cs.jhu.edu (Principal Investigator) 
Organization: Johns Hopkins University
3400 N CHARLES ST, BALTIMORE, MD 21218-2608, (443)997-1898
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Modern data sets are largely unlabeled. Unsupervised learning of useful representations to better understand the structure in data is a critical challenge in data science and machine learning; it finds application in computational and social science, including information retrieval, web mining, and recommendation systems. As we progress further into the age of Big data, and the amount of data to be processed grows faster than the growth in our computational resources, better and faster ways for performing unsupervised learning and data analysis on such big data sets become ever more necessary. Furthermore, with the advent of the internet of things, private data is collected rather ubiquitously and seamlessly through devices such as smartphones, cameras, microphones, radio-frequency identification (RFID) readers, and social networks, raising serious concerns about an individual's privacy. Therefore, in this project, we initiate a formal investigation into privacy-aware unsupervised learning for Big data applications.<br/><br/>Taking a stochastic optimization view of unsupervised learning, we capture more general learning problems than previously studied in the privacy literature. One such class of learning problems is non-convex problems, such as matrix learning, tensor factorization, deep learning, and many more. While most of these problems are NP-hard, in practice we find that we can efficiently find solutions to these problems. We conjecture that noisy stochastic gradient descent updates that have recently been shown to efficiently find local minima for a large class of non-convex problems also guarantees privacy implicitly. Finally, we consider extensions of the privacy model from that of a single curator to those to distributed learning, continual release model, streaming model, and a novel sliding window model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838154
Title: BIGDATA: F: Big Data Analysis via Non-Standard Property Testing
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2018
Latest Amendment Date: September 08, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $910,000
ARRA Amount: $
Investigator(s): Rocco Servedio rocco@cs.columbia.edu (Principal Investigator) Xi Chen (Co-Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: In the modern era truly enormous amounts of data are constantly being generated across a wide range of domains: these include ongoing large-scale scientific experiments, ubiquitous smartphones and sensors, the continuous production and evolution of content on social media, and many others.  How can this flood of data be efficiently processed and analyzed?  A branch of computer science called "property testing" seeks to develop ultra-fast algorithms for analyzing massive data sets to quickly determine whether or not the data has some property of interest.  However, the standard theoretical models that have mostly been considered in property testing are not well suited to many real-world data analysis scenarios; these standard models prioritize mathematical elegance, but the resulting assumptions they make do not align well with the abilities of actual data analysis algorithms or with the nature of many actual data sets.  (As one example, these models typically assume that a data analysis algorithm can synthesize arbitrary data points and query them to receive accurate information about how such data points should be labeled, but such queries are impossible in many real-world settings where data points "come as they are" and cannot be synthesized to meet the specifications of a data analyst.  As another example, these models typically can only deal with data which is assumed to follow certain highly structured probability distributions, but real-world data is messy and rarely possesses such a high degree of structure.)  The high-level goal of this project is to develop and analyze non-standard models of property testing, with the explicit goal of developing algorithms which align with the realities and constraints of real-world data analysis problems.  An important related goal is to foster human resource development by performing outreach and training graduate students, including members of historically under-represented groups, in the analytic and algorithmic techniques that are central to this project.  Planned activities to achieve broader impacts also include new courses, survey articles, and the continuation of outreach activities aimed at students at the elementary and middle school levels.<br/><br/>In more detail, the project will focus on three different aspects of property testing algorithms for big data, all of which are motivated by considerations arising from real-world data analysis:(1) The first focus of the project will be on developing flexible algorithms for testing whether a massive high-dimensional data set has been labeled according to a "junta" --- this is a labeling rule which depends only on a very small but unknown set of data features out of a huge set of possible features.  Building on their previous work, the investigators will work to develop junta testing algorithms which can handle arbitrary data distributions and noisy data, and can succeed even given only a limited form of access to the data set being analyzed. (2) The second focus of the project will be on transferring ideas and techniques from theoretical machine learning algorithms to the domain of property testing of massive data sets.  Previous work of the investigators gave a proof-of-concept for how (certain relatively inefficient) machine learning algorithms can be modified to yield far more efficient property testing algorithms for data analysis, but this transfer went through only in the relatively constrained standard models of property testing, alluded to above, which assume highly structured data distributions.  In this project the investigators will work to extend these earlier results so that the machine learning techniques will yield algorithms for more flexible property testing models that are of greater real-world applicability.(3) Finally, the third focus of the project is to develop property testing algorithms which do not need to make queries on synthetic data points but instead use only random samples, and which can be applied to high-dimensional continuous data sets.  Data of this type arises commonly in settings where sensors or measurements of different sorts are generating the data, but most property testing algorithms are designed for discrete binary-valued data rather than continuous data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837821
Title: BIGDATA: IA: Collaborative Research: Data-Driven, Multi-Scale  Design of Liquid Crystals for Wearable Sensors for  Monitoring Human Exposure and Air Quality
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Christina Payne
Start Date: September 15, 2018
End Date: August 31, 2023
Awarded Amount to Date: $656,531
ARRA Amount: $
Investigator(s): Nicholas Abbott nabbott@cornell.edu (Principal Investigator) 
Organization: Cornell University
341 PINE TREE RD, ITHACA, NY 14850-2820, (607)255-5014
NSF Directorate: CSE
Program(s): Special Initiatives Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 1642, 8083
Abstract: Liquid crystals are responsive materials that can be used to manufacture low-cost and highly selective chemical sensors. Liquid crystals provide a potentially scalable approach toward deploying millions of wearable chemical sensors (e.g., in mobile phones or attached to clothing) that collect high-resolution data on human exposure to toxic contaminants in the air. This information is key to understanding health-risks associated with air quality, developing industrial practices that minimize workers' exposure to hazardous environments, and detecting point sources (e.g., fabrication of explosives). Liquid crystal sensors work by amplifying events that occur at the molecular-level into an optical signal when the sensor is exposed to a chemical environment. The amplification process involves a sequence of tightly coupled phenomena spanning multiple length and time scales. This span in scales lies beyond what is currently possible to characterize, model, and predict directly from first principles. This project seeks to combine first-principles and data-driven methodologies to overcome this technical challenge. The methods developed will enable the prediction of the influence of liquid crystal design variables on the information content of optical signals and will lead to a revolutionary impact on chemical sensing technologies and on the design of functional materials. The multidisciplinary nature of this project will train a new generation of engineers in the integration of data science into the design and analysis of advanced functional materials. K-12 students and the public will be engaged through development of hands-on liquid crystal sensors that respond to model target chemicals (e.g., carbon dioxide from sodas).<br/><br/>The project will investigate scalable machine learning techniques that enable the efficient use of large sets of experimental and first-principles simulation data to uncover and understand multi-scale phenomena that govern the performance of liquid crystals. Specifically, the project goals are to: i) Investigate the use of density functional theory and molecular dynamics simulations to identify nanoscale descriptors of the underlying spatiotemporal events occurring within and at liquid crystal interfaces (e.g., binding energies), ii) Establish feature extraction techniques to identify suitable macroscale descriptors of liquid crystal optical signals (e.g., optical response times and texture fields), and iii) Develop machine learning techniques that enable the creation of multi-scale models capable of mapping nanoscale and macroscale descriptors. These capabilities will be combined in a reinforcement learning framework that will help guide experimental data collection and identification of innovative liquid crystal system designs. The ultimate engineering goal of the project is to design LC sensors to infer exposure events involving carbon monoxide, ozone, and nitrogen and sulfur oxide.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837992
Title: BIGDATA: F: Collaborative Research: Moment Methods for Big Data: Modern Theory, Algorithms, and Applications
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: September 07, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2018
End Date: September 30, 2022
Awarded Amount to Date: $1,000,000
ARRA Amount: $
Investigator(s): Amit Singer amits@math.princeton.edu (Principal Investigator) 
Organization: Princeton University
1 NASSAU HALL, PRINCETON, NJ 08544-2001, (609)258-3090
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: Modern scientific disciplines are increasingly faced with datasets of ever larger size and complexity. Experimental observations may be marred by inaccurate measurements and missing values, and the sheer volume of the output of modern high-throughput experimental procedures in the life sciences makes data processing an increasing challenge. Drawing accurate scientific inferences from such data requires developing new tools that are both theoretically sound and computationally efficient. This project aims to develop statistical methodologies for uncovering the intrinsic structure in large, complex data. The planned methods have the potential to become the default data science techniques used in many scientific and engineering disciplines. Fast, user-friendly software will be made publicly available, both for general purpose big data analysis and specific scientific applications.<br/><br/>The first pillar of the planned methodology is principal component analysis (PCA). The investigators are extending the use of PCA to the setting of high-dimensional observations with corrupted observations, non-Gaussian noise, and low signal-to-noise ratios. These kinds of datasets arise in problems such as cryo-electron microscopy and X-ray free electron laser imaging. This work will provide robust tools for exploratory data analysis for these problems. The second pillar of the research program is the method of moments, a classical technique for parameter estimation that the investigators have repurposed for new problems. The investigators will extend the range of applicability of the method of moments to many big data problems that exhibit certain algebraic structure. For these problems, the method of moments enables scalable and near-optimal statistical inference. Finally, the novel extensions of PCA and the method of moments will be combined to derive new near-optimal and scalable statistical inference procedures for high-dimensional problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934637
Title: Collaborative Research: Physics-Based Machine Learning for Sub-Seasonal Climate Forecasting
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $352,620
ARRA Amount: $
Investigator(s): Rebecca Willett willett@g.uchicago.edu (Principal Investigator) 
Organization: University of Chicago
5801 S ELLIS AVE, CHICAGO, IL 60637-5418, (773)702-8669
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: While the past few decades have seen major advances in weather forecasting on time scales of days to about a week, making high quality forecasts of key climate variables such as temperature and precipitation on sub-seasonal time scales, the time range between 2 weeks and 2 months, continues to challenge operational forecasters. Skillful climate forecasts on sub-seasonal time scales would have immense societal value in areas such as agricultural productivity, hydrology and water resource management, transportation and aviation systems, and emergency planning for extreme events such as Atlantic hurricanes and midwestern tornadoes. In spite of the scientific, societal, and financial importance of sub-seasonal climate forecasting, progress on the problem has been limited. The project has initiated a systematic investigation of physics-based machine learning with specific focus on advancing sub-seasonal climate forecasting. In particular, this project is developing novel machine learning (ML) approaches for sub-seasonal forecasting by leveraging both limited observational data as well as vast amounts of dynamical climate model output data. Further, the project is focusing on improving the dynamical climate models themselves based on ML with specific emphasis on learning model parameterizations suitable for accurate sub-seasonal forecasting. The principles, models, and methodology for physics-based machine learning being developed in the project will benefit other scientific domains which rely on dynamical models. The project is establishing a public repository of a benchmark dataset for sub-seasonal forecasting to engage the wider data science community and accelerate progress in this critical area. The project is training a new generation of interdisciplinary scientists who can cross the traditional boundaries between computer science, statistics, and climate science.<br/><br/>The project works with two key sources of data for sub-seasonal forecasting: limited amounts of observational data and vast amounts of output data from dynamical model simulations, which capture physical laws and dynamics based on large coupled systems of partial differential equations (PDEs). The project is investigating the following central question: what is the best way to learn simultaneously from limited observational data and imperfect dynamical models for improving sub-seasonal forecasts? The project is building a framework for physics-based machine that has two inter-linked components: (1) deduction, in which ML models are trained on dynamical model outputs as well as limited observations, and (2) induction, in which ML models are used to improve dynamical models. Across the two components, the project is making fundamental advances in learning representations, functional gradient descent, transfer learning, derivative-free optimization and multi-armed bandits, Monte Carlo tree search, and block coordinate descent. On the climate side, the project is building an idealized dynamical climate model and doing an in depth investigation on learning suitable parameterizations for the dynamical model with ML methods to improve forecast accuracy in the sub-seasonal time scales. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934985
Title: HDR TRIPODS: Collaborative Research: Foundations of Greater Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 10, 2019
Latest Amendment Date: September 08, 2021
Award Instrument: Continuing Grant
Program Manager: Huixia Wang
Start Date: September 15, 2019
End Date: August 31, 2023
Awarded Amount to Date: $685,835
ARRA Amount: $
Investigator(s): David Matteson dm484@cornell.edu (Principal Investigator) David Bindel (Co-Principal Investigator) Qing Zhao (Co-Principal Investigator) Aaron Wagner (Co-Principal Investigator) Gennady Samorodnitsky (Co-Principal Investigator) 
Organization: Cornell University
341 PINE TREE RD, ITHACA, NY 14850-2820, (607)255-5014
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The University of Rochester and Cornell University jointly establish the Greater Data Science Cooperative Institute (GDSC). The GDSC is based on two founding tenets. The first is that enduring advances in data science require combining techniques and viewpoints across electrical engineering, mathematics, statistics, and theoretical computer science. The investigators' goal is to forge a consensus perspective on data science that transcends any individual field. The second is that data-science research must be grounded in an application domain. This helps to ensure that assumptions about the availability and quality of data are realistic, and it allows methodological results to be tested experimentally as well as theoretically. As such, the GDSC aims to consider applications in medicine and healthcare, an important application domain and one for which advances in data science can have a direct, positive impact on society. The GDSC aims to tackle foundational questions that are motivated by problems in healthcare, obtain solutions that fuse domain expertise with application-agnostic methodologies, and ultimately yield scientific advances that impact the way healthcare is provided. The GDSC aims to leverage the physical proximity of the two institutions, and the unique strengths in each of the core disciplines above and in medicine.<br/><br/>The GDSC's cross-disciplinary research directions include: (i) Topological Data Analysis. The challenges that high-dimensional, incomplete, and noisy data present are great, but in many applications, exploiting the topological nature of the problem is possible. GDSC aims to develop new fundamental methods and theory to rigorously explore the promise of this unique approach. (ii) Data Representation. Data compression, embeddings, and dimension reduction play a fundamental role in data science. Inspired by new core challenges in biomedical imaging, genomics, and neural-spike training data, GDSC aims to develop novel source models and distortion measures, and ultimately seek a unifying theoretical framework across domains and disciplines. (iii) Network & Graph Learning. Many of the fundamental challenges in applying data science to non-homogeneous populations are best explored through a network or graph structure. GDSC aims to develop new techniques for parameter-dependent eigenvalue problems in spectral community detection, density-estimation methods on networks, and a theoretical framework for time-varying graphical models to study dynamic variable relations in time-evolving networks. (iv) Decisions, Control & Dynamic Learning. Sequential decisions are high-stakes in medicine. GDSC aims to utilize systems and control-engineering methods to improve health and disease management and develop new foundational theories and methods for label-efficient active learning and dynamic treatment regimes. (v) Diverse & Complex Modalities. Big data is complex data, and major new innovations are needed. GDSC aims to develop theoretical frameworks for inference under computational and privacy constraints and for high-dimensional data without parametric model assumptions. Text, image, and audio data present further challenges. To address such challenges, GDSC aims to explore transition systems for graph parsing of natural language and new fusion approaches for fully multimodal analysis. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1546296
Title: BIGDATA: Collaborative Research: IA: Hardware and Software for Spike Detection and Sorting in Massively Parallel Electrophysiological Recording Systems for the Brain
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 16, 2015
Latest Amendment Date: June 09, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2015
End Date: September 30, 2022
Awarded Amount to Date: $898,000
ARRA Amount: $
Investigator(s): Kenneth Shepard shepard@ee.columbia.edu (Principal Investigator) Liam Paninski (Co-Principal Investigator) Luca Carloni (Co-Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): Big Data Science &Engineering IntgStrat Undst Neurl&Cogn Sys 
Program Reference Code(s): 7433 8083 8089 8091 9251
Program Element Code(s): 8083, 8624
Abstract: Understanding how the brain works is arguably one of the most significant scientific challenges of our time and the focus of the BRAIN initiative. It is widely believed that neural circuit function is emergent, the result of complex interactions between constituents with individual neurons forming synaptic connections with thousands of other neurons. Mapping of these complex circuits has been virtually impossible because of the reliance on electrophysiological recordings which sample these networks extremely sparsely. These tools for extracellular spike recordings are only able to simultaneously record from several tens to a few hundred neurons. Raw signals from these recording electrodes are first filtered to remove out-of-band signals. Putative spike events are then detected and extracted. Finally, these snippets of time-series event are sorted, typically on the basis of waveform shapes, into clusters. Even at the very modest bandwidths for these systems, computing systems struggle to save the data and process the resulting data sets. Scalability of these measurement techniques by many orders of magnitude in recording density and channels will be essential to future progress in understanding neuron circuits.<br/><br/>This project is exploiting emerging electrophysiological recording systems in which the electrode (and channel) count is increased by almost three orders of magnitude over conventional systems with data bandwidths exceeding 1GB/sec. To handle these data bandwidths and resulting data volumes and deliver scalability, this project will develop dedicated hardware and associated algorithms for spike detection and sorting that allow these tasks to be performed in real-time in close proximity to the recording system. Compression by more than three orders of magnitude is possible by these means by taking advantage of the special spatiotemporal local structure in these data sets; by exploiting strong prior information about the spiking signal and reducing the dimensionality of the problem accordingly; and by adapting and extending modern scalable nonparametric Bayesian inference methods. In addition to providing important new tools for neuroscience, the tools developed here for scalable real-time event detection and annotation have broad applicability to other spatiotemporal data sets (or more generally, any data set comprising multiple streams of data, in which the streams could involve different data modalities) in which objects of interest are spatially and temporally localized with fixed spatial footprints. Examples abound in cell and molecular biology, particle and solid-state physics, financial monitoring,  monitoring of power networks, and sensor networks.

Award Number: 1940224
Title: Collaborative Research: Accelerating the Discovery of Electronic Materials through Human-Computer Active Search
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $305,855
ARRA Amount: $
Investigator(s): Roman Garnett garnett@wustl.edu (Principal Investigator) 
Organization: Washington University
ONE BROOKINGS DR, SAINT LOUIS, MO 63130-4862, (314)747-4134
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8249 8396 8611 9150
Program Element Code(s): 099Y, 1712
Abstract: The overarching goal of this project is to accelerate the discovery of  materials with tailored electronic properties through human-computer active search. These efforts will lay the groundwork for accelerating materials discovery, and advance the capability to control electronic properties in materials with the potential for profound societal impact. The thermoelectric and photocatalytic materials predicted, synthesized, and characterized in this research can realize societal advances in the space of energy and solar fuels. High-efficiency thermoelectric materials can revolutionize how heat sources are transformed into electrical power by eliminating the traditional intermediate mechanical energy conversions.  Earth-abundant  light-responsive catalysts are emerging as  an alternative to costly, rare metal catalysts to store solar energy as  portable liquid fuels, like ethanol. These green reactions  are enabling low-cost, carbon-neutral fuels.  The team brings together expertise in materials science, chemistry, machine learning, visualization, metadata, and knowledge frameworks to develop multi-fidelity, expert-guided active search strategies within materials science and chemistry.  Resonances among the team's existing outreach programs will broaden inclusion of students from underrepresented groups and be moderated via the Alliance for Diversity in Science and Engineering.  The work will provide cross-disciplinary training to graduate students and postdocs in all aspects of material informatics, including participating in and leading team efforts, co-mentorship of Ph.D.  and postdoctoral researchers, inclusive symposia at national conferences, and a summer workshop focused on the intersection of visualization, machine learning, ontological engineering and materials science. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative. <br/><br/>An interdisciplinary team will create a search framework for scientific discovery that leverages recent advances in material databases, machine learning, visualization, human-machine interaction, and knowledge structures. To broadly assess the efficacy of this approach, the search effort will span the electronic behavior of both molecules and crystalline materials:  (i) new organic photocatalysts for solar fuels production and (ii) new thermoelectric materials for electricity generation.  Central to this effort is the engagement of domain experts and associated feedback in a human-in-the-loop active search process. Dynamic visualizations will enable the user to (i) understand the underlying reasons why the materials are being suggested and (ii) provide a user steering capability to identify and annotate specific aspects of the explored search space. Domain-expert annotations and feedback will be parsed against a suite of ontologies, further aiding the search process by providing relational insight between features. New molecules and materials will be explored through a combination of first principles calculations and high-throughput, automated experimentation; these results will be incorporated into a continually growing open-access database. Efficiently integrating and directing evolving data-streams from experiment, computation, and human steering during the search will be achieved with a multi-fidelity active search policy. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940166
Title: Collaborative Research: Integrating Physics and Generative Machine-Learning Models for Inverse Materials Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $400,000
ARRA Amount: $
Investigator(s): Yifei Mo yfmo@umd.edu (Principal Investigator) 
Organization: University of Maryland, College Park
3112 LEE BLDG 7809 REGENTS DR, COLLEGE PARK, MD 20742-0001, (301)405-6269
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8396 8399
Program Element Code(s): 099Y, 1712
Abstract: This project is aimed to address a grand challenge in data-intensive materials science and engineering to find better materials with desired properties, often with the goal to enhance performance in specific applications. This project addresses this grand challenge with a specific focus on finding metal organic framework (MOF) materials that are used to separate gas mixtures and finding better battery materials for energy storage. The PIs will combine theoretical methods from statistical mechanics and condensed-matter physics, and physics-based models, to generate information-rich materials data which is integrated with generative machine learning (ML) algorithms to search a complex chemical design space efficiently and to train deep learning models for fast screening of materials properties. This project will be carried out by a multidisciplinary collaboration involving researchers from physics, materials science and engineering, computer science, and mathematics. The resulting multidisciplinary environment fosters training the next generation data savvy scientists who will engage in collaborative multidisciplinary research.  <br/><br/>Existing approaches for computational design of metal organic frameworks (MOF) and solid-state electrolyte materials are largely based on screening of known materials or enumerative search of hypothetical materials. This project develops a new approach that integrates first principles calculations, experimental data and abundant data generated by physics-based models to train generalized antagonistic network (GAN) models for efficient search of the materials design space, and to train deep convolutional neural network (DCNN) models for fast and accurate screening of properties of the GAN-generated candidate materials. Additionally, graph-based GAN models will be used for MOF topology exploration and can be applied to other nanomaterials designs. More specifically, the investigators will: 1) develop and exploit physics-based models for fast calculation of properties such as diffusivity, ion conductivity, and mechanical stability; 2) develop generative adversarial network (GAN) models with built-in physics rules for efficient exploration of the chemical design space for both MOF materials and solid electrolytes; 3) use persistence homology and Bravais lattice sequence representations of MOF materials and solid electrolytes, respectively, to build Deep Convolutional Neural Network (DCNN) models for fast and accurate prediction of the physical properties of generated materials; 4)  apply high-level quantum-mechanical calculations for verification of discovered materials. Accomplishments from this project will lead to accelerated discovery of novel nanostructured materials for gas separation and energy storage, materials for lithium-ion batteries, novel data-driven scheme for materials design, and theoretical methods enabling implementation of advanced data science techniques. The highly interdisciplinary collaboration will offer students unique opportunities to interact with a variety of disciplines, and training the next-generation scientists with the mindset for multidiscipline collaborations. Educational and outreach activities will be developed and undertaken in conjunction with the proposed research activities.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940175
Title: Collaborative Research: Accelerating the Discovery of Electronic Materials through Human-Computer Active Search
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $231,838
ARRA Amount: $
Investigator(s): Remco Chang remco@cs.tufts.edu (Principal Investigator) 
Organization: Tufts University
169 HOLLAND ST FL 3, SOMERVILLE, MA 02144-2401, (617)627-3696
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8249 8396 8611
Program Element Code(s): 099Y, 1712
Abstract: The overarching goal of this project is to accelerate the discovery of  materials with tailored electronic properties through human-computer active search. These efforts will lay the groundwork for accelerating materials discovery, and advance the capability to control electronic properties in materials with the potential for profound societal impact. The thermoelectric and photocatalytic materials predicted, synthesized, and characterized in this research can realize societal advances in the space of energy and solar fuels. High-efficiency thermoelectric materials can revolutionize how heat sources are transformed into electrical power by eliminating the traditional intermediate mechanical energy conversions.  Earth-abundant  light-responsive catalysts are emerging as  an alternative to costly, rare metal catalysts to store solar energy as  portable liquid fuels, like ethanol. These green reactions  are enabling low-cost, carbon-neutral fuels.  The team brings together expertise in materials science, chemistry, machine learning, visualization, metadata, and knowledge frameworks to develop multi-fidelity, expert-guided active search strategies within materials science and chemistry.  Resonances among the team's existing outreach programs will broaden inclusion of students from underrepresented groups and be moderated via the Alliance for Diversity in Science and Engineering.  The work will provide cross-disciplinary training to graduate students and postdocs in all aspects of material informatics, including participating in and leading team efforts, co-mentorship of Ph.D.  and postdoctoral researchers, inclusive symposia at national conferences, and a summer workshop focused on the intersection of visualization, machine learning, ontological engineering and materials science. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative. <br/><br/>An interdisciplinary team will create a search framework for scientific discovery that leverages recent advances in material databases, machine learning, visualization, human-machine interaction, and knowledge structures. To broadly assess the efficacy of this approach, the search effort will span the electronic behavior of both molecules and crystalline materials:  (i) new organic photocatalysts for solar fuels production and (ii) new thermoelectric materials for electricity generation.  Central to this effort is the engagement of domain experts and associated feedback in a human-in-the-loop active search process. Dynamic visualizations will enable the user to (i) understand the underlying reasons why the materials are being suggested and (ii) provide a user steering capability to identify and annotate specific aspects of the explored search space. Domain-expert annotations and feedback will be parsed against a suite of ontologies, further aiding the search process by providing relational insight between features. New molecules and materials will be explored through a combination of first principles calculations and high-throughput, automated experimentation; these results will be incorporated into a continually growing open-access database. Efficiently integrating and directing evolving data-streams from experiment, computation, and human steering during the search will be achieved with a multi-fidelity active search policy. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1852606
Title: BIGDATA: Collaborative Research: IA: Big Imaging-Omics Data Mining Framework for Precision Medicine
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: November 01, 2018
Latest Amendment Date: July 29, 2022
Award Instrument: Standard Grant
Program Manager: Wendy Nilsen
Start Date: September 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $1,253,373
ARRA Amount: $
Investigator(s): Heng Huang heng.huang@pitt.edu (Principal Investigator) 
Organization: University of Pittsburgh
4200 5TH AVE, PITTSBURGH, PA 15260-0001, (412)624-7400
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: The research objective of this proposal is to address the computational challenges in an innovative BIGDATA application on imaging-omics based precision medicine. Recent advances in high-throughput imaging (such as histopathology image) and multi-omics (such as DNA sequence, RNA expression, methylation, etc.) technologies created new opportunities for exploring relationships between histology, molecular events, and clinical outcomes using quantitative methods. However, the unprecedented scale and complexity of these imaging-omic data have presented critical computational bottlenecks requiring new concepts and enabling tools. This project builds a new computational framework to integrate novel big data mining algorithms with cloud and high-performance computing strategies for revealing complex relationships between histopathology images, multi-omics, and phenotypic outcomes. This project is innovative and crucial not only to facilitating the development of new big data mining techniques, but also to addressing emerging scientific questions in imaging-omics and many other biomedical applications. The developed methods and tools are expected to impact other cancer genomics research and enable investigators working on cancer medicine to effectively test their scientific hypothesis. This project facilitates the development of novel educational tools to enhance several current courses. University of Texas at Arlington is a minority-serving institution and has large population of Hispanic and Black Americans. This project engages the minority students and under-served populations in research activities to give them a better exposure to cutting-edge science research.<br/><br/>To solve the key and challenge problems in big imaging-omics data mining, this project explores the following research tasks. First, the large-scale non-convex sparse learning models are developed for identifying outcome-relevant phenotypic traits from big histopathology images. Second, the biological domain knowledge is utilized to guide the sparse learning models to uncover the molecular bases of complex traits. Third, the data integration models are designed to integrate imaging-omics data from multiple sources and discover the heterogeneous biomarkers. Fourth, the Baysian learning model is explored to predict longitudinal cancer outcomes. Fifth, the cloud computing and high-performance computing strategies are developed to support the big imaging-omics data mining, such as optimizations for various data mining workloads on heterogeneous hardware (e.g. GPU and NUMA multicore processors) to fully unlock the potential of data center hardware. It is innovative to integrate big data mining algorithms with cloud and high-performance computing to imaging-omics that hold great promise for a systems biology of the precision medicine.

Award Number: 1918925
Title: Collaborative Research: A Generalizable Data Framework Towards Precision Radiotherapy
NSF Org: DMS Division Of Mathematical Sciences
Initial Amendment Date: July 11, 2019
Latest Amendment Date: July 11, 2019
Award Instrument: Standard Grant
Program Manager: Christopher Stark
Start Date: August 01, 2019
End Date: July 31, 2023
Awarded Amount to Date: $439,440
ARRA Amount: $
Investigator(s): Jun Deng jun.deng@yale.edu (Principal Investigator) 
Organization: Yale University
105 WALL ST, NEW HAVEN, CT 06511-8917, (203)785-4689
NSF Directorate: MPS
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z
Program Element Code(s): 8083
Abstract: In treating cancer patients with radiation therapy, different patients may have different responses to the same type of radiotherapy.  Hence, it is critical to individualize the radiation treatment based on the patient's health data, clinical conditions, as well as response over time.  The goal of this project is to develop a generalizable data framework that can support precision radiotherapy for individual cancer patients.  Specifically, a deep reinforcement learning model will be built and validated with multimodal imaging data acquired during diagnosis, treatment and follow-up of individual patients.  Harmonization of the medical imaging data with genetic and clinical data will create an invaluable repository of knowledge to draw from, while calling for new analytics.  The developed data framework will provide critical clinical decision support for individualized radiotherapy<br/><br/>By leveraging the wealth of data generated in the radiotherapy clinic, the project aims to develop a generalized deep reinforcement learning (DRL) tool for cancer risk stratification.  Based on the DRL tool, an ensemble model will be built to analyze all the data types useful to patient outcome prediction.  The model will be validated with independent datasets to ensure generalization.  To account for information from multiple imaging modalities combined with treatment plans, a multimodal deep reinforcement learning (mDRL) model will be developed and trained with patient data stored in the electronic medical record system, as well as genomic information derived from blood and tissue specimens. The detection tool will be used in both lung cancer and colorectal cancer patients.  Generalization to a variety of other cancers will be possible once the tools become available to the clinical research community.  The ensemble model will allow integrated analysis of multiple data types recorded along the patient outcome trajectory, provide better discrimination between tumor phenotypes and superior predictive power. The framework will be designed to coordinate and synthesize various types of evidence and measurements into scores for the objective assessment and quantification of outcomes and endpoints. This strategy will ultimately provide novel patient re-stratification and support clinical decisions for highly individualized patient management.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2217023
Title: Institute for Data, Econometrics, Algorithms and Learning (IDEAL)
NSF Org: ECCS Div Of Electrical, Commun & Cyber Sys
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $1,272,000
ARRA Amount: $
Investigator(s): Lev Reyzin lreyzin@uic.edu (Principal Investigator) Yichao Wu (Co-Principal Investigator) Natasha Devroye (Co-Principal Investigator) William Perkins (Co-Principal Investigator) Elena Zheleva (Co-Principal Investigator) 
Organization: University of Illinois at Chicago
809 S MARSHFIELD RM 520, CHICAGO, IL 60612-4305, (312)996-2862
NSF Directorate: ENG
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) will consolidate and amplify research devoted to the foundations of data science across all the major research-focused educational institutions in the greater Chicago area: the University of Illinois at Chicago, Northwestern University, the Toyota Technological Institute at Chicago, the University of Chicago, and the Illinois Institute of Technology. This transdisciplinary institute involves over 50 researchers working on key aspects of the foundations of data science across computer science, electrical engineering, mathematics, statistics, and several related fields like economics, operations research, and law, and they are complemented by members of Google?s learning theory team. Its research goals range from the core foundations of data science to its interfaces with other disciplines: 1) tackling important challenges related to foundations of machine learning and optimization, 2) addressing statistical, algorithmic and mathematical challenges in dealing with high-dimensional data, and 3) exploring the foundations of aspects of data science that interact with society. The institute will foster strong connections with the community and local high schools, broaden participation in data science locally and nationally, and build lasting research and educational infrastructure through its activities. Institute activities will include workshops for undergraduate students, high school teacher workshops, public lectures, and museum exhibit designs. These will build new pathways for undergraduate students, high school students, and the broader public from diverse and underrepresented backgrounds, to increase participation and engagement with scientific fields related to data science.<br/><br/>The research thrusts of the institute will center around the foundations of machine learning, high-dimensional data analysis and inference, and data science and society. Specific topics include foundations of deep learning, reinforcement learning, machine learning and logic, network inference, high-dimensional data analysis, trustworthiness & reliability, fairness, and data science with strategic agents. The research activities are designed to facilitate collaboration between the different disciplines and across the five Chicago-area institutions, and they build on the extensive experience from previous efforts of the participating universities. The activities include topical special programs, postdoctoral fellows, co-mentored PhD students, workshops, coordinated graduate courses, visiting fellows, research meetings, and brainstorming sessions. The proposed research will lead to new theoretical frameworks, models, mathematical tools and algorithms for analyzing high-dimensional data, inference and learning. Successful outcomes will also lead to a better understanding of the foundations of data science and machine learning in both strategic and non-strategic environments ? including emerging concerns like reliability, fairness, privacy and interpretability as data science interacts with society in various ways. The institute will also have broader impacts of strengthening  research and educational infrastructure, developing human resources, broadening participation from underrepresented groups, and by connecting theory to science and industry. The institute will organize activities to engage the community and a diverse group of students at all levels, including introductory workshops for undergraduate research participants, high school student and teacher outreach (through a partnership with the Math Circles of Chicago), and public lectures as part of both our research program and a partnership with the Museum of Science and Industry. The Chicago public institutions that we engage serve a very diverse population, so the outreach, recruitment, and training activities will broaden participation from underrepresented groups. Finally, the institute will have direct engagement with applications and industry through its activities involving Google, other industry partners in the broader Chicago area, and applied data science institutes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934964
Title: HDR TRIPODS: Innovations in Data Science: Integrating Stochastic Modeling, Data Representations, and Algorithms
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 02, 2021
Award Instrument: Continuing Grant
Program Manager: Christopher Stark
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Sayan Mukherjee sayan@stat.duke.edu (Principal Investigator) Cynthia Rudin (Co-Principal Investigator) Arthur Calderbank (Co-Principal Investigator) Jianfeng Lu (Co-Principal Investigator) Rong Ge (Co-Principal Investigator) 
Organization: Duke University
2200 W MAIN ST STE 710, DURHAM, NC 27708-4677, (919)684-3030
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: This award supports TRIPODS@Duke Phase I, a project that will develop the foundations of data science both at Duke University and in the broader NC Research Triangle and surrounding region.  A total of 25 faculty at Duke representing the disciplines of Computer Science, Electrical Engineering, Mathematics, and Statistical Science will be involved in Phase I.  Activities include five semesters of workshops, with 3-4 one-week workshops each semester. These workshops will involve local and national participants and will bring experts on data science to the area. The project will support graduate students and postdoctoral trainees both in terms of education in the foundations of data science as well as in their professional development. Educational activities include the development and teaching of data science across curricula in Computer Science, Electrical and Computer Engineering, Mathematics, and Statistical Science, both at the undergraduate and graduate levels. The project will also leverage existing data science programs, including the Rhodes Information Initiative at Duke, a center for "big data" computational research and expanding opportunities for student engagement in data science; and the Statistical and Applied Mathematical Sciences Institute (SAMSI), one of the NSF/DMS-funded Mathematical Sciences Research Institutes (MSRIs), which is a partnership among Duke University, North Carolina State University (NCSU), and the University of North Carolina at Chapel Hill (UNC).<br/><br/>The topics of the signature workshops supported by the TRIPODS@Duke Phase I project are (1) scalable inference with uncertainty, (2) causal inference, (3) neural networks, (4) complex and dynamic image and signal processing, and (5) interpretable models. These five topics all fall under three research themes that require transdisciplinary collaborations among computer scientists, electrical engineers, mathematicians, and statisticians: Theme I: Scalable algorithms with uncertainty for data science; Theme II: Data science at the human-machine interface; and Theme III: Fundamental limits of data science.  The potential research innovations for the three themes that will be developed and or advanced include: For Theme I, scalable Bayesian and generalized Bayesian inference, robust optimization for uncertain inputs, and algorithm and architecture design for neural networks; for Theme II, interpretable models and algorithms, causal inference with high-dimensional complex observational data,  and image and signal processing for screening and monitoring; and for Theme III, robust optimization for uncertain inputs,  statistical and approximation power of deep neural network architectures, and fundamental limits of causal inference in observational studies.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1912887
Title: BIGDATA: IA: Collaborative Research: Domain Adaptation Approaches for Classifying Crisis Related Data on Social Media
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: December 21, 2018
Latest Amendment Date: December 21, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: August 26, 2018
End Date: September 30, 2023
Awarded Amount to Date: $395,502
ARRA Amount: $
Investigator(s): Cornelia Caragea cornelia@uic.edu (Principal Investigator) 
Organization: University of Illinois at Chicago
809 S MARSHFIELD RM 520, CHICAGO, IL 60612-4305, (312)996-2862
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7364 7433 8083
Program Element Code(s): 8083
Abstract: The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br/><br/>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.

Award Number: 2117997
Title: HDR Institute: Accelerated AI Algorithms for Data-Driven Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2021
Latest Amendment Date: July 12, 2022
Award Instrument: Cooperative Agreement
Program Manager: Amy Walton
Start Date: October 01, 2021
End Date: September 30, 2026
Awarded Amount to Date: $4,500,000
ARRA Amount: $
Investigator(s): Shih-Chieh Hsu schsu@uw.edu (Principal Investigator) Kate Scholberg (Co-Principal Investigator) Mark Neubauer (Co-Principal Investigator) Michael Coughlin (Co-Principal Investigator) Philip Harris (Co-Principal Investigator) Song Han (Former Co-Principal Investigator) 
Organization: University of Washington
4333 Brooklyn Ave NE, Seattle, WA 98195-0001, (206)543-4043
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu WoU-Windows on the Universe: T 
Program Reference Code(s): 062Z 069Z 075Z 1206 7483 9102
Program Element Code(s): 099Y, 107Y
Abstract: The data revolution is dramatically accelerating the acquisition rate of new information, creating a vast amount  of data. Artificial intelligence (AI) has emerged as a solution for rapid processing of complex datasets.  New hardware such as graphics processing units (GPUs) and field-programmable gate arrays (FPGAs) allow AI algorithms to be greatly accelerated.  To take full advantage of fast AI, the Institute of Accelerated AI Algorithms for Data-Driven Discovery (A3D3) targets fundamental problems in three fields of science: high energy physics, multi-messenger astrophysics, and systems neuroscience.  A3D3 works closely within these domains to develop customized AI solutions to process large datasets in real-time, significantly enhancing their discovery potential.  The ultimate goal of A3D3 is to construct the institutional knowledge essential for real-time applications of AI in any scientific field. Through dedicated outreach efforts, A3D3 will empower scientists with new tools to deal with the data deluge.  Students mentored through A3D3 research will interact closely with industry partners, creating new career opportunities and strengthening synergies between academia and industry.<br/><br/>The approach of A3D3 is to tightly couple AI algorithm innovations, heterogeneous computing platforms, and science-driven application development informed through close collaboration with domain scientists within physics, astronomy, and neuroscience.  The common theme  across domains is  the development of AI strategies accelerated by emerging processor technology, employing hardware-AI co-design as a transformative solution to a wide range of scientific challenges.  Hardware architectures such as GPUs and FPGAs have emerged as promising technologies to address many of the challenges in data-intensive science because they provide highly-performant, parallelizable, and configurable data processing pipeline capabilities.  When combined with AI algorithms, these architectures significantly accelerate scientific workflows compared to CPU-only computing platforms.  Building on the existing Fast Machine Learning community, A3D3 cultivates an ecosystem where scientists across domains collaborate to meet critical challenges, forming a central hub of excellence for innovation in accelerated AI for science.  The work is extended to the public at large through a diverse set of educational training programs and by mentoring next-generation scientists.<br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR) and Windows on the Universe - The Era of Multi-Messenger Astrophysics (WoU-MMA).  This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Divisions of Astronomical Sciences and of Physics within the NSF Directorate for Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123237
Title: Collaborative Research: HDR DSC: Infusion of data science and computation into engineering curricula
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 05, 2021
Latest Amendment Date: August 05, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $120,061
ARRA Amount: $
Investigator(s): David Lattanzi dlattanz@gmu.edu (Principal Investigator) 
Organization: George Mason University
4400 UNIVERSITY DR, FAIRFAX, VA 22030-4422, (703)993-2295
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a curricular framework for data science education and workforce development that is transferable between diverse institutions, so STEM-related programs can plug and play data science lessons with existing curricula without much overhead. These lessons will be created in conjunction with community stakeholders and industry partners to ensure a focus on real-world problem solving and include student organizations in course development to promote flexible learning pathways. The proposed additions to undergraduate STEM education will provide an evidence-based blueprint for best practices in integrating data science with existing engineering curricula. Implementation across multiple engineering departments will result in a significant impact on society through the training of a diverse, globally competitive STEM workforce with high data literacy. <br/><br/>The objectives of this project are to (1) facilitate data science education and workforce development for engineering and related topics, (2) provide opportunities for students to participate in practical experiences where they can learn new skills in a variety of environments, and (3) expand the data science talent pool by enabling the participation of undergraduate students with diverse backgrounds, experiences, skills, and technical maturity in the Data Science Corps. This work will support the Data Science Corps objective of building capacity for education and workforce development to harness the data revolution at local, state, and national levels. The institutions gathered for this project will develop training programs and curate datasets that will be made available so they can be included in undergraduate instruction nationwide. Furthermore, the training materials will be shared with industry partners, facilitating workforce development. The project team will develop a website to house data science training programs, didactic datasets, and other resources for educators. These resources are intended to reduce barrier to entry for faculty seeking to incorporate data science into their instruction, as recruiting and retaining faculty to create and teach integrated introductory courses in data science has been recognized as a significant hurdle by the National Academies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940181
Title: Collaborative Research: Autonomous Computing Materials
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $345,915
ARRA Amount: $
Investigator(s): Takaki Komiyama tkomiyama@ucsd.edu (Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: The recent explosion in worldwide data together with the end of Moore's Law and the near-term limits of silicon-based data storage being reached are driving an urgent need for alternative forms of computing and data storage/retrieval platforms. In particular, exabyte-scale datasets are increasingly being generated by the biological sciences and engineering disciplines including genomics, transcriptomics, proteomics, metabolomics, and high-resolution imaging, as well as disparate other scientific fields including climate science, ecology, astronomy, oceanography, sociology, and meteorology, amongst others. In this data revolution, the continuously increasing size of these datasets requires a concomitant increase in available computational power to store, process, and harness them, which is driving a need for revolutionary new, alternative substrates for, and forms of, computing and data storage. Unlike traditional data storage and computing materials such as silicon, the human brain offers a remarkable ability to sense, store, retrieve, and compute information in a manner that is unrivaled by any human-made material. In this research project, analogous modes of information sensing, data storage, retrieval, and computation will be explored in non-traditional computing molecular systems and materials. The over-arching goal of the research is to discover revolutionary new modes of data storage/retrieval, sensing, and computation that rival conventional silicon-based technology, for deployment to benefit society broadly across all domains of data science. Graduate students and postdocs across five institutions will be trained and mentored in a highly interdisciplinary manner to attain this goal and prepare the next-generation of data scientists, chemists, physicists, and engineers to harness the ongoing data revolution. The research will be disseminated to a broad community through news outlets and integration of high school student internships in participating research laboratories. <br/><br/>Large-scale datasets from spatial-temporal calcium imaging of the mouse brain will be recorded into DNA-based, nanoparticle-based, and phononic 2D and 3D soft and hard materials. Continuous spatial-temporal data will first be transformed into discrete data for mapping onto DNA-conjugated fluorophore networks, dynamic barcoded nanoparticle networks, and phononic 2D and 3D materials. Sensing, computation, and data storage/retrieval will be demonstrated as proofs-of-principle in exploiting the chemical properties of molecular networks and materials to recover the encoded neuronal datasets and their sensing and computing processes. Success with any of these three prototypical materials would revolutionize the ability to encode arbitrarily complex, large-scale datasets into complex molecular systems, with the potential to scale across diverse data domains and materials frameworks. The investigators' Autonomous Computing Materials framework will thereby enable the encoding of arbitrary "big data" sets into diverse materials for data storage, sensing, and computing. This project maximizes opportunities for disruptive new computing and data science concepts to emerge from a multi-disciplinary, collaborative team spanning data science, neuroscience, materials science, chemistry, physics, and biological engineering. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1836914
Title: BIGDATA: F: Metric-space Positioning Systems for Symbolic Data Science
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2018
Latest Amendment Date: September 08, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $610,560
ARRA Amount: $
Investigator(s): Manuel Lladser lladser@colorado.edu (Principal Investigator) Rafael Frongillo (Co-Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: Next-generation DNA sequencing technologies produce datasets that are the epitome of "big data." Resulting files are typically quite large, consisting almost entirely of symbolic (i.e., non-numeric) short DNA sequences. In contrast, the most widely used machine learning algorithms require numerical datasets to learn. Unfortunately, both traditional and cutting-edge methods to numerically represent symbolic data often suffer from high-dimensionality or substantial running time requirements, which hinder the application of powerful machine learning algorithms to modern biological questions. To overcome these crucial issues, this project addresses the fundamental problem of determining the "right" dimension in which to embed symbolic data for a data-mining or classification task. It does so by representing symbolic datasets numerically via a method reminiscent of Global Positioning Systems (GPS) but in a far more general setting. Besides exploring modern biology applications, the project will also investigate how to predict the source of a spread (i.e., ground zero) over large networks. This may assist administrators in determining how best to respond to new epidemics and cyber-threats. Additionally, the project will closely mentor undergraduate and graduate students to become mature data scientists. Its findings will be communicated as notes, open-source software, and video-lectures available to the general public, including students in the Colorado Data Science Team, which encourages the participation of women and under-represented minorities in Engineering education.<br/><br/>Much like GPS uses trilateration to locate a receiver anywhere on the planet, finite metric spaces contain resolving sets, that is sets of points that uniquely identify every point in the space via multilateration (i.e., the vector of distances to points in the set). Associated with any resolving set R, there is a one-to-one transformation from its ambient metric space to a Euclidean space of dimension |R|, the cardinality of R. The smallest resolving set thus induces the lowest-dimensional representation of its ambient space. Importantly, even when the ambient metric space is finite but exponentially large, its metric dimension is often much smaller than its cardinality. Determining the metric dimension is, however, an NP-hard problem in a variety of contexts. Building on this abstracted notion of multilateration, this project will: (1) assess the computational complexity of calculating the metric dimension of Hamming graphs, and characterize the metric dimension of various random graph models to guide the development of new and efficient algorithms to approximate this quantity; (2) explore relaxations and constraints of multilateration, including approximate and probabilistic algorithms, to expand the reach of applications of multilateration to other finite but large metric spaces; and finally (3) provide proofs-of-concept of multilateration to learn non-contiguous regions of dependencies in genomic sequences, develop classifiers for historically elusive virus targets, and identify the source of spread of information or disease in large networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1855099
Title: BIGDATA: F: Collaborative Research: Taming Big Networks via Embedding
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: October 23, 2018
Latest Amendment Date: October 23, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: July 01, 2018
End Date: December 31, 2022
Awarded Amount to Date: $499,879
ARRA Amount: $
Investigator(s): Quanquan Gu qgu@cs.ucla.edu (Principal Investigator) 
Organization: University of California-Los Angeles
10889 WILSHIRE BLVD STE 700, LOS ANGELES, CA 90024-4201, (310)794-0102
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: In the Internet Age, information entities and objects are interconnected, thereby forming gigantic information networks. Recently, network embedding methods, that create low-dimensional feature representations that preserve the structure of data points in their original space, have been shown to be greatly beneficial for many data mining and machine learning problems over networks. Despite significant research progress, we are still lacking powerful network embedding techniques with theoretical guarantees to effectively deal with massive, heterogeneous, complex and dynamic networks. The PIs aim to develop a new generation of network embedding methods for analyzing massive networks. The research project has the potential to significantly transform graph mining and network analysis. The PIs also plan to develop open course materials and open source software tools that integrate information network analysis and machine learning. <br/><br/>This project consists of four synergistic research thrusts. First, it develops model-based network embedding to leverage the first-order and second-order proximity of networks. Second, it devises a family of inductive network embedding methods that are able to leverage both linkage information and side information. Third, it develops both local clustering and deep learning based network embedding methods to attack the complex structure of networks such as locality and non-linearity. Fourth, it develops online and stochastic optimization algorithms for different network embedding methods to tackle the fast growth and evolution of modern massive networks. The new methods developed in this project enjoy faster rates of convergence in optimization, lower computational complexities, and statistical learning guarantees. The targeted applications include but are not limited to semantic search and information retrieval in social/information network analysis, expert finding in bibliographical database, and recommendation systems.

Award Number: 1940097
Title: Collaborative Research: Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $320,017
ARRA Amount: $
Investigator(s): Carlos Fernandez Granda cfg3@nyu.edu (Principal Investigator) 
Organization: New York University
70 WASHINGTON SQ S, NEW YORK, NY 10012-1019, (212)998-2121
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1916454
Title: BD Hubs: Collaborative Proposal: South: The South Big Data Innovation Hub
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: May 31, 2019
Latest Amendment Date: July 25, 2022
Award Instrument: Cooperative Agreement
Program Manager: Martin Halbert
Start Date: June 01, 2019
End Date: May 31, 2023
Awarded Amount to Date: $2,038,666
ARRA Amount: $
Investigator(s): Stanley Ahalt ahalt@renci.org (Principal Investigator) Stephen Fiore (Co-Principal Investigator) Jay Aikat (Co-Principal Investigator) Lea Shanley (Former Co-Principal Investigator) 
Organization: University of North Carolina at Chapel Hill
104 AIRPORT DR STE 2200, CHAPEL HILL, NC 27599-5023, (919)966-3411
NSF Directorate: CSE
Program(s): BD Spokes -Big Data Regional I HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 8083 9102
Program Element Code(s): 024Y, 099Y
Abstract: The BD Hubs foster regional networks of stakeholders and cooperate nationally on US priorities of importance to a region and to the nation. The activities of the BD Hubs contribute to a vibrant national data innovation ecosystem. The South Big Data Regional Innovation Hub nucleates community across organizations.  It does this through stimulating new activities and provides continuity and a neutral place for activities to advance.  It works in the context of regional and national data science priorities. The South Big Data Regional Innovation Hub will serve the critical national need to educate new, and retrain current, work-force in data science, and increase data literacy.   It will achieve this by tapping into the collective expertise of its member universities, create a clearinghouse for resources, materials, and collaborations, engage with industry for training and placement of individuals, assist non-research intensive universities and community colleges develop data science curriculum, and promote collaborative team science approaches to research and project execution.<br/><br/>The initial priority areas of the South Big Data Regional Innovation Hub are in data science cyberinfrastructure; health analytics for mitigating health disparities that largely impact the South; geospatial mapping for assessment of environmental hazards such as flooding along the Gulf coasts; data science for advanced materials and manufacturing to integrate and enhance the materials-manufacturing value chain; digital modeling as well as data-driven policies for smart cities; and education and workforce training in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837812
Title: BIGDATA: IA: Collaborative Research: Data-Driven, Multi-Scale Design of Liquid-Crystals for Wearable Sensors for Monitoring Human Exposure and Air Quality
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Christina Payne
Start Date: September 15, 2018
End Date: August 31, 2023
Awarded Amount to Date: $1,243,464
ARRA Amount: $
Investigator(s): Victor Zavala Tejeda victor.zavala@wisc.edu (Principal Investigator) James Schauer (Co-Principal Investigator) Emmanouil Mavrikakis (Co-Principal Investigator) Reid Van Lehn (Co-Principal Investigator) 
Organization: University of Wisconsin-Madison
21 N PARK ST STE 6301, MADISON, WI 53715-1218, (608)262-3822
NSF Directorate: CSE
Program(s): Special Initiatives Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9102
Program Element Code(s): 1642, 8083
Abstract: Liquid crystals are responsive materials that can be used to manufacture low-cost and highly selective chemical sensors. Liquid crystals provide a potentially scalable approach toward deploying millions of wearable chemical sensors (e.g., in mobile phones or attached to clothing) that collect high-resolution data on human exposure to toxic contaminants in the air. This information is key to understanding health-risks associated with air quality, developing industrial practices that minimize workers' exposure to hazardous environments, and detecting point sources (e.g., fabrication of explosives). Liquid crystal sensors work by amplifying events that occur at the molecular-level into an optical signal when the sensor is exposed to a chemical environment. The amplification process involves a sequence of tightly coupled phenomena spanning multiple length and time scales. This span in scales lies beyond what is currently possible to characterize, model, and predict directly from first principles. This project seeks to combine first-principles and data-driven methodologies to overcome this technical challenge. The methods developed will enable the prediction of the influence of liquid crystal design variables on the information content of optical signals and will lead to a revolutionary impact on chemical sensing technologies and on the design of functional materials. The multidisciplinary nature of this project will train a new generation of engineers in the integration of data science into the design and analysis of advanced functional materials. K-12 students and the public will be engaged through development of hands-on liquid crystal sensors that respond to model target chemicals (e.g., carbon dioxide from sodas).<br/><br/>The project will investigate scalable machine learning techniques that enable the efficient use of large sets of experimental and first-principles simulation data to uncover and understand multi-scale phenomena that govern the performance of liquid crystals. Specifically, the project goals are to: i) Investigate the use of density functional theory and molecular dynamics simulations to identify nanoscale descriptors of the underlying spatiotemporal events occurring within and at liquid crystal interfaces (e.g., binding energies), ii) Establish feature extraction techniques to identify suitable macroscale descriptors of liquid crystal optical signals (e.g., optical response times and texture fields), and iii) Develop machine learning techniques that enable the creation of multi-scale models capable of mapping nanoscale and macroscale descriptors. These capabilities will be combined in a reinforcement learning framework that will help guide experimental data collection and identification of innovative liquid crystal system designs. The ultimate engineering goal of the project is to design LC sensors to infer exposure events involving carbon monoxide, ozone, and nitrogen and sulfur oxide.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934843
Title: HDR TRIPODS: Collaborative Research: Institute for Data, Econometrics, Algorithms and Learning
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 10, 2019
Latest Amendment Date: August 18, 2021
Award Instrument: Continuing Grant
Program Manager: Zhengdao Wang
Start Date: September 15, 2019
End Date: August 31, 2023
Awarded Amount to Date: $511,610
ARRA Amount: $
Investigator(s): Nathan Srebro nati@ttic.edu (Principal Investigator) Yury Makarychev (Co-Principal Investigator) 
Organization: Toyota Technological Institute at Chicago
6045 S KENWOOD AVE, CHICAGO, IL 60637-2902, (773)834-0409
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) is a multi-discipline (computer science, statistics, economics, electrical engineering, and operations research) and multi-institution (Northwestern University, Toyota Technological Institute at Chicago, and University of Chicago) collaborative institute that focuses on key aspects of the theoretical foundations of data science.   The institute will support the study of foundational problems related to machine learning, high-dimensional data analysis and optimization in both strategic and non-strategic environments.  The primary activity of the institute will be thematically focused quarters which will coordinate graduate course work with workshops and external visitors.  The institute will facilitate collaboration between Chicago-area institutions through a number of initiatives, and across multiple disciplines. Several components of the research agenda have direct applications areas, and the PIs will involve practitioners in development economics, online markets, public policy, as well as data scientists.   <br/><br/>The research areas supported by the institute focus on three broad themes:  (1) High dimensional data analysis, to address algorithmic and statistical challenges in dealing with high dimensional data, and investigate topics like metric embeddings, sketching, and problems in unsupervised learning; (2) Data Science in Strategic Environments, to address computational and information theoretic challenges in econometric models of strategic behavior like inference on high-dimensional structural parameter spaces,  dealing with unobserved heterogeneity, partial identification, and machine learning in econometrics; and (3) Machine learning and optimization, to address foundational questions in both continuous and discrete optimization and its use in machine learning including topics like representation learning, robustness in learning, and provable bounds for non-convex optimization.   Initially, six research topics will be selected that tie interests across the institutions: inference and data science on networks; theory of deep learning; incentives in shared data infrastructure; robustness in high-dimensional statistics; high-dimensional data analysis; and algorithms for partially identified models.  There will be special quarters (fall and spring) where the Institute will bring together investigators, postdocs, and Ph.D. students to focus on one of the topics.  In the following quarter (winter and summer) teams will continue research that advance the proposal topics.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2216970
Title: Institute for Data, Econometrics, Algorithms and Learning (IDEAL)
NSF Org: ECCS Div Of Electrical, Commun & Cyber Sys
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $1,371,000
ARRA Amount: $
Investigator(s): Aravindan Vijayaraghavan aravindv@northwestern.edu (Principal Investigator) Jorge Nocedal (Co-Principal Investigator) Samir Khuller (Co-Principal Investigator) Randall Berry (Co-Principal Investigator) Jason Hartline (Co-Principal Investigator) 
Organization: Northwestern University
633 CLARK, EVANSTON, IL 60208-0001, (312)503-7955
NSF Directorate: ENG
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) will consolidate and amplify research devoted to the foundations of data science across all the major research-focused educational institutions in the greater Chicago area: the University of Illinois at Chicago, Northwestern University, the Toyota Technological Institute at Chicago, the University of Chicago, and the Illinois Institute of Technology. This transdisciplinary institute involves over 50 researchers working on key aspects of the foundations of data science across computer science, electrical engineering, mathematics, statistics, and several related fields like economics, operations research, and law, and they are complemented by members of Google?s learning theory team. Its research goals range from the core foundations of data science to its interfaces with other disciplines: 1) tackling important challenges related to foundations of machine learning and optimization, 2) addressing statistical, algorithmic and mathematical challenges in dealing with high-dimensional data, and 3) exploring the foundations of aspects of data science that interact with society. The institute will foster strong connections with the community and local high schools, broaden participation in data science locally and nationally, and build lasting research and educational infrastructure through its activities. Institute activities will include workshops for undergraduate students, high school teacher workshops, public lectures, and museum exhibit designs. These will build new pathways for undergraduate students, high school students, and the broader public from diverse and underrepresented backgrounds, to increase participation and engagement with scientific fields related to data science.<br/><br/>The research thrusts of the institute will center around the foundations of machine learning, high-dimensional data analysis and inference, and data science and society. Specific topics include foundations of deep learning, reinforcement learning, machine learning and logic, network inference, high-dimensional data analysis, trustworthiness & reliability, fairness, and data science with strategic agents. The research activities are designed to facilitate collaboration between the different disciplines and across the five Chicago-area institutions, and they build on the extensive experience from previous efforts of the participating universities. The activities include topical special programs, postdoctoral fellows, co-mentored PhD students, workshops, coordinated graduate courses, visiting fellows, research meetings, and brainstorming sessions. The proposed research will lead to new theoretical frameworks, models, mathematical tools and algorithms for analyzing high-dimensional data, inference and learning. Successful outcomes will also lead to a better understanding of the foundations of data science and machine learning in both strategic and non-strategic environments ? including emerging concerns like reliability, fairness, privacy and interpretability as data science interacts with society in various ways. The institute will also have broader impacts of strengthening  research and educational infrastructure, developing human resources, broadening participation from underrepresented groups, and by connecting theory to science and industry. The institute will organize activities to engage the community and a diverse group of students at all levels, including introductory workshops for undergraduate research participants, high school student and teacher outreach (through a partnership with the Math Circles of Chicago), and public lectures as part of both our research program and a partnership with the Museum of Science and Industry. The Chicago public institutions that we engage serve a very diverse population, so the outreach, recruitment, and training activities will broaden participation from underrepresented groups. Finally, the institute will have direct engagement with applications and industry through its activities involving Google, other industry partners in the broader Chicago area, and applied data science institutes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2216926
Title: Institute for Data, Econometrics, Algorithms and Learning (IDEAL)
NSF Org: ECCS Div Of Electrical, Commun & Cyber Sys
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $102,000
ARRA Amount: $
Investigator(s): Jinqiao Duan duan@iit.edu (Principal Investigator) Binghui Wang (Co-Principal Investigator) 
Organization: Illinois Institute of Technology
10 W 35TH ST, CHICAGO, IL 60616-3717, (312)567-3035
NSF Directorate: ENG
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) will consolidate and amplify research devoted to the foundations of data science across all the major research-focused educational institutions in the greater Chicago area: the University of Illinois at Chicago, Northwestern University, the Toyota Technological Institute at Chicago, the University of Chicago, and the Illinois Institute of Technology. This transdisciplinary institute involves over 50 researchers working on key aspects of the foundations of data science across computer science, electrical engineering, mathematics, statistics, and several related fields like economics, operations research, and law, and they are complemented by members of Google?s learning theory team. Its research goals range from the core foundations of data science to its interfaces with other disciplines: 1) tackling important challenges related to foundations of machine learning and optimization, 2) addressing statistical, algorithmic and mathematical challenges in dealing with high-dimensional data, and 3) exploring the foundations of aspects of data science that interact with society. The institute will foster strong connections with the community and local high schools, broaden participation in data science locally and nationally, and build lasting research and educational infrastructure through its activities. Institute activities will include workshops for undergraduate students, high school teacher workshops, public lectures, and museum exhibit designs. These will build new pathways for undergraduate students, high school students, and the broader public from diverse and underrepresented backgrounds, to increase participation and engagement with scientific fields related to data science.<br/><br/>The research thrusts of the institute will center around the foundations of machine learning, high-dimensional data analysis and inference, and data science and society. Specific topics include foundations of deep learning, reinforcement learning, machine learning and logic, network inference, high-dimensional data analysis, trustworthiness & reliability, fairness, and data science with strategic agents. The research activities are designed to facilitate collaboration between the different disciplines and across the five Chicago-area institutions, and they build on the extensive experience from previous efforts of the participating universities. The activities include topical special programs, postdoctoral fellows, co-mentored PhD students, workshops, coordinated graduate courses, visiting fellows, research meetings, and brainstorming sessions. The proposed research will lead to new theoretical frameworks, models, mathematical tools and algorithms for analyzing high-dimensional data, inference and learning. Successful outcomes will also lead to a better understanding of the foundations of data science and machine learning in both strategic and non-strategic environments ? including emerging concerns like reliability, fairness, privacy and interpretability as data science interacts with society in various ways. The institute will also have broader impacts of strengthening  research and educational infrastructure, developing human resources, broadening participation from underrepresented groups, and by connecting theory to science and industry. The institute will organize activities to engage the community and a diverse group of students at all levels, including introductory workshops for undergraduate research participants, high school student and teacher outreach (through a partnership with the Math Circles of Chicago), and public lectures as part of both our research program and a partnership with the Museum of Science and Industry. The Chicago public institutions that we engage serve a very diverse population, so the outreach, recruitment, and training activities will broaden participation from underrepresented groups. Finally, the institute will have direct engagement with applications and industry through its activities involving Google, other industry partners in the broader Chicago area, and applied data science institutes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2216912
Title: Institute for Data, Econometrics, Algorithms and Learning (IDEAL)
NSF Org: ECCS Div Of Electrical, Commun & Cyber Sys
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $468,000
ARRA Amount: $
Investigator(s): Chao Gao chaogao@galton.uchicago.edu (Principal Investigator) Lek-Heng Lim (Co-Principal Investigator) Mladen Kolar (Co-Principal Investigator) Varun Gupta (Co-Principal Investigator) Utku Candogan (Co-Principal Investigator) 
Organization: University of Chicago
5801 S ELLIS AVE, CHICAGO, IL 60637-5418, (773)702-8669
NSF Directorate: ENG
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) will consolidate and amplify research devoted to the foundations of data science across all the major research-focused educational institutions in the greater Chicago area: the University of Illinois at Chicago, Northwestern University, the Toyota Technological Institute at Chicago, the University of Chicago, and the Illinois Institute of Technology. This transdisciplinary institute involves over 50 researchers working on key aspects of the foundations of data science across computer science, electrical engineering, mathematics, statistics, and several related fields like economics, operations research, and law, and they are complemented by members of Google?s learning theory team. Its research goals range from the core foundations of data science to its interfaces with other disciplines: 1) tackling important challenges related to foundations of machine learning and optimization, 2) addressing statistical, algorithmic and mathematical challenges in dealing with high-dimensional data, and 3) exploring the foundations of aspects of data science that interact with society. The institute will foster strong connections with the community and local high schools, broaden participation in data science locally and nationally, and build lasting research and educational infrastructure through its activities. Institute activities will include workshops for undergraduate students, high school teacher workshops, public lectures, and museum exhibit designs. These will build new pathways for undergraduate students, high school students, and the broader public from diverse and underrepresented backgrounds, to increase participation and engagement with scientific fields related to data science.<br/><br/>The research thrusts of the institute will center around the foundations of machine learning, high-dimensional data analysis and inference, and data science and society. Specific topics include foundations of deep learning, reinforcement learning, machine learning and logic, network inference, high-dimensional data analysis, trustworthiness & reliability, fairness, and data science with strategic agents. The research activities are designed to facilitate collaboration between the different disciplines and across the five Chicago-area institutions, and they build on the extensive experience from previous efforts of the participating universities. The activities include topical special programs, postdoctoral fellows, co-mentored PhD students, workshops, coordinated graduate courses, visiting fellows, research meetings, and brainstorming sessions. The proposed research will lead to new theoretical frameworks, models, mathematical tools and algorithms for analyzing high-dimensional data, inference and learning. Successful outcomes will also lead to a better understanding of the foundations of data science and machine learning in both strategic and non-strategic environments ? including emerging concerns like reliability, fairness, privacy and interpretability as data science interacts with society in various ways. The institute will also have broader impacts of strengthening  research and educational infrastructure, developing human resources, broadening participation from underrepresented groups, and by connecting theory to science and industry. The institute will organize activities to engage the community and a diverse group of students at all levels, including introductory workshops for undergraduate research participants, high school student and teacher outreach (through a partnership with the Math Circles of Chicago), and public lectures as part of both our research program and a partnership with the Museum of Science and Industry. The Chicago public institutions that we engage serve a very diverse population, so the outreach, recruitment, and training activities will broaden participation from underrepresented groups. Finally, the institute will have direct engagement with applications and industry through its activities involving Google, other industry partners in the broader Chicago area, and applied data science institutes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2216899
Title: Institute for Data, Econometrics, Algorithms and Learning (IDEAL)
NSF Org: ECCS Div Of Electrical, Commun & Cyber Sys
Initial Amendment Date: July 28, 2022
Latest Amendment Date: July 28, 2022
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2022
End Date: August 31, 2027
Awarded Amount to Date: $787,000
ARRA Amount: $
Investigator(s): Avrim Blum avrim@ttic.edu (Principal Investigator) Nathan Srebro (Co-Principal Investigator) Julia Chuzhoy (Co-Principal Investigator) Yury Makarychev (Co-Principal Investigator) 
Organization: Toyota Technological Institute at Chicago
6045 S KENWOOD AVE, CHICAGO, IL 60637-2902, (773)834-0409
NSF Directorate: ENG
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 048Z 062Z 075Z 079Z 9102
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) will consolidate and amplify research devoted to the foundations of data science across all the major research-focused educational institutions in the greater Chicago area: the University of Illinois at Chicago, Northwestern University, the Toyota Technological Institute at Chicago, the University of Chicago, and the Illinois Institute of Technology. This transdisciplinary institute involves over 50 researchers working on key aspects of the foundations of data science across computer science, electrical engineering, mathematics, statistics, and several related fields like economics, operations research, and law, and they are complemented by members of Google?s learning theory team. Its research goals range from the core foundations of data science to its interfaces with other disciplines: 1) tackling important challenges related to foundations of machine learning and optimization, 2) addressing statistical, algorithmic and mathematical challenges in dealing with high-dimensional data, and 3) exploring the foundations of aspects of data science that interact with society. The institute will foster strong connections with the community and local high schools, broaden participation in data science locally and nationally, and build lasting research and educational infrastructure through its activities. Institute activities will include workshops for undergraduate students, high school teacher workshops, public lectures, and museum exhibit designs. These will build new pathways for undergraduate students, high school students, and the broader public from diverse and underrepresented backgrounds, to increase participation and engagement with scientific fields related to data science.<br/><br/>The research thrusts of the institute will center around the foundations of machine learning, high-dimensional data analysis and inference, and data science and society. Specific topics include foundations of deep learning, reinforcement learning, machine learning and logic, network inference, high-dimensional data analysis, trustworthiness & reliability, fairness, and data science with strategic agents. The research activities are designed to facilitate collaboration between the different disciplines and across the five Chicago-area institutions, and they build on the extensive experience from previous efforts of the participating universities. The activities include topical special programs, postdoctoral fellows, co-mentored PhD students, workshops, coordinated graduate courses, visiting fellows, research meetings, and brainstorming sessions. The proposed research will lead to new theoretical frameworks, models, mathematical tools and algorithms for analyzing high-dimensional data, inference and learning. Successful outcomes will also lead to a better understanding of the foundations of data science and machine learning in both strategic and non-strategic environments ? including emerging concerns like reliability, fairness, privacy and interpretability as data science interacts with society in various ways. The institute will also have broader impacts of strengthening  research and educational infrastructure, developing human resources, broadening participation from underrepresented groups, and by connecting theory to science and industry. The institute will organize activities to engage the community and a diverse group of students at all levels, including introductory workshops for undergraduate research participants, high school student and teacher outreach (through a partnership with the Math Circles of Chicago), and public lectures as part of both our research program and a partnership with the Museum of Science and Industry. The Chicago public institutions that we engage serve a very diverse population, so the outreach, recruitment, and training activities will broaden participation from underrepresented groups. Finally, the institute will have direct engagement with applications and industry through its activities involving Google, other industry partners in the broader Chicago area, and applied data science institutes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940168
Title: Collaborative Research: Autonomous Computing Materials
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $356,566
ARRA Amount: $
Investigator(s): Raghu Machiraju machiraju.1@osu.edu (Principal Investigator) 
Organization: Ohio State University
1960 KENNY RD, COLUMBUS, OH 43210-1016, (614)688-8735
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: The recent explosion in worldwide data together with the end of Moore's Law and the near-term limits of silicon-based data storage being reached are driving an urgent need for alternative forms of computing and data storage/retrieval platforms. In particular, exabyte-scale datasets are increasingly being generated by the biological sciences and engineering disciplines including genomics, transcriptomics, proteomics, metabolomics, and high-resolution imaging, as well as disparate other scientific fields including climate science, ecology, astronomy, oceanography, sociology, and meteorology, amongst others. In this data revolution, the continuously increasing size of these datasets requires a concomitant increase in available computational power to store, process, and harness them, which is driving a need for revolutionary new, alternative substrates for, and forms of, computing and data storage. Unlike traditional data storage and computing materials such as silicon, the human brain offers a remarkable ability to sense, store, retrieve, and compute information in a manner that is unrivaled by any human-made material. In this research project, analogous modes of information sensing, data storage, retrieval, and computation will be explored in non-traditional computing molecular systems and materials. The over-arching goal of the research is to discover revolutionary new modes of data storage/retrieval, sensing, and computation that rival conventional silicon-based technology, for deployment to benefit society broadly across all domains of data science. Graduate students and postdocs across five institutions will be trained and mentored in a highly interdisciplinary manner to attain this goal and prepare the next-generation of data scientists, chemists, physicists, and engineers to harness the ongoing data revolution. The research will be disseminated to a broad community through news outlets and integration of high school student internships in participating research laboratories. <br/><br/>Large-scale datasets from spatial-temporal calcium imaging of the mouse brain will be recorded into DNA-based, nanoparticle-based, and phononic 2D and 3D soft and hard materials. Continuous spatial-temporal data will first be transformed into discrete data for mapping onto DNA-conjugated fluorophore networks, dynamic barcoded nanoparticle networks, and phononic 2D and 3D materials. Sensing, computation, and data storage/retrieval will be demonstrated as proofs-of-principle in exploiting the chemical properties of molecular networks and materials to recover the encoded neuronal datasets and their sensing and computing processes. Success with any of these three prototypical materials would revolutionize the ability to encode arbitrarily complex, large-scale datasets into complex molecular systems, with the potential to scale across diverse data domains and materials frameworks. The investigators' Autonomous Computing Materials framework will thereby enable the encoding of arbitrary "big data" sets into diverse materials for data storage, sensing, and computing. This project maximizes opportunities for disruptive new computing and data science concepts to emerge from a multi-disciplinary, collaborative team spanning data science, neuroscience, materials science, chemistry, physics, and biological engineering. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1916589
Title: BD Hubs: Collaborative Proposal: SOUTH:The South Big Data Innovation Hub
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: May 31, 2019
Latest Amendment Date: June 28, 2021
Award Instrument: Cooperative Agreement
Program Manager: Martin Halbert
Start Date: June 01, 2019
End Date: May 31, 2023
Awarded Amount to Date: $1,716,711
ARRA Amount: $
Investigator(s): Srinivas Aluru aluru@cc.gatech.edu (Principal Investigator) Surya Kalidindi (Co-Principal Investigator) Madhav Marathe (Co-Principal Investigator) Renata Rawlings-Goss (Co-Principal Investigator) Patrick Sullivan (Co-Principal Investigator) 
Organization: Georgia Tech Research Corporation
926 DALNEY ST NW, ATLANTA, GA 30332-, (404)894-4819
NSF Directorate: CSE
Program(s): BD Spokes -Big Data Regional I HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 024Y, 099Y
Abstract: The BD Hubs foster regional networks of stakeholders and cooperate nationally on US priorities of importance to a region and to the nation. The activities of the BD Hubs contribute to a vibrant national data innovation ecosystem. The South Big Data Regional Innovation Hub nucleates community across organizations.  It does this through stimulating new activities and provides continuity and a neutral place for activities to advance.  It works in the context of regional and national data science priorities. The South Big Data Regional Innovation Hub will serve the critical national need to educate new, and retrain current, work-force in data science, and increase data literacy.   It will achieve this by tapping into the collective expertise of its member universities, create a clearinghouse for resources, materials, and collaborations, engage with industry for training and placement of individuals, assist non-research intensive universities and community colleges develop data science curriculum, and promote collaborative team science approaches to research and project execution.<br/><br/>The initial priority areas of the South Big Data Regional Innovation Hub are in data science cyberinfrastructure; health analytics for mitigating health disparities that largely impact the South; geospatial mapping for assessment of environmental hazards such as flooding along the Gulf coasts; data science for advanced materials and manufacturing to integrate and enhance the materials-manufacturing value chain; digital modeling as well as data-driven policies for smart cities; and education and workforce training in data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838071
Title: BIGDATA:F: Statistical and Computational Optimal Transport for Geometric Data Analysis
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: September 07, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: December 01, 2018
End Date: November 30, 2022
Awarded Amount to Date: $1,000,000
ARRA Amount: $
Investigator(s): Justin Solomon jsolomon@mit.edu (Principal Investigator) Philippe Rigollet (Co-Principal Investigator) 
Organization: Massachusetts Institute of Technology
77 MASSACHUSETTS AVE, CAMBRIDGE, MA 02139-4301, (617)253-1000
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Current approaches to big data and accompanying computational methods have left behind critical applications where the data is not a collection of individual points, but rather whole geometric objects. Such applications include medical imaging, LiDAR for self-driving cars, and single-cell RNA sequencing, to name a few. Transferring the overwhelming success of simpler data processing and statistical techniques to this regime requires not only large datasets, but also suitable models and algorithms for analysis of this more general type of data. The theory of optimal transport has proven valuable to address these limitations thanks to recent advances on the computational front. Yet, understanding optimal transport as a statistical tool is still in its infancy. This project aims at developing a "geometric data analysis" toolbox based on optimal transport to tackle these new datasets. This proposal will help create a common language to interact and collaborate across disciplines. Much of this research will be integrated in this curriculum and made available through MIT OpenCourseWare. This proposal will also enable rich interdisciplinary training of PhD and undergraduate students.<br/><br/>The proposed methods are built around the rich mathematical theory of optimal transport (OT). This theory provides a framework for the development of new methods for geometric data analysis in addition to their rigorous statistical and computational analysis. The nascent theory of computational optimal transport is still largely dissociated from statistics, and many methods do not account properly for sampling and measurement noise. To avoid the pitfalls of overfitting, this proposal singularly and systematically takes a statistical approach to geometric data analysis. With an understanding of the theoretical advantages and drawbacks of OT for statistical modeling, it will lead to scalable OT algorithms with strong statistical guarantees. A tangible outcome of this proposal is a cohesive toolbox extending not only averaging but also regression, classification, clustering, and other notions from classical statistics in a fashion that captures global geometric features of data.  It will have a direct impact on various applications in analysis of not only medical images but also point clouds gathered by LiDAR for self-driving cars, sequences of gene expressions produced by single-cell RNA sequencing, and other diverse yet large-scale sources of data.  These datasets contain millions of entities but resist application of standard statistical procedures; current state-of-the-art techniques for their analysis are ad-hoc, not generalizable, and fail to reach the quality achieved by "big data" tools in other domains.  Educational impact will be made by incorporating this work in new degree programs in statistics at MIT.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123313
Title: Collaborative Research: HDR DSC: DS-PATH: Data Science Career Pathways in the Inland Empire)
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 17, 2021
Latest Amendment Date: August 17, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $118,899
ARRA Amount: $
Investigator(s): Kasey Nguyen kasey.nguyen@mvc.edu (Principal Investigator) Mary Legner (Co-Principal Investigator) Mark Lehr (Co-Principal Investigator) Caroline Hutchings (Co-Principal Investigator) 
Organization: Riverside Community College District
3801 MARKET ST, RIVERSIDE, CA 92501-3225, (951)222-8932
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: This project brings together six partnering institutions to advance Data Science education in the Inland Empire, one of the most populous and diverse regions in California and the nation. The partnership includes the University of California Riverside, California State University San Bernardino, the three community colleges of the Riverside Community College District, and San Bernardino Valley College. All six partners are Hispanic Serving Institutions. The objective is develop and deploy ?The Data Science Career Pathways in the Inland Empire? (DS-PATH), a DSC program that aims to: (i) create flexible pathways for Data Science education in the Inland Empire region of Southern California, (ii) provide students with experiential learning opportunities, (iii) develop a community of partners that will provide local, tangible, and impactful Data Science projects, and (iv) broaden participation of females and under-represented minorities in Data Science. <br/><br/>The team of diverse PIs and co-PIs puts forward a program centered around more flexible educational pathways, along with course alignments, articulations, and shared experiential learning opportunities. DS-PATH will create a pipeline that starts with outreach opportunities at the high-school level, continues<br/>with undergraduate experiences and innovative bridge pathways from other majors, and culminates in professional Master?s degrees. Bridging these together is a Summer Fellowship program that will train 120 student participants at all levels. These pathways and the long-lasting relationships developed with local industry and community partners will continue to offer workforce development, educational advancement, and project-based learning opportunities not only for DS-PATH fellows but for all future aspiring Data Scientists in the region. Moreover, a workshop focused on Data Science pedagogy will<br/>offer best and inclusive teaching strategies to Inland Empire teachers/faculty.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1938914
Title: Collaborative Research: From Brains to Society: Neural Underpinnings of Collective Behaviors Via Massive Data and Experiments
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $268,815
ARRA Amount: $
Investigator(s): Prodromos Daoutidis daout001@umn.edu (Principal Investigator) 
Organization: University of Minnesota-Twin Cities
200 OAK ST SE # 224, MINNEAPOLIS, MN 55455-2009, (612)624-5599
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1640
Abstract: Despite thousands of investigations on the neural basis of individual behaviors and even more studies on collective behaviors, a clear bridge between the organization of individual brains and their combinational impact on group behaviors, such as cooperation and conflict and ultimately collective action, is lacking. To address the grand challenge of inferring group cooperation from the functional neuroarchitecture of individual brains, this project will harness advances in data, experiment and computation. Specifically, it will integrate, for the first time, existing large-scale human functional neuroimaging data, prospectively collected individual and group behavioral data from a large cohort, with cutting-edge machine learning tools, hierarchical models and large-scale simulations. This is a collaborative effort between a team of neuroscientists, social scientists and data scientists, that aims to elucidate the neural basis of cooperation, a fundamental process in a functioning society and at the core of social environments. <br/><br/>The project will first harness the combined wealth of existing neuroimaging and behavioral data from large-scale studies, including the Human Connectome-Lifespan (HCP-L) and the Adolescent Brain Cognitive Development (ABCD) and will leverage recent breakthroughs in machine learning to characterize the diversity, individuality and commonality of neural circuits (the connectome) supporting cognitive function across the lifespan. It will then conduct large-scale (~10,000 individuals) online behavioral experiments to identify connections between individual behaviors, decisions and group behaviors during a Public Goods Game. The experiments will measure individual proclivity towards cooperation and the social welfare obtained by cooperation, leading to potentially transformative insights into the emergence of cooperation within groups via individual behaviors. The resulting first-of-its-kind dataset may become a very valuable resource to the research community. Large-scale simulations based on statistical models estimated from this and the assembled neuroimaging datasets will then assess the direct or indirect relationships between individual connectomes and cooperation in group settings, and will elucidate the role of group processes in amplifying or ameliorating individual differences towards collective outcomes. Findings from this project may have a transformative impact on the scientific community's currently incomplete understanding of how individual brains shape societal behavior via cognitive, social, and interactive mechanisms.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123260
Title: Collaborative Research: HDR DSC: Increasing Accessibility through Building Alternative Data Science Pathways
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 12, 2021
Latest Amendment Date: July 25, 2022
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $586,983
ARRA Amount: $
Investigator(s): Andrew Christlieb christli@msu.edu (Principal Investigator) Vincent Melfi (Co-Principal Investigator) Brian O'Shea (Co-Principal Investigator) Dirk Colbry (Co-Principal Investigator) Kathleen Colbry (Co-Principal Investigator) 
Organization: Michigan State University
426 AUDITORIUM RD RM 2, EAST LANSING, MI 48824-2600, (517)355-5040
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: As computers become faster and less expensive, huge amounts of data are being produced every day. Data scientists are trained to analyze this information and apply the results to scientific research, engineering challenges, business decisions, and other efforts to improve society. The demand for data scientists increased by 28 percent between 2019 and 2020, and the U.S. Bureau of Labor Statistics estimates that 11.5 million data science jobs will be created by 2026. This project will help meet this need by making data science education available to more diverse populations of students in STEM (science, technology, engineering, mathematics). This project will also develop flexible curriculum materials that can be used to add specialized data science coursework to undergraduate programs at other institutions, beginning with Spelman College and seeking to grow this to the Atlanta University Center and beyond. <br/>  <br/>In a combined synergistic effort, Spelman College, the Atlanta University Center Data Science Initiative and Michigan State University (MSU) seek to address issues of accessibility through a joint partnership focused on creating pathways to foster data science education across STEM (science, technology, engineering, mathematics) disciplines.  First, the proposed partnership seeks to build a 3+2 BS+MS program (BS-Bachelors of Science, MS-Masters of Science). This 3+2 program will allow students to complete their BS in a STEM field (e.g., Mathematics, Physics, Biology) at Spelman and complete a MS in Data Science at MSU, while also providing a strong foundation and clear trajectory for students interested in obtaining a PhD. Second, this partnership seeks to develop a minor in Data Science at Spelman, targeting students across STEM fields. In creating this minor, we will leverage work already done at MSU to create a data science program and the expertise of faculty at Spelman to develop curricula that serves the needs of undergraduates from diverse majors and backgrounds.   The new educational material we seek to create is based on an innovative one month one credit curriculum that was initially designed to develop skills in bio-informatics for students at MSU.  Harnessing these ideas and mapping them onto the needs of Spelman STEM students, we seek to create an accessible pathway into data science that meets students where they are in their educational journey.  These educational efforts will create pathways for STEM majors who seek to bring to bear the power of modern data science methods in their STEM field of study, both at MSU and Spelman.  The curriculum will serve as a model for creating accessible data science educational initiatives nationwide.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940247
Title: Collaborative Research: Biology-guided neural networks for discovering phenotypic traits
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $422,000
ARRA Amount: $
Investigator(s): Anuj Karpatne karpatne@vt.edu (Principal Investigator) 
Organization: Virginia Polytechnic Institute and State University
300 TURNER ST NW, BLACKSBURG, VA 24060-3359, (540)231-5281
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. <br/><br/>This project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741345
Title: BIGDATA: IA: Collaborative Research: Domain Adaptation Approaches for Classifying Crisis Related Data on Social Media
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 14, 2017
Latest Amendment Date: September 14, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $500,000
ARRA Amount: $
Investigator(s): Doina Caragea dcaragea@ksu.edu (Principal Investigator) Daniel Andresen (Co-Principal Investigator) 
Organization: Kansas State University
2 FAIRCHILD HALL, MANHATTAN, KS 66506-1100, (785)532-6804
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 9102
Program Element Code(s): 8083
Abstract: The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br/><br/>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.

Award Number: 1934292
Title: HDR: I-DIRSE-FW: Accelerating the Engineering Design and Manufacturing Life-Cycle with Data Science
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Giovanna Biscontin
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $2,000,000
ARRA Amount: $
Investigator(s): Magdalena Balazinska magda@cs.washington.edu (Principal Investigator) W. James Pfaendtner (Co-Principal Investigator) David Beck (Co-Principal Investigator) Ariel Rokem (Co-Principal Investigator) 
Organization: University of Washington
4333 Brooklyn Ave NE, Seattle, WA 98195-0001, (206)543-4043
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099y, 7231
Abstract: The manufacturing life cycle begins with the discovery of new molecules and materials. This first step is often initiated through computer simulations that explore the space of possible molecules and materials, and identify promising candidates that can later be tested in laboratories. As simulations have grown in scale and complexity, this step has become a critical bottleneck. New data-driven approaches present the opportunity to increase the speed and accuracy of such predictions, with broad potential impact on the US Manufacturing sector. This Harnessing the Data Revolution Institutes for Data-Intensive Research in Science and Engineering (HDR-I-DIRSE) Frameworks award brings together Engineers and Data Scientists to conceptualize a new Engineering Data Science Institute where these tools can be applied for new discovery. The effort will develop new data science approaches to accelerate the engineering life cycle: design, characterization, manufacturing, and operation. This life cycle starts with the discovery of new molecules and materials, followed by advanced characterization with high throughput methods augmented by machine learning. Then, efficient manufacturing and operation of systems that use these materials can be designed and developed. By focusing on this holistic lifecycle, the researchers will build a broadly applicable foundation in Engineering Data Science methods. The new Institute will seek to create an Engineering Data Science environment that supports engineers and scientists (students, postdoctoral researchers, and faculty) through a synergistic set of collaboration and education activities.<br/><br/><br/>This collaborative effort follows three thrusts. The first focuses on the reduction of the experimental design space with data science tools targeting the discovery of new molecules and polymers. The research develops a new, formal framework for pairing accurate predictive simulations with data-driven models to create a scalable and transferable workflow that can be deployed across multiple examples of molecular engineering applications. The second thrust addresses a manifold of cross-cutting needs at the intersection of image data analytics and characterization of materials and systems. It also builds community cyberinfrastructure through open-source software resources with support for execution in public clouds. The final thrust focuses on improving manufacturing, optimization, and control. It further enhances cyberinfrastructure resources through a suite of open-source software solutions to systematically develop digital twin models for complex engineering and manufacturing systems, and apply them for optimization and control. This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity and is co-funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1918854
Title: Collaborative Research: New Bayesian Methods for Modeling the Effect of Antiretroviral Drugs on Depressive Symptomatology in HIV Patients
NSF Org: DMS Division Of Mathematical Sciences
Initial Amendment Date: June 21, 2019
Latest Amendment Date: June 21, 2019
Award Instrument: Standard Grant
Program Manager: Christopher Stark
Start Date: July 01, 2019
End Date: June 30, 2023
Awarded Amount to Date: $598,249
ARRA Amount: $
Investigator(s): Yanxun Xu Yanxun.xu@jhu.edu (Principal Investigator) Leah Rubin (Co-Principal Investigator) 
Organization: Johns Hopkins University
3400 N CHARLES ST, BALTIMORE, MD 21218-2608, (443)997-1898
NSF Directorate: MPS
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z
Program Element Code(s): 8083
Abstract: Antiretroviral therapy (ART) has transformed HIV infection into a manageable chronic disease, thereby shifting the focus of the care for people living with HIV more toward controlling the adverse effects of ART.  Depression is the leading mental health comorbidity of HIV infection and may trigger negative consequences such as poor adherence to ART, more rapid HIV disease progression, and engagement in risky behaviors.  Since ART is recommended for all HIV patients and must be continued indefinitely, minimizing the adverse effects of ART has garnered increasing attention.  Due to the rapid generation of drug-resistant mutations, modern ART typically combines three or four ART drugs of different mechanisms or against different targets.  Understanding the effects of a single ART drug or combinations of ART drugs can help physicians better manage patients' depression, guide treatment changes if needed, and facilitate individualized treatment.  This project aims to fill a critical gap in the availability of appropriate statistical models to systematically investigate the effects of ART on depression.  Recent technological advances in the biomedical field have led to rapid accumulation of health- and disease-related data,  which provide researchers with an unprecedented opportunity to make reliable and efficient inference from these complex and heterogeneous datasets using novel statistical models.  This project will use data from the Women's Interagency HIV Study (WIHS), a prospective, observational, multi-center study which includes more than 4,000 women living with HIV or at risk for HIV infection in the United States.<br/><br/>This project aims to develop novel Bayesian parametric and nonparametric models to estimate the effects of ART based on patients'  longitudinal medication data and depression outcomes, adjusting for socio-demographic, behavioral, and clinical factors.  Specifically, a new Bayesian longitudinal graphical model will be developed with nodes representing drugs and depression items, and weighted edges representing the strength of the drug-depression relationships, which may vary across different clinical visits and different patients.  In addition, a novel Bayesian framework that incorporates the similarity between different drug combinations as well as accounts for patients' treatment histories will be developed to learn arbitrary drug combination effects.  The proposed work will bridge the gap between the experience/knowledge acquired during basic research and day-to-day practice by facilitating the understanding of the adverse effects of individual drugs, guiding more informed and effective treatment regimen selection, and eventually helping to reduce the healthcare resource burden. The proposed models can be easily generalized to learn other ART-related complications such as cognitive impairment, and may also be used in a wide range of applications across multiple biomedical fields and beyond, such as electronic health record data analysis for chronic conditions, study of combination therapy for cancer treatment, and injury prevention in sports medicine.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940322
Title: Collaborative Research: Biology-guided neural networks for discovering phenotypic traits
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $298,454
ARRA Amount: $
Investigator(s): Henry Bart hbartjr@tulane.edu (Principal Investigator) 
Organization: Tulane University
6823 SAINT CHARLES AVE, NEW ORLEANS, LA 70118-5665, (504)865-4000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231 9150
Program Element Code(s): 099Y, 7231
Abstract: Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. <br/><br/>This project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1633720
Title: BIGDATA: Collaborative Research: F: Efficient Distributed Computation of Large-Scale Graph Problems in Epidemiology and Contagion Dynamics
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2016
Latest Amendment Date: June 22, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $565,877
ARRA Amount: $
Investigator(s): Gopal Pandurangan gopalpandurangan@gmail.com (Principal Investigator) 
Organization: University of Houston
4800 W CALHOUN ST STE 316, HOUSTON, TX 77004-, (713)743-5773
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 7934 8083 9251
Program Element Code(s): 8083
Abstract: A number of phenomena of societal importance, such as the spread of diseases and<br/>contagion processes, can be modeled by stochastic processes on networks. The analysis <br/>and control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. <br/>The graphs encountered are typically of large-scale (having tens of millions of nodes); <br/>further, typical experimental analyses involve large designs with a number of parameters, <br/>leading to hundreds of thousands of graph computations. Novel methods for solving these problems<br/>are needed, since fast response times are critical to effective decision making.<br/>The overarching goal of this project is to develop efficient distributed algorithms <br/>and associated lower bounds for graph-theoretic problems that arise in computational <br/>epidemiology and contagion dynamics.  This will have a significant impact on these specific <br/>applications, through more efficient algorithmic tools for enabling complex analyses.  <br/>The project will also make fundamental contributions to the design and analysis of <br/>distributed algorithms for graph problems in large-scale networks, and will<br/>result in an algorithmic toolkit with building blocks for performing large-scale <br/>distributed graph computation.  The project will lead to significant curriculum development <br/>for undergraduate as well as graduate students, as well as public health analysts. <br/>Finally, the project will help in involving minority and underrepresented students in research. <br/><br/>The technical focus of the project will be on distributed algorithms for fundamental topics <br/>in graph algorithms such as graph connectivity, distances, subgraph analysis, and different<br/>kinds of centrality measures.  These topics underlie some of the recurring problems in the <br/>modeling, simulation and analysis and control of different kinds of contagion processes.  <br/>For all these problems, the project will focus on developing provably efficient distributed <br/>algorithms and showing lower bounds under a message-passing distributed computing model. <br/>The PIs will also develop efficient implementations of these algorithms, and evaluate their <br/>performance and solution quality in real-world graphs arising in epidemiology.  The graphs <br/>that arise in these applications have several novel characteristics, which will present new <br/>challenges as well as opportunities for distributed computing.

Award Number: 2123264
Title: Collaborative Research: HDR DSC: Delaware and Mid-Atlantic Data Science Corps
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 13, 2021
Latest Amendment Date: September 13, 2021
Award Instrument: Continuing Grant
Program Manager: Paul Tymann
Start Date: September 15, 2021
End Date: August 31, 2024
Awarded Amount to Date: $1,400,000
ARRA Amount: $
Investigator(s): Federica Bianco fbianco@nyu.edu (Principal Investigator) Hacene Boukari (Co-Principal Investigator) Claude Tameze (Co-Principal Investigator) Gregory Dobler (Co-Principal Investigator) Jing Gao (Co-Principal Investigator) 
Organization: University of Delaware
220 HULLIHEN HALL, NEWARK, DE 19716-0099, (302)831-2136
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9150
Program Element Code(s): 099Y
Abstract: Data science is having an enormous impact on society and the economy. As the field of data science evolves, there is an increasing need for a qualified and diverse set of professionals with skills in data science. The Delaware and Mid-Atlantic Data Science Corps network will bring together three partner institutions from the Delaware Valley, the University of Delaware (UD), Delaware State University (DSU), and Lincoln University (LU). The resulting network will strengthen and promote interdisciplinary training in foundational and applied data science, both in the classroom and in projects with internal researchers and external collaborations. This project will provide equitable pedagogical opportunities in data science across students? backgrounds, resources, and lived experiences, focusing on inclusion of student populations traditionally underrepresented in STEM. The program will offer traditional (classroom-based) and active (participatory workshops and research experiences) opportunities providing job-ready skills to students, including training in the ethics of data science, visualization and communication, and collaborative skills.  <br/><br/>Each year of the program will focus on a different area of data-intensive pedagogy and research selected to be maximally relevant to one of the three partnering institutes, maximizing student engagement and empowering each institute to contribute domain expertise and data to support hands-on research opportunities for in-classroom and out-of-classroom activities.  DSU and LU, two Historically Black Colleges and Universities with growing interests in data science, will leverage UD?s established portfolio of pedagogical and research initiatives in data science throughout the program to develop independent data science initiatives. A modular approach will be used that will allow the program to meet the needs of students at any point of their career path, regardless of previous exposure to data science and STEM. Coding and Stats Bootcamps will be offered to the uninitiated. Data science foundational classes will level the playing field and offer all students basic skills. Master Classes will enable participatory discussion and hands-on training in ethics, collaboration skills, and scientific communication, and facilitate engagement with external partners. Topical advanced classes and research opportunities will complete the program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934641
Title: HDR IDEAS^2 Institute: Data-Driven Frameworks for Materials Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Giovanna Biscontin
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $2,000,000
ARRA Amount: $
Investigator(s): Samantha Daly samdaly@engineering.ucsb.edu (Principal Investigator) Tresa Pollock (Co-Principal Investigator) Bangalore Manjunath (Co-Principal Investigator) Yu-Xiang Wang (Co-Principal Investigator) Christos Thrampoulidis (Co-Principal Investigator) 
Organization: University of California-Santa Barbara
3227 CHEADLE HALL, SANTA BARBARA, CA 93106-0001, (805)893-4188
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Special Initiatives 
Program Reference Code(s): 062Z 8021
Program Element Code(s): 099y, 1642
Abstract: The discovery and development of new materials with unique properties and functionalities has revolutionized entire industries, including aviation, space, communication, biomedical, and automotive. Materials design has been traditionally experimentally and computationally intensive. However, advances in data-driven approaches, computational power, and experimental capabilities have created a tipping point for targeted and efficient materials design.  This Harnessing the Data Revolution Institutes for Data-Intensive Research in Science and Engineering (HDR-I-DIRSE) Frameworks award supports conceptualization of an Institute to advance data-intensive research in Materials Science and Engineering. The IDEAS^2 (Integrated Data Environment for Accelerated Stochastic Science) Institute for Materials Discovery will provide a platform for the development of experimental and computational frameworks for materials advancement, that encourages collaboration and the sharing of data-driven approaches among research communities. The Data Science methods are intrinsically interoperable, and this program will engage diverse research communities in the collaborative development of large data frameworks that are applicable across a wide range of disciplines. The IDEAS^2 Institute will be structured to lower the barrier for domain scientists to work with data scientists through a variety of mechanisms including biannual "Teach the Teacher" workshops, an annual IDEAS^2 Symposium, visiting faculty positions at UCSB, and a range of other community engagement activities. Students working on this program will gain valuable multidisciplinary research and educational opportunities.<br/><br/>First-principle calculations of thermodynamic and kinetic properties and information from microstructurally-based, high throughput models will be integrated into the design of data structures and the analyses of the developed techniques. The developed frameworks will be grounded in machine learning approaches that are fundamentally-based, computationally and statistically tractable, and incorporate domain knowledge and simulation results. The frameworks and data developed in the Institute - such as those to predict processing advancements from first principles, model these advancements in a high-throughput fashion, enable high-throughput experimentation, align the resulting experimental data (chemical, microstructure, deformation, etc.), and efficiently mine the resultant high-dimensional datasets - will be integrated with an open-source platform (BisQue) to facilitate both internal and external collaboration on their development for a broad range of materials applications. The computational infrastructure and parallelization of calculations through the BisQue platform enables the screening of very large datasets, with a hierarchical workflow requiring minimal software requirements (only a web browser is needed) and minimal domain knowledge of the user in modeling of materials. The focus of this program is on a research area with major and broad implications on numerous scientific and technological fields, and it also represents a unique training opportunity with acquired skills that will propel its graduates to the forefront of the emerging, critical field of data-driven science, as well as its many application areas within various scientific disciplines and high-tech industry sectors. This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity and is co-funded by the Division of Civil, Mechanical and Manufacturing Innovation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940208
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $170,000
ARRA Amount: $
Investigator(s): Ryan McGranaghan rmcgranaghan@astraspace.net (Principal Investigator) 
Organization: Atmospheric & Space Tech Research Associates
282 CENTURY PL, LOUISVILLE, CO 80027-1677, (210)834-3475
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934931
Title: HDR TRIPODS: Collaborative Research: Institute for Data, Econometrics, Algorithms and Learning
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 10, 2019
Latest Amendment Date: August 24, 2021
Award Instrument: Standard Grant
Program Manager: Zhengdao Wang
Start Date: September 15, 2019
End Date: August 31, 2023
Awarded Amount to Date: $849,819
ARRA Amount: $
Investigator(s): Jason Hartline hartline@eecs.northwestern.edu (Principal Investigator) Randall Berry (Co-Principal Investigator) Ivan Canay (Co-Principal Investigator) Aravindan Vijayaraghavan (Co-Principal Investigator) Zhaoran Wang (Co-Principal Investigator) 
Organization: Northwestern University
633 CLARK, EVANSTON, IL 60208-0001, (312)503-7955
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu CCSS-Comms Circuits & Sens Sys 
Program Reference Code(s): 047Z 062Z 9251
Program Element Code(s): 041Y, 099Y, 7564
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) is a multi-discipline (computer science, statistics, economics, electrical engineering, and operations research) and multi-institution (Northwestern University, Toyota Technological Institute at Chicago, and University of Chicago) collaborative institute that focuses on key aspects of the theoretical foundations of data science.   The institute will support the study of foundational problems related to machine learning, high-dimensional data analysis and optimization in both strategic and non-strategic environments.  The primary activity of the institute will be thematically focused quarters which will coordinate graduate course work with workshops and external visitors.  The institute will facilitate collaboration between Chicago-area institutions through a number of initiatives, and across multiple disciplines. Several components of the research agenda have direct applications areas, and the PIs will involve practitioners in development economics, online markets, public policy, as well as data scientists.   <br/><br/>The research areas supported by the institute focus on three broad themes:  (1) High dimensional data analysis, to address algorithmic and statistical challenges in dealing with high dimensional data, and investigate topics like metric embeddings, sketching, and problems in unsupervised learning; (2) Data Science in Strategic Environments, to address computational and information theoretic challenges in econometric models of strategic behavior like inference on high-dimensional structural parameter spaces,  dealing with unobserved heterogeneity, partial identification, and machine learning in econometrics; and (3) Machine learning and optimization, to address foundational questions in both continuous and discrete optimization and its use in machine learning including topics like representation learning, robustness in learning, and provable bounds for non-convex optimization.   Initially, six research topics will be selected that tie interests across the institutions: inference and data science on networks; theory of deep learning; incentives in shared data infrastructure; robustness in high-dimensional statistics; high-dimensional data analysis; and algorithms for partially identified models.  There will be special quarters (fall and spring) where the Institute will bring together investigators, postdocs, and Ph.D. students to focus on one of the topics.  In the following quarter (winter and summer) teams will continue research that advance the proposal topics.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934360
Title: Collaborative Research: Advancing Science with Accelerated Machine Learning
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $600,001
ARRA Amount: $
Investigator(s): Shih-Chieh Hsu schsu@uw.edu (Principal Investigator) Scott Hauck (Co-Principal Investigator) 
Organization: University of Washington
4333 Brooklyn Ave NE, Seattle, WA 98195-0001, (206)543-4043
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099y, 7231
Abstract: In the next generation of big science experiments, the demands for computing resources are expected to outstrip the capabilities of existing computing infrastructure. In light of this, a radical rethinking of the cyberinfrastructure is needed to contend with these developments. With the onset of deep learning, parallelized processing architectures have emerged as a solution. Combined with deep learning algorithms, parallelized processing architectures, in particular, Field Programmable Gate Arrays (FPGAs) have been shown to give large speedups in computing when compared with conventional CPUs. This project aims to bring machine learning based accelerated computing with FPGAs into the scientific community by targeting two big-data physics experiments: the Large Hadron Collider (LHC) and the Laser Interferometer Gravitational-wave  Observatory (LIGO). This project will push the frontiers of deep learning at scale, demonstrating the versatility and scalability of these methods to accelerate and enable new physics in the big data era. This project serves the national interest, as stated by NSF's mission, by promoting the progress of science. The PIs and their collaborators will build upon their recent work to design and exploit state-of-the-art neural network models for real-time data analytics, reducing overall computing latency. This new computing paradigm aims to significantly increase the processing capability at the LHC and LIGO, leading to an increased scientific output of these devices and,  potentially, foundational discoveries. The students to be mentored and trained in this research will interact closely with industry partners, creating new career opportunities, and strengthening synergies between academia and industry. In addition to sharing algorithms with the community through open source repositories, the team will continue to educate the community regarding credit and citation of scientific software.<br/><br/>In this project, the PIs will build upon their recent work developing high quality deep learning algorithms for real-time data analytics of time-series and image datasets using Field Programmable Gate Arrays (FPGAs) to accelerate low-latency inference of machine learning algorithms. The team will develop machine learning based acceleration tools focusing on FPGAs to be used within LIGO and the LHC experiments. The team's immediate goal is to take benchmark examples of LHC high level trigger processing and LIGO gravitational wave processing and construct demonstrators in each scenario. For this benchmark, they aim to design and implement an FPGA based accelerator that can perform low latency gravitational wave identification and LHC event reconstruction.  Additionally, the PIs aim to add the capability of graph based neural network accelerators for FPGAs. The open source tools to be developed as part of these activities will be readily shared with LIGO, LHC, and LSST. The project will create an advisory group, including members of large and small projects,  members of the neutrino physics, multi-messenger astronomy community, industry partners, computer scientists, and computational biologists. This project aims to bring together representatives of the different communities that will benefit from and can contribute to this work. The PIs will organize deep learning workshops and boot camps to train students and researchers on how to use and contribute to the framework, creating a wide network of contributors and developers across key science missions.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940076
Title: Collaborative Research: Precision Learning: Data-Driven Experimentation of Learning Theories using Internet-of-Videos
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: February 28, 2020
Award Instrument: Standard Grant
Program Manager: Finbarr Sloane
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $416,000
ARRA Amount: $
Investigator(s): Dongwon Lee dongwon@psu.edu (Principal Investigator) 
Organization: Pennsylvania State Univ University Park
201 Old Main, University Park, PA 16802-1503, (814)865-1372
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu IUSE Cyberlearn & Future Learn Tech 
Program Reference Code(s): 062Z 7645 9178 9251
Program Element Code(s): 099Y, 1998, 8020
Abstract: This is a project to study what works to help students learn more effectively in the context of the ASSISTments system. ASSISTments is an online system that provides both assistance to students and real time assessment data to teachers. ASSISTments now supports 100,000 students who have completed more than 12 million mathematics problems. The system uses teacher input and artificial intelligence to provide assistance to students who are attempting to solve mathematics problems. This project will increase the assistance provided by the teacher and machine learning by incorporating video suggestions, such as those produced by the Kahn academy, targeted to the needs of the student. The experimentation will take content from three Open Educational Resource textbooks that are openly licensed and free to schools.<br/><br/>More specifically, the researchers will identify a large collection of videos that address mathematics skills in the textbooks and will extract features of these videos including language complexity, speaking rate, and other features. These videos and features will be checked by both teachers and through a Mechanical Turk process for usability before they are presented to students. Additionally, the project will develop a suite of novel technologies for precision learning including fine grained video feature extraction, student feature learning from heterogeneous raw data, causal modeling, and fairness aware and causal relationship enhanced optimized personalized recommendation. The research will advance theoretical understanding of fundamental issues related to personalized learning and will enable data-driven experimentation of learning theories. Causal modeling will enable the researchers to learn the features of video that are correlated with learning effectiveness. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity and is co-funded by the Division of Undergraduate Education and the Division of Research on Learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934700
Title: Collaborative Research: Advancing Science with Accelerated Machine Learning
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $610,000
ARRA Amount: $
Investigator(s): Philip Harris pcharris@mit.edu (Principal Investigator) Erotokritos Katsavounidis (Co-Principal Investigator) Song Han (Co-Principal Investigator) 
Organization: Massachusetts Institute of Technology
77 MASSACHUSETTS AVE, CAMBRIDGE, MA 02139-4301, (617)253-1000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099y, 7231
Abstract: In the next generation of big science experiments, the demands for computing resources are expected to outstrip the capabilities of existing computing infrastructure. In light of this, a radical rethinking of the cyberinfrastructure is needed to contend with these developments. With the onset of deep learning, parallelized processing architectures have emerged as a solution. Combined with deep learning algorithms, parallelized processing architectures, in particular, Field Programmable Gate Arrays (FPGAs) have been shown to give large speedups in computing when compared with conventional CPUs. This project aims to bring machine learning based accelerated computing with FPGAs into the scientific community by targeting two big-data physics experiments: the Large Hadron Collider (LHC) and the Laser Interferometer Gravitational-wave  Observatory (LIGO). This project will push the frontiers of deep learning at scale, demonstrating the versatility and scalability of these methods to accelerate and enable new physics in the big data era. This project serves the national interest, as stated by NSF's mission, by promoting the progress of science. The PIs and their collaborators will build upon their recent work to design and exploit state-of-the-art neural network models for real-time data analytics, reducing overall computing latency. This new computing paradigm aims to significantly increase the processing capability at the LHC and LIGO, leading to an increased scientific output of these devices and,  potentially, foundational discoveries. The students to be mentored and trained in this research will interact closely with industry partners, creating new career opportunities, and strengthening synergies between academia and industry. In addition to sharing algorithms with the community through open source repositories, the team will continue to educate the community regarding credit and citation of scientific software.<br/><br/>In this project, the PIs will build upon their recent work developing high quality deep learning algorithms for real-time data analytics of time-series and image datasets using Field Programmable Gate Arrays (FPGAs) to accelerate low-latency inference of machine learning algorithms. The team will develop machine learning based acceleration tools focusing on FPGAs to be used within LIGO and the LHC experiments. The team's immediate goal is to take benchmark examples of LHC high level trigger processing and LIGO gravitational wave processing and construct demonstrators in each scenario. For this benchmark, they aim to design and implement an FPGA based accelerator that can perform low latency gravitational wave identification and LHC event reconstruction.  Additionally, the PIs aim to add the capability of graph based neural network accelerators for FPGAs. The open source tools to be developed as part of these activities will be readily shared with LIGO, LHC, and LSST. The project will create an advisory group, including members of large and small projects,  members of the neutrino physics, multi-messenger astronomy community, industry partners, computer scientists, and computational biologists. This project aims to bring together representatives of the different communities that will benefit from and can contribute to this work. The PIs will organize deep learning workshops and boot camps to train students and researchers on how to use and contribute to the framework, creating a wide network of contributors and developers across key science missions.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934884
Title: HDR TRIPODS: D4 (Dependable Data-Driven Discovery) Institute
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 12, 2019
Latest Amendment Date: August 23, 2021
Award Instrument: Continuing Grant
Program Manager: Tracy Kimbrel
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,531,995
ARRA Amount: $
Investigator(s): Hridesh Rajan hridesh@iastate.edu (Principal Investigator) Daniel Nettleton (Co-Principal Investigator) Eric Weber (Co-Principal Investigator) Pavan Aduri (Co-Principal Investigator) Chinmay Hegde (Co-Principal Investigator) 
Organization: Iowa State University
515 MORRILL RD, 1350 BEARDSHEAR, AMES, IA 50011-2105, (515)294-5225
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu WORKFORCE IN THE MATHEMAT SCI EPCN-Energy-Power-Ctrl-Netwrks EPSCoR Co-Funding 
Program Reference Code(s): 047Z 062Z 7926 9251
Program Element Code(s): 041Y, 099Y, 7335, 7607, 9150
Abstract: Data-driven discoveries are permeating critical fabrics of society. Unreliable discoveries lead to decisions that can have far-reaching and catastrophic consequences on society, defense, and the individual. Thus, the dependability of data-science lifecycles that produce discoveries and decisions is a critical issue that requires a new holistic view and formal foundations. This project will establish the Dependable Data Driven Discovery (D4) Institute at Iowa State University that will advance foundational research on ensuring that data-driven discoveries are of high quality. The activities of the D4 Institute will have a transformative impact on the dependability of data-science lifecycles. First, the problem definition itself will have a significant impact by helping future innovations beyond academia. While the notion of dependability is well-studied in the computer-systems literature, challenges in data science push the boundary of existing knowledge into the unknown. This institute's work will define D4, and increase data science's benefit to society by providing a transformative theory of D4. The second impact will come from the process of shared vocabulary development facilitated by this institute, and its result that would encourage experts across TRIPODS disciplines and domain experts to collaborate on common goals and challenges. Third, the institute will set research directions for D4 by providing funding for foundational research, which will have a separate set of impacts. Fourth, the institute will facilitate transdisciplinary training of a diverse cadre of data scientists through activities such as the Midwest Big Data Summer School and the D4 workshop.<br/> <br/>The project will advance the theoretical foundations of data science by fostering foundational research to enable understanding of the risks to the dependability of data-science lifecycles, to formalize the rigorous mathematical basis of the measures of dependability for data science lifecycles, and to identify mechanisms to create dependable data-science lifecycles. The project defines a risk to be a cause that can lead to failures in data-driven discovery, and the processes that plan for, acquire, manage, analyze, and infer from data collectively as the data-science lifecycle. For instance, an inference procedure that is significantly expensive can deliver late information to a human operator facing a deadline (complexity as a risk); if the data-science lifecycle provides a recommendation without an uncertainty measure for the recommendation, a human operator has no means to determine whether to trust the recommendation (uncertainty as a risk). Compared to recent works that have focused on fairness, accountability, and trustworthiness issues for machine learning algorithms, this project will take a holistic perspective and consider the entire data-science lifecycle. In phase I of the project the investigators will focus on four measures: complexity, resource constraints, uncertainty, and data freshness. In developing a framework to study these measures, this work will prepare the investigators to scale up their activities to other measures in phase II as well as to address larger portions of the data-science lifecycle. The study of each measure brings about foundational challenges that will require expertise from multiple TRIPODS disciplines to address.<br/><br/>This project is jointly funded by HDR TRIPODS and the Established Program to Stimulate Competitive Research (EPSCoR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940062
Title: Collaborative Research: Converging Genomics, Phenomics, and Environments Using Interpretable Machine Learning Models
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: July 14, 2022
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: June 30, 2023
Awarded Amount to Date: $483,022
ARRA Amount: $
Investigator(s): Patrick Heidorn heidorn@u.arizona.edu (Principal Investigator) Tyson Swetnam (Co-Principal Investigator) 
Organization: University of Arizona
888 N EUCLID AVE RM 510, TUCSON, AZ 85719-4824, (520)626-6000
NSF Directorate: CSE
Program(s): ICB: Infrastructure Capacity f HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 1165
Program Element Code(s): 085Y, 099Y
Abstract: Mitigating the effects of climate change on public health and conservation calls for a better understanding of the dynamic interplay between biological processes and environmental effects. The state-of-the-art, which has led to many important discoveries, utilizes numerical or statistical models for making predictions or performing in silico experimentation, but these techniques struggle to capture the nonlinear response of natural systems. Machine learning (ML) methods are better able to cope with nonlinearity and have been used successfully in biological applications, but several barriers still exist, including the opaque nature of the algorithm output and the absence of ML-ready data. This project seeks to significantly advance technologies in ML and create a new interdisciplinary field, computational ecogenomics. This will be accomplished by designing ML techniques for encoding heterogeneous genomic and environmental data and mapping them to multi-level phenotypic traits, reducing the amount of necessary training data, and then developing interactive visualizations to better interpret ML models and their outputs.  These advances will responsibly and transparently inform policy to maximize resources during this crucial window for planetary health, while revealing underlying biological mechanisms of response to stress and evolutionary pressure.<br/><br/>The long-term vision for this project is to develop predictive analytics for organismal response to environmental perturbations using innovative data science approaches and change the way scientists think about gene expression and the environment. The goal for this two-year award is to develop a proof-of-concept for an institute focused on predicting emergent properties of complex systems; an institute that would itself foster the development of many new sub-disciplines.  The core of this activity is developing a machine learning framework capable of predicting phenotypes based on multi-scale data about genes and environments.  Available data, ranging from simple vectors to complex images to sequences, will be ingested into this framework by applying proven semantic data integration tools and algorithmic data transformation methods.  The central hypothesis of this research is that deep learning algorithms and biological knowledge graphs will predict phenotypes more accurately across more taxa and more ecosystems than do current numerical and traditional statistical modeling methods.  The rationale for this project is that a timely investment in data science will push through a bottleneck in life science, accelerating discovery of gene-phenotype-environment relationships, and catalyzing a new computational discipline to uncover the complex "rules of life."<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934924
Title: HDR TRIPODS: Data Science Principles of the Human-Machine Convergence
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: August 29, 2019
Latest Amendment Date: July 12, 2022
Award Instrument: Continuing Grant
Program Manager: Tracy Kimbrel
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $1,591,503
ARRA Amount: $
Investigator(s): Fred Roberts froberts@dimacs.rutgers.edu (Principal Investigator) Cun-Hui Zhang (Co-Principal Investigator) Matthew Stone (Co-Principal Investigator) Konstantin Mischaikow (Co-Principal Investigator) Kostas Bekris (Co-Principal Investigator) 
Organization: Rutgers University New Brunswick
3 RUTGERS PLZA, NEW BRUNSWICK, NJ 08901-8559, (848)932-0150
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu Special Projects - CCF EPCN-Energy-Power-Ctrl-Netwrks Algorithmic Foundations Comm & Information Foundations 
Program Reference Code(s): 047Z 062Z 7926 9251
Program Element Code(s): 041Y, 099Y, 2878, 7607, 7796, 7797
Abstract: This project will develop a new transdisciplinary Institute on Data Science for Intelligent Systems and People Interaction referred to as DATA-INSPIRE. This institute is premised on the belief that advances in data science principles are needed to impact the emerging paradigm of intelligent machines and their convergence with human society, and in particular to further improve the performance and better explain the operation of such machines that can accomplish diverse, real-world tasks and interact effectively with people. Fundamental notions of data science that can enhance development of intelligent machines can impact pressing problems facing our planet: healthcare, transportation, urban systems, etc. DATA-INSPIRE will bring together mathematicians, statisticians, and computer scientists for transdisciplinary research projects, new educational initiatives, workshops, and other efforts designed to catalyze a new foundational data science community focused on the development of intelligent, interactive machines. It will prepare students for transdisciplinary foundational work in data science, aid curriculum development, and involve government and industrial partners in collaborations and to aid in understanding of workforce issues resulting from use of intelligent machines.<br/><br/>Intelligent machines, such as robots, are evolving from simple automata performing repetitive tasks in highly structured and enclosed workspaces to sophisticated, closed-loop systems capable of satisfying human specifications in dynamic environments that include people. To manage and master the operations of complex machines and their interactions with people, it is necessary to better understand and adapt the data that drive the algorithms that control them. DATA-INSPIRE will address the following challenges. (1) Failures in tasks such as autonomous driving or robotic surgery can have devastating consequences. Data-driven solutions are often opaque computational tools for which it is impossible to verify correctness or explain failures. Formal tools, integrated with data, are needed to remove ambiguity about what causes intelligent machines to perform in certain ways. (2) Data-driven solutions frequently depend critically on vast corpora of accurately labeled training instances, which can be difficult to collect for physical operations. Tools are needed to reduce machine learning methods' dependence on large amounts of task-specific supervision. (3) Most intelligent machines need to react to sensing data under critical deadlines, which, if not met, can jeopardize operations. Mathematical and statistical analyses of the dynamics of learning and control are needed to assist with more effective real-time decision making.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934405
Title: Collaborative Research: Framework for Integrative Data Equity Systems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $656,000
ARRA Amount: $
Investigator(s): Bill Howe billhowe@uw.edu (Principal Investigator) 
Organization: University of Washington
4333 Brooklyn Ave NE, Seattle, WA 98195-0001, (206)543-4043
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099y, 7231
Abstract: Data Science continues to have a transformative impact on Science and Engineering, and on society at large, by enabling evidence-based decision making, reducing costs and errors, and improving objectivity. The techniques and technologies of data science also have enormous potential for harm if they reinforce inequity or leak private information.  As a result, sensitive datasets in the public and private sector are restricted from research use, slowing progress in those areas that have the most to gain: human services in the public sector.  Furthermore, the misuse of data science techniques and technologies will disproportionately harm underrepresented groups across race, gender, physical ability, sexual orientation, education, and more. These data equity issues are pervasive, and represent an existential risk for the use of data-driven methods in science and engineering. This project will establish a  Framework for Integrative Data Equity Systems (FIDES): an Institute for the study of systems that enable research on sensitive data while preventing misuse and misinterpretation. <br/><br/>FIDES will enable interdisciplinary community convergence around data equity systems, with an initial study in critical domains such as mobility, housing, education, economic indicators, and government transparency, leading to the development of a novel data analytics infrastructure that supports responsibility in integrative data science.  Towards this goal, the project will address several technically challenging problems: (1) To be able to use data from multiple sources, risks related to privacy, bias, and the potential for misuse must be addressed. This project will develop principled methods for dataset processing to overcome these concerns.  (2) Individual datasets are difficult to integrate for use in advanced multi-layer network models.  This project considers methods to create pre-trained tensors over large collections of spatially and temporally coherent datasets, making them easier to incorporate while controlling for fairness and equity.  (3) Any dataset or model must be equipped with sufficient information to determine fitness for use, communicate limitations, and describe underlying assumptions.  This project will develop tools and techniques to produce "nutritional labels" for data and models, formalizing and standardizing ad hoc metadata approaches to provenance, specialized for equity issues. In addition to supporting methodological innovation in data science, the Institute will become a focal point for sharing expertise in data equity systems.  It will do so by establishing interfaces for interaction between data science and domain experts to promote expertise development and sharing of best practices, and by consistently supporting efforts on diversity and equity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741340
Title: BIGDATA: F: Scalable and Interpretable Machine Learning: Bridging Mechanistic and Data-Driven Modeling in the Biological Sciences
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 14, 2017
Latest Amendment Date: September 14, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $900,000
ARRA Amount: $
Investigator(s): Bin Yu binyu@stat.berkeley.edu (Principal Investigator) James Bentley Brown (Co-Principal Investigator) 
Organization: University of California-Berkeley
1608 4TH ST STE 201, BERKELEY, CA 94710-1749, (510)643-3891
NSF Directorate: CSE
Program(s): STATISTICS Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 8251
Program Element Code(s): 1269, 8083
Abstract: With the rapid advances in information technology, an age of rich data has dawned in nearly every scientific field. Such data hold the potential to guide decision-making and accelerate understanding of complex processes such as human development and disease progression. For instance, massive databases on gene expression and other molecular processes can be used to build models to predict the drivers of a disease. Predictive models are an important step in understanding these complex systems, but equally important is the human interpretability of such models, e.g. to derive mechanistic insights into what factors drive disease onset in order to identify an appropriate course of treatment.  Next Generation Sequencing (NGS) technologies have led to a profound shift in how biological data are collected, assaying individual genomic elements that act as part of organized, stereospecific groups to drive emergent biological phenomena. These modern data call for new statistics/data science principles and scalable algorithms to advance the frontier of science.<br/><br/>This project focuses on developing novel scalable statistical machine learning algorithms that are predictable, stable and interpretable, and can be used to guide decision-making and discovery in biological systems. This project aims to build insights into how individual genomic elements act in concert by developing interpretable and stable supervised learning algorithms with state of the art predictive accuracy along with scalable, open source software. Many machine learning algorithms with state of the art predictive accuracies are capable of learning complicated rules that might govern complex systems but are difficult for humans to interpret. The research builds on iterative Random Forests (iRF), an algorithm recently developed by the PIs that recovers the high-order, human interpretable, Boolean type interactions that are important parts of the state-of-the-art predictive accuracy in Random Forests. The proposed work will develop and validate approaches for refining interactions recovered by iRF to produce testable hypotheses for follow-up studies, along with inference methods to assess the uncertainty associated with these hypotheses. These approaches and methods will be implemented in Apache Spark to ensure scalability to massive datasets in genomics and beyond.  Implementation of the methods for the large-scale applications will leverage cloud computing resources provided through an agreement between commercial cloud service providers and NSF for the BIGDATA solicitation.

Award Number: 1837956
Title: BIGDATA: IA: Collaborative Research: Asynchronous Distributed Machine Learning Framework for Multi-Site Collaborative Brain Big Data Mining
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: September 10, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $780,000
ARRA Amount: $
Investigator(s): Heng Huang heng.huang@pitt.edu (Principal Investigator) Liang Zhan (Co-Principal Investigator) 
Organization: University of Pittsburgh
4200 5TH AVE, PITTSBURGH, PA 15260-0001, (412)624-7400
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Recent advances in multimodal brain imaging and high throughput genotyping and sequencing techniques provide exciting new opportunities to ultimately improve our understanding of brain structure and neural dynamics, their genetic architecture, and their influences on cognition and behavior. However, data privacy and security issues have inhibited data sharing across institutes. Emerging multi-site collaborative data analysis can address these issues and facilitate data and computing resource sharing. In collaborative data analysis, the participating institutes keep their own data, which are analyzed and computed locally, and only share the computed results by communicating with a server. The server communicates with all institutes and updates the local models such that the trained machine learning models indirectly use all data and are shared with all institutes. Although some distributed/parallel computation techniques were recently proposed to address big data mining problems, most of them are synchronous models. Asynchronous distributed learning methods are much more efficient, because they allow the server to update the model with information from only one worker node without waiting for slow worker nodes in each round. However, the convergence analysis for the asynchronous distributed algorithms is much more difficult due to the inconsistent variables update across nodes. Thus, it is challenging to design efficient distributed machine learning algorithms for collaborative big data analysis. The research objective of this project is to address the computational challenges in the emerging multi-site collaborative data mining for brain big data.<br/> <br/>This project seeks to harness the opportunities of designing new efficient asynchronous distributed machine learning algorithms with rigorous theoretical foundations for multi-site collaborative brain big data mining, creating large-scale computational strategies and effective software tools to reveal sophisticated relationships among heterogeneous brain data. This project designs the asynchronous distributed machine learning and principled big data mining models to conduct the comprehensive study of brain imaging genomics and connectomics. Specifically, the principal investigators investigate: 1) collaborative genotype and phenotype association study using new asynchronous doubly stochastic proximal gradient algorithms; 2) communication-efficient multi-site collaborative data integration models to integrate imaging genomics data for predicting outcomes of interest; 3) collaborative deep learning algorithm speedup by the asynchronous distributed algorithms with applications in temporal cognitive change prediction; and 4) new graph convolutional deep learning models for brain network mining. It is innovative to integrate new distributed machine learning and data-intensive computing with brain imaging genomics and connectomics that hold great promise for a systems biology of the brain. The developed methods and tools impact other neuroimaging, genomics, and neuroscience research, and enable investigators working on brain science to effectively test their scientific hypotheses. This project will also facilitate the development of novel educational tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934565
Title: Collaborative Research: Framework for Integrative Data Equity Systems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: June 08, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $762,301
ARRA Amount: $
Investigator(s): H Jagadish jag@umich.edu (Principal Investigator) Margaret Levenstein (Co-Principal Investigator) Olutayo Fabusuyi (Co-Principal Investigator) Robert Hampshire (Former Co-Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231 9102
Program Element Code(s): 099Y, 7231
Abstract: Data Science continues to have a transformative impact on Science and Engineering, and on society at large, by enabling evidence-based decision making, reducing costs and errors, and improving objectivity. The techniques and technologies of data science also have enormous potential for harm if they reinforce inequity or leak private information.  As a result, sensitive datasets in the public and private sector are restricted from research use, slowing progress in those areas that have the most to gain: human services in the public sector.  Furthermore, the misuse of data science techniques and technologies will disproportionately harm underrepresented groups across race, gender, physical ability, sexual orientation, education, and more. These data equity issues are pervasive, and represent an existential risk for the use of data-driven methods in science and engineering. This project will establish a  Framework for Integrative Data Equity Systems (FIDES): an Institute for the study of systems that enable research on sensitive data while preventing misuse and misinterpretation. <br/><br/>FIDES will enable interdisciplinary community convergence around data equity systems, with an initial study in critical domains such as mobility, housing, education, economic indicators, and government transparency, leading to the development of a novel data analytics infrastructure that supports responsibility in integrative data science.  Towards this goal, the project will address several technically challenging problems: (1) To be able to use data from multiple sources, risks related to privacy, bias, and the potential for misuse must be addressed. This project will develop principled methods for dataset processing to overcome these concerns.  (2) Individual datasets are difficult to integrate for use in advanced multi-layer network models.  This project considers methods to create pre-trained tensors over large collections of spatially and temporally coherent datasets, making them easier to incorporate while controlling for fairness and equity.  (3) Any dataset or model must be equipped with sufficient information to determine fitness for use, communicate limitations, and describe underlying assumptions.  This project will develop tools and techniques to produce "nutritional labels" for data and models, formalizing and standardizing ad hoc metadata approaches to provenance, specialized for equity issues. In addition to supporting methodological innovation in data science, the Institute will become a focal point for sharing expertise in data equity systems.  It will do so by establishing interfaces for interaction between data science and domain experts to promote expertise development and sharing of best practices, and by consistently supporting efforts on diversity and equity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939699
Title: HDR: DIRSE-IL: Collaborative Research: Harnessing data advances in systems biology to design a biological 3D printer: the synthetic coral
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $333,352
ARRA Amount: $
Investigator(s): Nastassja Lewinski nalewinski@vcu.edu (Principal Investigator) 
Organization: Virginia Commonwealth University
912 W FRANKLIN ST, RICHMOND, VA 23284-9040, (804)828-6772
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: Corals are important natural resources that are key to the ocean's vast biodiversity and provide economic, cultural, and scientific benefits. As a result of human activities, locally and globally, coral reefs are declining rapidly. The complexity of corals makes conserving and restoring reefs very challenging. Corals are made up of thousands of different organisms, including the animal host and the algae, bacteria, viruses, and fungi that coexist as a so-called holobiont. Thus, corals are more like cities than individual animals, as they provide factories, housing, restaurants, nurseries, and more for an entire ecosystem. This project brings together experts in computer science, materials science, and biology to harness the data revolution in biology with machine learning to study how corals grow and function, when viewed as if they were manufacturing sites in the ocean. The study will focus on three key coral capabilities: (1) they create calcium carbonate skeletons that provide 3D structures for diverse sea life to live in, (2) they can heal damage to their tissues, and, (3) they live with the other organisms in a process referred to as symbiosis. Through these remarkable abilities, corals can 'print' resources for themselves and hundreds of thousands of other species, just like a 3D printer. The goal of this project is to understand these processes well enough to control them in the lab. This project may allow finding new ways to help coral survival, by deciphering the reasons why certain conditions damage them and find ways of repairing them. Furthermore, by synthetically growing corals, new types of materials may be identified for manufacturing. This project offers an opportunity to educate a diverse scientific workforce and the public by creating and disseminating the outcomes of a convergent research environment and will train postdoctoral researchers, graduate, and undergraduate students. Results of this research will be made available to the broader scientific community through web interfaces, peer-reviewed publications and workshops/conferences and shared with the public through outreach activities online, at schools, and public aquariums.<br/>    <br/>Through convergence of three disciplines, computer science, material science and biology, this project will provide a data-driven framework and toolset to learn from, control, engineer, and manufacture a combined form of living material, the 'synthetic coral', thereby opening new avenues for material synthesis and manufacturing. The research methodology will offer new analytical approaches to identify and quantify the parameters that govern coral growth and foster innovative new tools for controlling their growth. To understand the key functions of coral biology of biomineralization, wound healing, and symbiosis, this research will : (1) harness and analyze large amounts of coral '-omics' data to decipher critical molecules and their interactions for the aforementioned key functions, (2) experimentally validate the resulting predictions in coral individuals and cell lines, (3) manipulate the material properties of the calcium carbonate structures of the coral individuals and cell lines, and (4) test the biological and physical interactions in a network model of the 'synthetic coral'. This project develops and integrates fundamental building blocks that are essential for  an integrated computational and experimental validation system. Specifically, using machine learning, diverse data will be harnessed to identify physical conditions (e.g., surface characteristics), environmental conditions (e.g., temperature, pH), and key biological constituents (e.g., small molecule ligands and proteins encoded in the DNA) that are correlated to key structural and functional properties of the coral holobiont. These predicted conditions and molecules will be verified experimentally by perturbing individual coral nodes in a network of a 3D printed array of intact corals or their constituent cells and measuring their effects on the network of interactions and resulting structures. The results from this prediction-validation cycle will then be transferred back as input to manufacture novel adaptive materials fully embracing the organic/inorganic interface. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2118201
Title: HDR Institute: Institute for Data Driven Dynamical Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2021
Latest Amendment Date: February 18, 2022
Award Instrument: Cooperative Agreement
Program Manager: Amy Walton
Start Date: October 01, 2021
End Date: September 30, 2026
Awarded Amount to Date: $6,100,000
ARRA Amount: $
Investigator(s): Eric Toberer etoberer@mines.edu (Principal Investigator) Ryan Adams (Co-Principal Investigator) Alvitta Ottley (Co-Principal Investigator) Steven Lopez (Co-Principal Investigator) Adji Bousso Dieng (Co-Principal Investigator) 
Organization: Colorado School of Mines
1500 ILLINOIS ST, GOLDEN, CO 80401-1887, (303)273-3000
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT PROJECTS 
Program Reference Code(s): 054Z 060Z 062Z 094Z 095Z 8037 8249 8396 8399 8400 8604 9102 9216 9263
Program Element Code(s): 041Y, 099Y, 1712, 1978
Abstract: From molecules to robots, designing for dynamics has common theoretical underpinnings despite differences in length and time scale.  However, such research is often overwhelmed by the high dimensional design space.  The Institute for Data-Driven Dynamical Design addresses the challenge of prediction of dynamical processes in materials, including ion and molecular transport, catalytic pathways, and phase transformations in metamaterials, with a focus on discovering fundamentally new mechanisms and pathways.  This research represents a paradigm shift from traditional material efforts involving incremental improvements in ground-state and steady-state properties.  Developments in the data sciences target (i) strategies for encoding complex structures and mechanistic pathways for machine intelligence, (ii) new predictive capabilities for evolving systems, and (iii) advances in visualization and integrating machine and human expertise.  Fueling these data science developments are large-scale simulations of dynamical processes across high dimensional design spaces. Experimental validation of these large-scale simulations addresses both end-product prediction and mechanistic pathways therein.  The Institute's data science innovations may advance fields both within and beyond STEM involving complex time-evolving systems including molecular biology, atmospheric science, geophysics, and physical cosmology.  The Institute seeks to grow and unite the dispersed data-driven design community.  Long-term growth is sought through outreach activities involving (i) high school coding schools, (ii) undergraduate involvement in data-rich research, and (iii) a post-baccalaureate bridge program that introduces students to data sciences and motivate them to pursue higher degrees.  Data-driven design community activities include (i) interdisciplinary summer schools and workshops, (ii) a Fellows program to collaboratively grow and disseminate the Institute?s developments, and (iii) dedicated efforts to create open-source software for the design community.  Throughout these efforts, the Institute actively seeks to recruit, retain, and graduate a diverse array of students in STEM.  <br/><br/>This virtual Institute seeks to design complex dynamical materials and structures through the union of machine and human intelligence. To learn dynamical behavior and ultimately discover new mechanisms, three core data science needs are addressed: (i) new representations and learning architectures that capture and encode the spatial arrangement, interactions, and temporal evolution of complex materials and geometrical structures, (ii) efficient exploration of high dimensional, time-dependent design spaces, and (iii) new visual analytics tools to quantitatively incorporate human-in-the-loop design feedback. Advances in each of these areas form a virtuous cycle that accelerates discovery of new materials, driven by new mechanisms. This Institute converges an interdisciplinary team focused on four design spaces at their `tipping point', where large quantities of dynamical data can be readily created: (i) crystalline solids with tailored ion transport for fuel cells and batteries, (ii) pressure-sensitive metamaterials for robotics, (iii) light driven catalytic reactions for chemical production, and (iv) synthesis and assembly of porous frameworks for chemical separations. These four areas are testbeds for cyberinfrastructure development for the broader scientific community. Interwoven throughout these activities are dedicated activities to build a new generation of STEM talent at the intersection of data science and the physical sciences/engineering and to broaden participation in STEM through targeted outreach.<br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR).  The award by the Office of Advanced Cyberinfrastructure is jointly supported by the Divisions of Chemistry, Materials Research, and Mathematical Sciences within the NSF Directorate for Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939505
Title: Collaborative Research: Biology-guided neural networks for discovering phenotypic traits
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $592,152
ARRA Amount: $
Investigator(s): Ali Maga ali.maga@seattlechildrens.org (Principal Investigator) 
Organization: Seattle Children's Hospital
4800 SAND POINT WAY NE, SEATTLE, WA 98105-3916, (206)987-2005
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: Unlike genetic data, the traits of organisms such as their visible features, are not available in databases for analysis.  The lack of machine-readable trait data has slowed progress on four grand challenge problems in biology: predicting the genes that generate traits, understanding the patterns of evolution, predicting the effects of ecological change, and species identification. This project will use advances in machine learning and machine-readable biological knowledge to create a new method to automatically identify traits from images of organisms.  Images of organisms are widely available, and this new method could be used to rapidly harvest traits that could be used to solve the grand challenges in biology.  Large image collections and corresponding digital data from fishes will be used in this study because of the extensive resources available for these organisms. The new machine learning model can be generalized to other disciplines that have similar machine-readable knowledge, and it will help in explaining the results of artificial intelligence, thus advancing the field of computer science.  The new method stands to benefit society in application to areas such as agriculture or medicine, where trait discovery from images is critical in disease diagnosis.  The project will support the education of students and postdocs in biology, computer science, and information science.  It will disseminate its findings through workshops, presentations, publications, and open access to data and code that it produces. <br/><br/>This project will leverage advances in state-of-the-art machine learning to develop a novel class of artificial neural networks that can exploit the machine readable and predictive knowledge about biology that is available in the form of phylogenies and anatomy ontologies.  These biology-guided neural networks are expected to automatically detect and predict traits from specimen images, with little training data. Image-based trait data derived from this work will enable progress in gene-phenotype mapping to novel traits and understanding patterns of evolution. The resulting machine learning model can be generalized to other disciplines that have formally structured knowledge, and will contribute to advances in computer science by going beyond black-box learning and making important advances toward Explainable Artificial Intelligence.  It may be extended to applied areas, such as agriculture or the biomedical domain. The research will be piloted using teleost fishes because of many high-quality data resources (digital images, evolutionary trees, anatomy ontology). Methods for automated metadata quality assessment and provenance tracking will be developed in the course of this project to ensure the results and processes are verifiable, replicable and reusable.  These will broadly impact the many domains that will adopt machine learning as a way to make discoveries from images. This convergent research will accelerate scientific discovery across the biological sciences and computer science by harnessing the data revolution in conjunction with biological knowledge.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940330
Title: Collaborative Research: Converging Genomics, Phenomics, and Environments Using Interpretable Machine Learning Models
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: July 06, 2022
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: June 30, 2023
Awarded Amount to Date: $494,580
ARRA Amount: $
Investigator(s): Pankaj Jaiswal jaiswalp@science.oregonstate.edu (Principal Investigator) Anne Thessen (Former Principal Investigator) Anne Thessen (Co-Principal Investigator) Pankaj Jaiswal (Former Co-Principal Investigator) 
Organization: Oregon State University
1500 SW JEFFERSON ST, CORVALLIS, OR 97331-8655, (541)737-4933
NSF Directorate: CSE
Program(s): ICB: Infrastructure Capacity f HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 1165
Program Element Code(s): 085Y, 099Y
Abstract: Mitigating the effects of climate change on public health and conservation calls for a better understanding of the dynamic interplay between biological processes and environmental effects. The state-of-the-art, which has led to many important discoveries, utilizes numerical or statistical models for making predictions or performing in silico experimentation, but these techniques struggle to capture the nonlinear response of natural systems. Machine learning (ML) methods are better able to cope with nonlinearity and have been used successfully in biological applications, but several barriers still exist, including the opaque nature of the algorithm output and the absence of ML-ready data. This project seeks to significantly advance technologies in ML and create a new interdisciplinary field, computational ecogenomics. This will be accomplished by designing ML techniques for encoding heterogeneous genomic and environmental data and mapping them to multi-level phenotypic traits, reducing the amount of necessary training data, and then developing interactive visualizations to better interpret ML models and their outputs.  These advances will responsibly and transparently inform policy to maximize resources during this crucial window for planetary health, while revealing underlying biological mechanisms of response to stress and evolutionary pressure.<br/><br/>The long-term vision for this project is to develop predictive analytics for organismal response to environmental perturbations using innovative data science approaches and change the way scientists think about gene expression and the environment. The goal for this two-year award is to develop a proof-of-concept for an institute focused on predicting emergent properties of complex systems; an institute that would itself foster the development of many new sub-disciplines.  The core of this activity is developing a machine learning framework capable of predicting phenotypes based on multi-scale data about genes and environments.  Available data, ranging from simple vectors to complex images to sequences, will be ingested into this framework by applying proven semantic data integration tools and algorithmic data transformation methods.  The central hypothesis of this research is that deep learning algorithms and biological knowledge graphs will predict phenotypes more accurately across more taxa and more ecosystems than do current numerical and traditional statistical modeling methods.  The rationale for this project is that a timely investment in data science will push through a bottleneck in life science, accelerating discovery of gene-phenotype-environment relationships, and catalyzing a new computational discipline to uncover the complex "rules of life."<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934813
Title: HDR TRIPODS: Collaborative Research: Institute for Data, Econometrics, Algorithms and Learning
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 10, 2019
Latest Amendment Date: September 10, 2019
Award Instrument: Standard Grant
Program Manager: Zhengdao Wang
Start Date: September 15, 2019
End Date: August 31, 2023
Awarded Amount to Date: $154,569
ARRA Amount: $
Investigator(s): Chao Gao chaogao@galton.uchicago.edu (Principal Investigator) Varun Gupta (Co-Principal Investigator) 
Organization: University of Chicago
5801 S ELLIS AVE, CHICAGO, IL 60637-5418, (773)702-8669
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) is a multi-discipline (computer science, statistics, economics, electrical engineering, and operations research) and multi-institution (Northwestern University, Toyota Technological Institute at Chicago, and University of Chicago) collaborative institute that focuses on key aspects of the theoretical foundations of data science.   The institute will support the study of foundational problems related to machine learning, high-dimensional data analysis and optimization in both strategic and non-strategic environments.  The primary activity of the institute will be thematically focused quarters which will coordinate graduate course work with workshops and external visitors.  The institute will facilitate collaboration between Chicago-area institutions through a number of initiatives, and across multiple disciplines. Several components of the research agenda have direct applications areas, and the PIs will involve practitioners in development economics, online markets, public policy, as well as data scientists.   <br/><br/>The research areas supported by the institute focus on three broad themes:  (1) High dimensional data analysis, to address algorithmic and statistical challenges in dealing with high dimensional data, and investigate topics like metric embeddings, sketching, and problems in unsupervised learning; (2) Data Science in Strategic Environments, to address computational and information theoretic challenges in econometric models of strategic behavior like inference on high-dimensional structural parameter spaces,  dealing with unobserved heterogeneity, partial identification, and machine learning in econometrics; and (3) Machine learning and optimization, to address foundational questions in both continuous and discrete optimization and its use in machine learning including topics like representation learning, robustness in learning, and provable bounds for non-convex optimization.   Initially, six research topics will be selected that tie interests across the institutions: inference and data science on networks; theory of deep learning; incentives in shared data infrastructure; robustness in high-dimensional statistics; high-dimensional data analysis; and algorithms for partially identified models.  There will be special quarters (fall and spring) where the Institute will bring together investigators, postdocs, and Ph.D. students to focus on one of the topics.  In the following quarter (winter and summer) teams will continue research that advance the proposal topics.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934752
Title: A Framework for Data Intensive Discovery in Multimessenger Astrophysics
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: March 28, 2022
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $2,800,000
ARRA Amount: $
Investigator(s): Patrick Brady prbrady@uwm.edu (Principal Investigator) David Kaplan (Co-Principal Investigator) Mario Juric (Co-Principal Investigator) Chad Hanna (Co-Principal Investigator) 
Organization: University of Wisconsin-Milwaukee
3203 N DOWNER AVE STE 273, MILWAUKEE, WI 53211-3153, (414)229-4853
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu WoU-Windows on the Universe: T 
Program Reference Code(s): 062Z 069Z
Program Element Code(s): 099Y, 107Y
Abstract: This is the conceptualization phase for a Scalable Cyberinfrastructure Institute for Multi-Messenger Astrophysics (SCIMMA).  SCIMMA is a collaboration between data scientists, computer scientists, astronomers, astro-particle physicists, and gravitational wave physicists.  It leverages NSF investments in astronomical and multi-messenger facilities, and in advanced cyberinfrastructure.  Along with achieving key scientific goals and consulting with relevant collaborations and stakeholders, the conceptualization of SCIMMA includes developing algorithms, databases, and computing and networking cyberinfrastructure, to support both observations and their interpretation.  This phase includes prototyping a SCIMMA education and outreach center, and presenting accessible digests of the goals and achievements of the institute.  The team will be preparing novel curricula at the undergraduate and graduate levels, and the group will support graduate student fellowships for short duration projects.<br/><br/>Multi-messenger astrophysics (MMA) is a data-intensive science in its infancy, but already providing revolutionary insights.  At the current tipping point, timely investments in cyberinfrastructure for key MMA facilities will enable a torrent of new discoveries.  A key goal for SCIMMA is the efficient, rapid, and routine discovery of electromagnetic emission via coordinated follow-up of gravitational wave events.  This real-time science needs co-analysis of disparate datasets and the autonomous coordination of diverse follow-up in a seamless fashion.  SCIMMA balances rapid prototyping, novel algorithm development, and software sustainability.  The rapid-prototype team, tasked to use existing resources to meet immediate goals, is closely integrated with the cyberfoundations team, which will architect new algorithms and deploy new technologies.  Software sustainability is a foundational element of the design process, since the institute and its supporting cyberinfrastructure will persist for a decade or more, and both teams will adopt this principle.  SCIMMA in full operation will provide the community with consulting services and bring both existing and new MMA activities to maximal interoperability.<br/><br/>This project is part of the National Science Foundation's Big Idea activities in Harnessing the Data Revolution (HDR) and Windows on the Universe - The Era of Multi-Messenger Astrophysics (WoU-MMA).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924146
Title: HDR DSC: Collaborative Research: Modernizing Water and Wastewater Treatment through Data Science Education & Research (MoWaTER)
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 09, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,157,928
ARRA Amount: $
Investigator(s): Amanda Hering mandy_hering@baylor.edu (Principal Investigator) Douglas Nychka (Co-Principal Investigator) Greg Hamerly (Co-Principal Investigator) Tzahi Cath (Co-Principal Investigator) Michael Poor (Co-Principal Investigator) 
Organization: Baylor University
700 S UNIVERSITY PARKS DR, WACO, TX 76706-1003, (254)710-3817
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Social Psychology Cross-Directorate  Activities 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1332, 1397
Abstract: Collecting data is easier than ever before, but extracting actionable information from it is more challenging than ever. Society needs a workforce who understands data science and can apply it to creatively solve problems. In this project, a novel, introductory data science course and undergraduate summer research program will be designed to motivate students early in their academic studies to pursue careers in data science by connecting them with authentic projects and stakeholders. The data-rich industry of water and wastewater treatment (W/WWT) will provide an extensive portfolio of tractable projects. Although data are easy to collect and abundant in the W/WWT industry, methods of monitoring, maintenance, and sensor calibration lag behind the state-of-the art. This funded work will create opportunities to critically assess the suitability of current methods and produce creative alternatives. Recruiting from diverse and underrepresented populations of students, this project will produce the next generation of data scientists who are ready to fill "mid-level" data science positions. At the same time, this project will help W/WWT facility operators reduce costs and improve water quality by utilizing the information in their data.<br/><br/>Statisticians, computer scientists, and environmental engineers at Baylor University and Colorado School of Mines (Mines) will collaborate to (i) develop a three-credit, prerequisite-free sophomore-level course; (ii) organize a five-week data science summer program; and (iii) cultivate relationships with W/WWT stakeholders and community colleges (CC). The course will introduce data science through inquiry-driven modules to attract students who may not have previously considered a data science career. It will be offered in parallel at both universities each year and will weave not only W/WWT facility problems throughout but also problems associated with water scarcity, such as climate change, agricultural demands, and urbanization. The summer program will be developed with a singular focus on solving W/WWT problems with data. A diverse cohort will be recruited from Baylor, Mines, and CC partners. A one-week pre-program coding boot camp will be offered to bolster skills. PIs will curate and oversee team projects designed to develop data acumen, teamwork, and communication. Established relationships with urban and rural W/WWT utilities; manufacturers of W/WWT systems for decentralized use; W/WWT treatment operators; and academic partners will provide data and problem context. All project data will be well documented and made freely available. The student and program-level outcomes will be formally assessed, with results disseminated through publication in peer-reviewed journals and conference presentations. Methods for optimal operation and monitoring developed by student teams will be publicized through instructional videos and technical reports to our W/WWT stakeholders and rural industry service organizations.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1633295
Title: BIGDATA: F: Collaborative Research: From Visual Data to Visual Understanding
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 22, 2016
Latest Amendment Date: September 07, 2021
Award Instrument: Standard Grant
Program Manager: Hector Munoz-Avila
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $350,000
ARRA Amount: $
Investigator(s): Ashok Krishnamurthy ashok@renci.org (Principal Investigator) Tamara Berg (Former Principal Investigator) 
Organization: University of North Carolina at Chapel Hill
104 AIRPORT DR STE 2200, CHAPEL HILL, NC 27599-5023, (919)966-3411
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: The field of visual recognition, which focuses on creating computer algorithms for automatically understanding photographs and videos, has made tremendous gains in the past few years. Algorithms can now recognize and localize thousands of objects with reasonable accuracy as well as identify other visual content, such as scenes and activities. For instance, there are now smart phone apps that can automatically sift through a user's photos and find all party pictures, or all pictures of cars, or all sunset photos. However, the type of "visual understanding" done by these methods is still rather superficial, exhibiting mostly rote memorization rather than true reasoning. For example, current algorithms have a hard time telling if an image is typical (e.g., car on a road) or unusual (e.g., car in the sky), or answering simple questions about a photograph, e.g., "what are the people looking at?", "what just happened?", "what might happen next?" A central problem is that current methods lack the data about the world outside of the photograph. To achieve true human-like visual understanding, computers will have to reason about the broader spatial, temporal, perceptual, and social context suggested by a given visual input. This project is using big visual data to gather large-scale deep semantic knowledge about how events, physical and social interactions, and how people perceive the world and each other. The research focuses on developing methods to capture and represent this knowledge in a way that makes it broadly applicable to a range of visual understanding tasks. This will enable novel computer algorithms that have a deeper, more human-like, understanding of the visual world and can effectively function in complex, real-world situations and environments. For example, if a robot can predict what a person might do next in a given situation, then the robot can better aid the person in their task. Broader impacts will include new publicly-available software tools and data that can be used for various visual reasoning tasks. Additionally, the project will have a multi-pronged educational component, including incorporating aspects of the research in the graduate teaching curriculum, undergraduate and K-12 outreach, as well as special mentoring and focused events for advancement of women in computer science.<br/><br/>The main technical focus of this project is to advance computational recognition efforts toward producing a general human-like visual understanding of images and video that can function on previously unseen data, unseen tasks and settings. The aim of this project is to develop a new large-scale knowledge base called the visual Memex that extracts and stores vast set of visual relationships between data items in a multi-graph representation, with nodes corresponding to data items and edges indicating different types of relationships. This large knowledge base will be used in a lambda-calculus-powered reasoning engine to make inferences about visual data on a global scale. Additionally, the project will test computational recognition algorithms on several visual understanding tasks designed to evaluate progress on a variety of aspects of visual understanding, including: linguistic (evaluating our understanding about imagery through language tasks such as visual question-answering), to purely visual (evaluating our understanding of spatial context through visual fill-in-the-blanks), to temporal (evaluating our temporal understanding by predicting future states), to physical (evaluating our understanding of human-object and human-scene interactions by predicting affordances). Datasets, knowledge base, and evaluation tools will be hosted on the project web site (http://www.tamaraberg.com/grants/bigdata.html).

Award Number: 1940270
Title: Collaborative Research: Integrating Physics and Generative Machine Learning Models for Inverse Materials Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: July 28, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $312,016
ARRA Amount: $
Investigator(s): Fuchang Gao fuchang@uidaho.edu (Principal Investigator) 
Organization: Regents of the University of Idaho
875 PERIMETER DR MS 3020, MOSCOW, ID 83844-9803, (208)885-6651
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 054Z 062Z 8396 8399 9150
Program Element Code(s): 099Y
Abstract: This project is aimed to address a grand challenge in data-intensive materials science and engineering to find better materials with desired properties, often with the goal to enhance performance in specific applications. This project addresses this grand challenge with a specific focus on finding metal organic framework (MOF) materials that are used to separate gas mixtures and finding better battery materials for energy storage. The PIs will combine theoretical methods from statistical mechanics and condensed-matter physics, and physics-based models, to generate information-rich materials data which is integrated with generative machine learning (ML) algorithms to search a complex chemical design space efficiently and to train deep learning models for fast screening of materials properties. This project will be carried out by a multidisciplinary collaboration involving researchers from physics, materials science and engineering, computer science, and mathematics. The resulting multidisciplinary environment fosters training the next generation data savvy scientists who will engage in collaborative multidisciplinary research.  <br/><br/>Existing approaches for computational design of metal organic frameworks (MOF) and solid-state electrolyte materials are largely based on screening of known materials or enumerative search of hypothetical materials. This project develops a new approach that integrates first principles calculations, experimental data and abundant data generated by physics-based models to train generalized antagonistic network (GAN) models for efficient search of the materials design space, and to train deep convolutional neural network (DCNN) models for fast and accurate screening of properties of the GAN-generated candidate materials. Additionally, graph-based GAN models will be used for MOF topology exploration and can be applied to other nanomaterials designs. More specifically, the investigators will: 1) develop and exploit physics-based models for fast calculation of properties such as diffusivity, ion conductivity, and mechanical stability; 2) develop generative adversarial network (GAN) models with built-in physics rules for efficient exploration of the chemical design space for both MOF materials and solid electrolytes; 3) use persistence homology and Bravais lattice sequence representations of MOF materials and solid electrolytes, respectively, to build Deep Convolutional Neural Network (DCNN) models for fast and accurate prediction of the physical properties of generated materials; 4)  apply high-level quantum-mechanical calculations for verification of discovered materials. Accomplishments from this project will lead to accelerated discovery of novel nanostructured materials for gas separation and energy storage, materials for lithium-ion batteries, novel data-driven scheme for materials design, and theoretical methods enabling implementation of advanced data science techniques. The highly interdisciplinary collaboration will offer students unique opportunities to interact with a variety of disciplines, and training the next-generation scientists with the mindset for multidiscipline collaborations. Educational and outreach activities will be developed and undertaken in conjunction with the proposed research activities.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1922516
Title: HDR DSC: Engaging Undergraduates in Data and Decisions Research at the Engineering/Biology Interface
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,186,084
ARRA Amount: $
Investigator(s): David Schmale dschmale@vt.edu (Principal Investigator) Shane Ross (Co-Principal Investigator) Michael Wolyniak (Co-Principal Investigator) Birol Ozturk (Co-Principal Investigator) Eddie Red (Co-Principal Investigator) Kelly Mallari (Former Co-Principal Investigator) 
Organization: Virginia Polytechnic Institute and State University
300 TURNER ST NW, BLACKSBURG, VA 24060-3359, (540)231-5281
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Big Data Science &Engineering 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 8083
Abstract: Recent studies have documented the overall failure of undergraduate programs to prepare students for the complex, professional lives that lie ahead for them. This project addresses a number of these shortfalls, training students to navigate the more complex and uncertain professional terrain associated with interdisciplinary scholarship. The project will launch a unique data sciences program at Virginia Tech (coordinating organization), Morehouse College (HBCU for men, Georgia, implementing organization), Bennett College (HBCU for women, North Carolina, implementing organization), and Hampden-Sydney College (all-male college, Virginia, implementing organization). Our ultimate goal is to provide interdisciplinary education and research opportunities in data and decision science for undergraduate students who are experts in a core discipline of engineering or biology, but who are also proficient in the alternate discipline. Undergraduates from biology and engineering will take classes and conduct research in data science at the engineering/biology interface. A new collaborative, multi-university capstone course "Data and Decisions at the Engineering/Biology Interface" will be launched simultaneously at all four universities. This new course will be driven by the needs of stakeholders from agriculture, conservation, search and rescue, water quality, transportation in inclement weather, and global health and emergency relief.<br/><br/>The program will provide unique research opportunities in data and decision science for at least 75 students over 3 years, with about half coming from the two HBCUs. Multi-university student teams (comprised of biologists and engineers) will work together to identify broad social, global, economic, cultural and technical needs/constraints, and determine ways in which their complementary technical skills contribute to addressing complex data science grand challenges at the engineering/biology interface. The teams will submit their data science challenge ideas using sensor-based assets and computational-based assets, competing for slots to participate in a coordinated field campaign in which they will collect data, and learn to make decisions from these data. Team projects will be developed in response to stakeholder needs, using sensor assets available from the participating universities and stakeholders. Students will become well-grounded in the language and tools of computational modeling and data analytics, including machine learning, data-driven discovery of equations and causality, clustering, and neural networks. Students will learn to communicate effectively with fellow students, policymakers, and the public. Following their data sciences experiences, the students are expected to: (1) be conversant with data science research in a second discipline, open to its methods, culture, and perspectives; (2) be able to integrate the second discipline into sustainable new data science research; and (3) conduct interdisciplinary data science research with team members from other fields. The program will provide insights into the attitudes of students towards interdisciplinary data science research, and explore how conceptions of collaboration and career path are affected by their participation in the program.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838207
Title: BIGDATA: IA: A multi-level approach for global optimization of the surveillance and control of infectious disease in the swine industry
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: August 03, 2021
Award Instrument: Standard Grant
Program Manager: Wendy Nilsen
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $1,616,000
ARRA Amount: $
Investigator(s): Beatriz Martinez Lopez beamartinezlopez@ucdavis.edu (Principal Investigator) Xin Liu (Co-Principal Investigator) 
Organization: University of California-Davis
1850 RESEARCH PARK DR, STE 300, DAVIS, CA 95618-6153, (530)754-7700
NSF Directorate: CSE
Program(s): Info Integration & Informatics Big Data Science &Engineering 
Program Reference Code(s): 062Z 7364 8083 9102 9251
Program Element Code(s): 7364, 8083
Abstract: The United States livestock industry has an enormous socio-economic impact contributing to annual sales of $180 billion and 550,000 direct jobs. Its sustainability and success rely on the maintenance of good livestock health, high productivity, and efficiency. This requires effective analytical methods, prediction models, and decision tools. While a vast amount of data has been collected in all production processes, the integration and usage of such data to better inform decisions in livestock health has remained circumstantial. It is usually restricted to simple descriptive statistics or molecular analyses for specific aspects of animal breeding and pathogen diagnostics. The goal of this project is to develop a new, multi-scale, approach to bridge the gap between the data availability and its effective usage. The project will focus on the swine industry and its most economically devastating disease, the Porcine Reproductive and Respiratory Syndrome (PRRS). This will not only have a direct beneficial impact in the swine industry but will contribute to the better manage other livestock health problems, saving producers and US livestock industry millions of dollars yearly. This is the first principled decision framework for the livestock industry that integrates multi-level data to predict disease dynamics, detect changes in farm status, and optimize the use of testing, treatment and vaccination strategies. As a consequence, it is expected to improve animal health and welfare and secure the sustainability of US agriculture and food systems by providing a data-driven decision framework and tools that push the frontier of precision epidemiology. The outcome of this project will be widely disseminated through our education and extension program (BIGDATA-4- HEALTH) and the integration of methods in the Disease BioPortal platform. PIs have well integrated the research and education programs and will continue to do so. The project will generate new curriculum for multiple classes in computer science, animal science and veterinary science and will involve undergraduate and graduate students.<br/><br/>The project proposes a principled data-driven decision framework for systematic PRRS prevention and control, based on the multi-level data sources collected during swine production, using novel data mining and machine learning techniques. The objectives are: 1) Early detection through efficient testing using a proactive and cost sensitive testing framework. 2) Systematic PRRS prevention and control by effective integration of testing, vaccination, and biosecurity implementation at a production system level. 3) Real- world experimentation and algorithm evaluation using both large-scale numerical evaluation with real traces and small-scale experimentations and real-time validation in five demonstration swine operations. 4) Education and extension program (BIGDATA-4-HEALTH) with training materials and technology transfer activities and the expansion of our user-friendly Disease BioPortal platform to facilitate the use of the developed methods to all industry stakeholders, researchers, and the general public. The intellectual merits of this proposal are multi-folds: the research team will develop novel mechanisms that advance the state-of-the-art in data-driven decision making algorithms. To reduce exploration cost, efficient situation-aware exploration techniques that addresses the fundamental exploration-exploitation tradeoff in multi-armed bandits and reinforcement learning will be developed, To handle missing data, novel compressive sensing algorithms designed to better manage accuracy disparity will be investigated. Finally, to balance the cost-accuracy tradeoff, efficient means to integrate simulation and experimentation will be explored, which only has been limited studied in the literature. Furthermore, the value of these tools for the early detection of diseases at farm and system level using historical data and prospective real world experimentation will be also evaluated and demonstrated. While focusing on swine production, this work provides the foundations and can be adapted to improve animal health of other livestock species and to advance in other disciplines facing the same data challenges.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934745
Title: The Learner Data Institute: Harnessing The Data Revolution To Make The Learning Ecosystem More Effective, Efficient, and Engaging
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: July 07, 2022
Award Instrument: Continuing Grant
Program Manager: Finbarr Sloane
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $2,584,309
ARRA Amount: $
Investigator(s): Vasile Rus vrus@memphis.edu (Principal Investigator) Philip Pavlik Jr. (Co-Principal Investigator) Stephen Fancsali (Co-Principal Investigator) Dale Bowman (Co-Principal Investigator) Deepak Venugopal (Co-Principal Investigator) 
Organization: University of Memphis
101 WILDER TOWER, MEMPHIS, TN 38152-3520, (901)678-3251
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Discovery Research K-12 
Program Reference Code(s): 062Z 7645 9150
Program Element Code(s): 099y, 7645
Abstract: The project will lay the foundation for a Learner Data Institute, to further understanding of how people learn, how to improve adaptive instructional systems, and how to create learning systems that are more effective, efficient, engaging, and affordable.  An interdisciplinary team of people from academia, industry, and government will work together to improve the effectiveness of the learning ecosystem for the benefit of its hundreds of thousands of students, prepare teachers for the future learning ecosystem, and contribute to accelerating discovery and transforming the education ecosystem through the use of big data and cloud computing. The project will impact a number of communities including learning sciences, data science, artificial intelligence in education, assessment, educational data mining, and machine learning. The outcomes will be widely disseminated through training materials, workshops, tutorials, and a course for researchers and practitioners. <br/><br/>The two-year conceptualization phase of the Learner Data Institute will focus on building a strong community of researchers, define research priorities, and develop interdisciplinary prototype solutions that address critical student learning, cyber-learning, and learning engineering challenges. Based on modern theories of learning and recent advances in educational technologies, artificial intelligence, sensing technologies, signal processing, and data science, the team will explore new frontiers in multi-faceted (cognitive, motivational, emotional, etc.) learner data collection, analysis, and visualization in order to understand and possibly transform how learners learn with technology.  The multi-disciplinary team will address core research questions such as: (1) how to transform a widely distributed group of interdisciplinary researchers, developers, and practitioners into a community of practice that can fully exploit the data revolution for the benefit of the learners and educational stakeholders; (2) how adaptive instructional systems (AISs) and data science can be used as a research vehicle to further understanding of how learners learn; (3) how the human-technology partnership with data and data science can be used to improve learners? and teachers? ability to employ technology in ways that facilitate learning and improve the effectiveness, scalability, and affordability of AISs in order to maximize the potential of learning ecologies of the future; and (5) more generally, how to extend the frontiers of data science to include: new methods of data collection and design; more interpretable, knowledge-rich machine learning methods (e.g., by combining Deep Learning with Markov Logic); scalable new inference and learning algorithms symmetries and joint dependencies in the data; and methods for identifying causal mechanisms from unstructured, semi-structured, and structured data. While the project will address core educational tasks in the context of online and blended learning environments, the proposed data science methods and models are generally applicable to other instructional contexts as well as other science and engineering areas. All models, software, processes, and data used in the project will be documented and disseminated for everyone to use and build on the outcomes of the project.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Directorate for Education and Human Resources.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1740776
Title: TRIPODS: Transdisciplinary Research Institute for Advancing Data Science (TRIAD)
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: August 23, 2017
Latest Amendment Date: February 27, 2020
Award Instrument: Continuing Grant
Program Manager: Huixia Wang
Start Date: September 01, 2017
End Date: August 31, 2022
Awarded Amount to Date: $1,604,238
ARRA Amount: $
Investigator(s): Xiaoming Huo xiaoming@isye.gatech.edu (Principal Investigator) Dana Randall (Co-Principal Investigator) Prasad Tetali (Co-Principal Investigator) Srinivas Aluru (Co-Principal Investigator) C. F. Jeff Wu (Co-Principal Investigator) 
Organization: Georgia Tech Research Corporation
926 DALNEY ST NW, ATLANTA, GA 30332-, (404)894-4819
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: This project creates the Transdisciplinary Research Institute for Advancing Data Science (TRIAD) at the Georgia Institute of Technology.  TRIAD aims to integrate research and education in mathematical, statistical, and algorithmic foundations for data science. Analysis of massive, dynamic, noisy, and complex data arising in virtually every sphere of human activity is a pressing challenge of our time, and an area of great importance for its economic and societal impact. TRIAD will address the growing challenges in establishing the foundations of data science, much of which lies at the intersection of computer science, statistics, and mathematics. TRIAD's intellectual focus is to design and build transdisciplinary research programs that provide an enabling and cross-fertilizing platform of ideas and stakeholders (including theoreticians/scientists from domain sciences and users of technology). TRIAD hosts focused working groups, national and international workshops, and organized innovation labs. Participants include senior, mid-career, and junior faculty members, postdoctoral fellows, graduate and senior undergraduate students, and data science practitioners at large. All TRIAD activities involve interdisciplinary personnel from the three foundational disciplines. TRIAD deploys information technology and communication infrastructure to quickly and efficiently disseminate its research and activities, while the research community at large can easily access and comment/critique TRIAD's choice of research programs and topics. The institute aims to create an intellectual atmosphere that connects theoreticians and practitioners, scientists, and engineers from across the nation and worldwide on a regular basis.<br/><br/>TRIAD enriches careers of participants ranging from undergraduate students to senior researchers from around the nation. Postdoctoral fellows and graduate students are introduced to collaborative research in the institute activities and through workshops. TRIAD makes prudent efforts to reach out to diverse communities, including participants from smaller colleges and institutions serving under-represented minorities. TRIAD actively engages in outreach through public lectures, press releases, and dissemination via other internet channels. TRIAD works with associated professional societies to provide stimulus to data-science-related initiatives. Additional activities (such as customized workshops) will combine interactive projects and field trips to acquaint undergraduate and/or high school students from all over the U.S. with data-science-related techniques and the themes of TRIAD's year-long programs. Every effort will be made to make products and lectures available online and to enable remote participation.  Funds for the project come from CISE Computing and Communications Foundations and MPS Division of Mathematical Sciences.

Award Number: 1940223
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $260,925
ARRA Amount: $
Investigator(s): Mila Sherman msherman@isenberg.umass.edu (Principal Investigator) 
Organization: University of Massachusetts Amherst
COMMONWEALTH AVE, AMHERST, MA 01003-, (413)545-0698
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934915
Title: HDR TRIPODS: UIC Foundations of Data Science Institute
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 11, 2019
Latest Amendment Date: August 17, 2021
Award Instrument: Continuing Grant
Program Manager: Zhengdao Wang
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Lev Reyzin lreyzin@uic.edu (Principal Investigator) Tanya Berger-Wolf (Former Principal Investigator) Natasha Devroye (Co-Principal Investigator) William Perkins (Co-Principal Investigator) Anastasios Sidiropoulos (Co-Principal Investigator) Elena Zheleva (Co-Principal Investigator) Lev Reyzin (Former Co-Principal Investigator) 
Organization: University of Illinois at Chicago
809 S MARSHFIELD RM 520, CHICAGO, IL 60612-4305, (312)996-2862
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The project creates a collaborative research institute combining aspects of mathematics, statistics, computer science, and engineering to study the foundations of data science at the University of Illinois at Chicago (UIC).  The institute will be a collaboration between three departments: Computer Science (CS), Mathematics, Statistics, and Computer Science (MSCS), and Electrical and Computer Engineering (ECE). The institute will leverage the wide range of expertise among the investigators on this project in the three departments to bring the theoretical foundations of data science closer to the practice of data science.  This involves studying idealized models of data, understanding inherent computational limits associated to these idealized models, and then developing models and methods that are robust to realistic models of uncertainty.  The institute will also focus on training the next generation of researchers and will leverage the diversity of UIC, a large urban public research-intensive university with one of the most diverse student bodies in the country.<br/><br/>The research aims to push the boundaries of the theory of data science by both gaining deeper understanding of idealized models and by building a theory around realistic models of data and computation.  The themes pursued by this institute will include 1) the representation and structure of data; 2) machine learning and complexity; and 3) robustness and privacy.  These themes will serve to link the theory and application of data science and to provide opportunities for the investigators to pool their expertise across the three disciplines of theoretical computer science, mathematical sciences, and electrical engineering.  The specific activities of the research institute will include hosting themed research workshops, developing the UIC data science curriculum across the three departments, and fostering regional and industrial collaborations through partnerships with the Midwest Big Data Hub and the Discovery Partners Institute.  Broader impacts of the institute will include applications of the proposed research to practical data science problems, the development of interdisciplinary data science courses spanning multiple departments, and increasing participation, especially of underrepresented groups, by broadly recruiting students from UIC's diverse community to study data science.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939987
Title: Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $399,859
ARRA Amount: $
Investigator(s): Linbing Wang wangl@vt.edu (Principal Investigator) 
Organization: Virginia Polytechnic Institute and State University
300 TURNER ST NW, BLACKSBURG, VA 24060-3359, (540)231-5281
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc Info Integration & Informatics 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1640, 7364
Abstract: The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.<br/><br/>The project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741536
Title: BIGDATA: F: Critical Visualization Technologies for Analyzing and Understanding Big Network Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 16, 2017
Latest Amendment Date: April 13, 2018
Award Instrument: Standard Grant
Program Manager: Hector Munoz-Avila
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $576,000
ARRA Amount: $
Investigator(s): Kwan-Liu Ma ma@cs.ucdavis.edu (Principal Investigator) Robert Faris (Co-Principal Investigator) 
Organization: University of California-Davis
1850 RESEARCH PARK DR, STE 300, DAVIS, CA 95618-6153, (530)754-7700
NSF Directorate: CSE
Program(s): Info Integration & Informatics Big Data Science &Engineering 
Program Reference Code(s): 7364 7433 8083 9251
Program Element Code(s): 7364, 8083
Abstract: Big data presents both opportunities and challenges to all fields of study and practice. Visualization has been proven effective as a knowledge discovery and storytelling tool for big data. This project aims to develop new visualization technologies for big network data that will both illustrate empirical findings and generate new discoveries. Although many network visualization techniques and tools have been introduced, visualizing large, dynamic networks to extract key entities, structures, and trends from the network data remains a challenging task. Most of the existing network visualization solutions were not designed for handling dynamic networks and are too slow for interactive exploration of large networks. This project will closely examine the integral parts of a holistic solution for the problem of big network visualization.  The research study will be largely driven by the data analysis needs of sociological studies such as finding hidden associations between multiple networks; however, the project team will also investigate the solution's applicability in areas such as emergency management, life science and cyber security. The resulting technologies are expected to drastically enhance one's ability to explore and understand large, complex dynamic networks for knowledge discovery, critical decision making, and storytelling. This research effort is timely because of the explosive growth of data and common use of graphs as both the internal data structure and a visual representation in data-driven applications. Those who must deal with large, complex dynamic network data for their work will benefit from the advanced visualization technologies resulted from this research project. Students participating in this project will acquire strong interdisciplinary research skills for real-world problem solving. <br/><br/>This research underscores the importance of providing a comprehensive solution to the understanding of big data containing complex relations, structure, and trends. Primary research topics are: (1) Visual depiction and exploration of big network data; (2) Modeling and visualizing dynamic network data; (3) Visual monitoring and analysis of live, streaming network data; and (4) Provenance and storytelling with dynamic network data.  This project will explore and integrate new network modeling, reduction, and visualization techniques for analyzing large, multivariate dynamic graphs. The resulting research innovations will both enhance existing methods and investigate new approaches to dynamic network visual analytics and drastically improve their usability for real-world applications. The targeted applications, emergency service and sociology, present the project team with some of the most challenging problems to address in making sense of heterogeneous dynamic big networks data. The collaborating domain experts are fully committed to participating in the evaluation work, which promises to produce usable technologies that will enable respondents to look at the data in new ways and uncover intricate relations among different entities/events for critical decision making and mitigation planning. The project results will be disseminated to the visualization community and beyond through annual conferences, workshops, and tutorials, and also through the project website which will include project status updates and resulting images, videos, and prototype software.

Award Number: 1934962
Title: HDR TRIPODS: Collaborative Research: Foundations of Greater Data Science
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 10, 2019
Latest Amendment Date: August 25, 2021
Award Instrument: Continuing Grant
Program Manager: Huixia Wang
Start Date: September 15, 2019
End Date: August 31, 2023
Awarded Amount to Date: $814,165
ARRA Amount: $
Investigator(s): Mujdat Cetin mujdat.cetin@rochester.edu (Principal Investigator) Daniel Gildea (Co-Principal Investigator) Daniel Stefankovic (Co-Principal Investigator) Alex Iosevich (Co-Principal Investigator) Tong Tong Wu (Co-Principal Investigator) 
Organization: University of Rochester
500 JOSEPH C WILSON BLVD, ROCHESTER, NY 14627-0001, (585)275-4031
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: The University of Rochester and Cornell University jointly establish the Greater Data Science Cooperative Institute (GDSC). The GDSC is based on two founding tenets. The first is that enduring advances in data science require combining techniques and viewpoints across electrical engineering, mathematics, statistics, and theoretical computer science. The investigators' goal is to forge a consensus perspective on data science that transcends any individual field. The second is that data-science research must be grounded in an application domain. This helps to ensure that assumptions about the availability and quality of data are realistic, and it allows methodological results to be tested experimentally as well as theoretically. As such, the GDSC aims to consider applications in medicine and healthcare, an important application domain and one for which advances in data science can have a direct, positive impact on society. The GDSC aims to tackle foundational questions that are motivated by problems in healthcare, obtain solutions that fuse domain expertise with application-agnostic methodologies, and ultimately yield scientific advances that impact the way healthcare is provided. The GDSC aims to leverage the physical proximity of the two institutions, and the unique strengths in each of the core disciplines above and in medicine.<br/><br/>The GDSC's cross-disciplinary research directions include: (i) Topological Data Analysis. The challenges that high-dimensional, incomplete, and noisy data present are great, but in many applications, exploiting the topological nature of the problem is possible. GDSC aims to develop new fundamental methods and theory to rigorously explore the promise of this unique approach. (ii) Data Representation. Data compression, embeddings, and dimension reduction play a fundamental role in data science. Inspired by new core challenges in biomedical imaging, genomics, and neural-spike training data, GDSC aims to develop novel source models and distortion measures, and ultimately seek a unifying theoretical framework across domains and disciplines. (iii) Network & Graph Learning. Many of the fundamental challenges in applying data science to non-homogeneous populations are best explored through a network or graph structure. GDSC aims to develop new techniques for parameter-dependent eigenvalue problems in spectral community detection, density-estimation methods on networks, and a theoretical framework for time-varying graphical models to study dynamic variable relations in time-evolving networks. (iv) Decisions, Control & Dynamic Learning. Sequential decisions are high-stakes in medicine. GDSC aims to utilize systems and control-engineering methods to improve health and disease management and develop new foundational theories and methods for label-efficient active learning and dynamic treatment regimes. (v) Diverse & Complex Modalities. Big data is complex data, and major new innovations are needed. GDSC aims to develop theoretical frameworks for inference under computational and privacy constraints and for high-dimensional data without parametric model assumptions. Text, image, and audio data present further challenges. To address such challenges, GDSC aims to explore transition systems for graph parsing of natural language and new fusion approaches for fully multimodal analysis. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2130835
Title: Collaborative Research: Physics-Based Machine Learning for Sub-Seasonal Climate Forecasting
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: May 03, 2021
Latest Amendment Date: May 03, 2021
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: May 15, 2021
End Date: August 31, 2023
Awarded Amount to Date: $241,766
ARRA Amount: $
Investigator(s): Arindam Banerjee arindamb@illinois.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: While the past few decades have seen major advances in weather forecasting on time scales of days to about a week, making high quality forecasts of key climate variables such as temperature and precipitation on sub-seasonal time scales, the time range between 2 weeks and 2 months, continues to challenge operational forecasters. Skillful climate forecasts on sub-seasonal time scales would have immense societal value in areas such as agricultural productivity, hydrology and water resource management, transportation and aviation systems, and emergency planning for extreme events such as Atlantic hurricanes and midwestern tornadoes. In spite of the scientific, societal, and financial importance of sub-seasonal climate forecasting, progress on the problem has been limited. The project has initiated a systematic investigation of physics-based machine learning with specific focus on advancing sub-seasonal climate forecasting. In particular, this project is developing novel machine learning (ML) approaches for sub-seasonal forecasting by leveraging both limited observational data as well as vast amounts of dynamical climate model output data. Further, the project is focusing on improving the dynamical climate models themselves based on ML with specific emphasis on learning model parameterizations suitable for accurate sub-seasonal forecasting. The principles, models, and methodology for physics-based machine learning being developed in the project will benefit other scientific domains which rely on dynamical models. The project is establishing a public repository of a benchmark dataset for sub-seasonal forecasting to engage the wider data science community and accelerate progress in this critical area. The project is training a new generation of interdisciplinary scientists who can cross the traditional boundaries between computer science, statistics, and climate science.<br/><br/>The project works with two key sources of data for sub-seasonal forecasting: limited amounts of observational data and vast amounts of output data from dynamical model simulations, which capture physical laws and dynamics based on large coupled systems of partial differential equations (PDEs). The project is investigating the following central question: what is the best way to learn simultaneously from limited observational data and imperfect dynamical models for improving sub-seasonal forecasts? The project is building a framework for physics-based machine that has two inter-linked components: (1) deduction, in which ML models are trained on dynamical model outputs as well as limited observations, and (2) induction, in which ML models are used to improve dynamical models. Across the two components, the project is making fundamental advances in learning representations, functional gradient descent, transfer learning, derivative-free optimization and multi-armed bandits, Monte Carlo tree search, and block coordinate descent. On the climate side, the project is building an idealized dynamical climate model and doing an in depth investigation on learning suitable parameterizations for the dynamical model with ML methods to improve forecast accuracy in the sub-seasonal time scales. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934668
Title: Collaborative Research: Knowledge Guided Machine Learning: A Framework for Accelerating Scientific Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: July 02, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: September 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $399,745
ARRA Amount: $
Investigator(s): Imme Ebert-Uphoff iebert@colostate.edu (Principal Investigator) Elizabeth Barnes (Co-Principal Investigator) 
Organization: Colorado State University
601 S HOWES ST, FORT COLLINS, CO 80521-2807, (970)491-6355
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The success of machine learning (ML) in many applications where large-scale data is available has led to a growing anticipation of similar accomplishments in scientific disciplines. The use of data science is particularly promising in scientific problems involving processes that are not completely understood. However, a purely data-driven approach to modeling a physical process can be problematic. For example, it can create a complex model that is neither generalizable beyond the data on which it was trained nor physically interpretable. This problem becomes worse when there is not enough training data, which is quite common in science and engineering domains.  A machine learning model that is grounded by explainable theories stands a better chance at safeguarding against learning spurious patterns from the data that lead to non-generalizable performance. This is especially important when dealing with problems that are critical and associated with high risks (e.g., extreme weather or collapse of an ecosystem).  Hence, neither an ML-only nor a scientific knowledge-only approach can be considered sufficient for knowledge discovery in complex scientific and engineering applications. This project is developing novel techniques to explore the continuum between knowledge-based and ML models, where both scientific knowledge and data are integrated synergistically. Such integrated methods have the potential for accelerating discovery in a range of scientific and engineering disciplines. This project will train interdisciplinary scientists who are well versed in such methods and will disseminate results of the project via peer-reviewed publications, open-source software, and a series of workshops to engage the broader scientific community.<br/><br/>This project aims to develop a framework that uses the unique capability of data science models to automatically learn patterns and models from data, without ignoring the treasure of accumulated scientific knowledge. Specifically, the project builds the foundations of knowledge-guided machine learning (KGML) by exploring several ways of bringing scientific knowledge and machine learning models together using pilot applications from four domains: aquatic ecodynamics, climate and weather, hydrology, and translational biology. These pilot applications were selected because they are at tipping points where knowledge-guided machine learning can have a transformative effect.  KGML has the potential for providing scientists and engineers with new insights into their domains of interest and will require the development of innovative new machine learning approaches and architectures that can incorporate scientific principles. Scientific knowledge, KGML methods, and software developed in this project could potentially be extended to a wide range of scientific applications where mechanistic (also known as process-based) models are used.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940118
Title: Collaborative Research: Integrating Physics and Generative Machine Learning Models for Inverse Materials Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: July 28, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $424,386
ARRA Amount: $
Investigator(s): Jianzhong Wu jwu@engr.ucr.edu (Principal Investigator) 
Organization: University of California-Riverside
900 UNIVERSITY AVE, RIVERSIDE, CA 92521-9800, (951)827-5535
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 054Z 062Z 8396 8399
Program Element Code(s): 099Y
Abstract: This project is aimed to address a grand challenge in data-intensive materials science and engineering to find better materials with desired properties, often with the goal to enhance performance in specific applications. This project addresses this grand challenge with a specific focus on finding metal organic framework (MOF) materials that are used to separate gas mixtures and finding better battery materials for energy storage. The PIs will combine theoretical methods from statistical mechanics and condensed-matter physics, and physics-based models, to generate information-rich materials data which is integrated with generative machine learning (ML) algorithms to search a complex chemical design space efficiently and to train deep learning models for fast screening of materials properties. This project will be carried out by a multidisciplinary collaboration involving researchers from physics, materials science and engineering, computer science, and mathematics. The resulting multidisciplinary environment fosters training the next generation data savvy scientists who will engage in collaborative multidisciplinary research.  <br/><br/>Existing approaches for computational design of metal organic frameworks (MOF) and solid-state electrolyte materials are largely based on screening of known materials or enumerative search of hypothetical materials. This project develops a new approach that integrates first principles calculations, experimental data and abundant data generated by physics-based models to train generalized antagonistic network (GAN) models for efficient search of the materials design space, and to train deep convolutional neural network (DCNN) models for fast and accurate screening of properties of the GAN-generated candidate materials. Additionally, graph-based GAN models will be used for MOF topology exploration and can be applied to other nanomaterials designs. More specifically, the investigators will: 1) develop and exploit physics-based models for fast calculation of properties such as diffusivity, ion conductivity, and mechanical stability; 2) develop generative adversarial network (GAN) models with built-in physics rules for efficient exploration of the chemical design space for both MOF materials and solid electrolytes; 3) use persistence homology and Bravais lattice sequence representations of MOF materials and solid electrolytes, respectively, to build Deep Convolutional Neural Network (DCNN) models for fast and accurate prediction of the physical properties of generated materials; 4)  apply high-level quantum-mechanical calculations for verification of discovered materials. Accomplishments from this project will lead to accelerated discovery of novel nanostructured materials for gas separation and energy storage, materials for lithium-ion batteries, novel data-driven scheme for materials design, and theoretical methods enabling implementation of advanced data science techniques. The highly interdisciplinary collaboration will offer students unique opportunities to interact with a variety of disciplines, and training the next-generation scientists with the mindset for multidiscipline collaborations. Educational and outreach activities will be developed and undertaken in conjunction with the proposed research activities.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1802017
Title: BIGDATA: Collaborative Research: IA: Big Data Analytics for Optimized Planning of Smart, Sustainable, and Connected Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: May 15, 2018
Latest Amendment Date: June 24, 2021
Award Instrument: Standard Grant
Program Manager: David Corman
Start Date: August 21, 2017
End Date: August 31, 2022
Awarded Amount to Date: $427,414
ARRA Amount: $
Investigator(s): Wangda Zuo wangda.zuo@psu.edu (Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 8083
Program Element Code(s): 8083
Abstract: Transforming villages, towns, and cities into smart, connected, and sustainable communities is one of the most critical technological challenges of the coming decade. Realizing this vision is contingent upon enabling existing community infrastructure such as transportation, communications, and energy systems, to seamlessly integrate sustainable components such as renewable sources, smart sensors, and electric vehicles. Such an integration will ensure that tomorrow's communities are truly sustainable and connected by exhibiting desirable qualities that include: a) zero energy, in that they are self-sufficient in their energy production, b) zero outage, in that communication links across the community are ultra-reliable and experience significantly low interruption, and c) zero congestion, in that the traffic congestion is minimized across the community. With this overarching vision, the goal of this project is to develop a new planning framework for smart, connected and sustainable communities that allows meeting such zero-energy, zero-outage, and zero-congestions goals by optimally deciding on how, when, and where to deploy or upgrade a community's infrastructure. These decisions will be driven by massive volumes of community data, stemming from multiple sources that can include mobility, energy, traffic, communication demands, and other socio-technological information, to make informed decisions on how to gradually and organically transform a community into a fully sustainable and truly connected environment.  The scale and heterogeneity of this problem necessitates the need for innovation in the tools used to process, analyze, and visualize heterogeneous data, as well as the data-aware metrics used to monitor the performance of this community infrastructure. One key element of this research is creation of a virtual testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging real-world big data sets from Virginia Tech and a zero-energy community in Florida as well as other sources, such as the DOE.   The testbed is intended to be open access and will be able to support both research at host institution as well as other users requiring non-proprietary multi-domain open-data sets.  The holistic nature of this research is thus expected to catalyze the global deployment of sustainable and connected communities. The proposed research will be complemented by a smart community big data challenge event that will enable broad community participation. The educational plan includes new big data-centric courses, as well as a large-scale involvement of graduate and undergraduate students in big data and smart communities research. Broad dissemination is ensured via open-source software and periodic workshops and tutorials. K-12 outreach events will be organized to attract under-represented student groups to big data research.<br/><br/>This transformative research will lay the theoretical and practical foundations of smart, connected, and sustainable communities by developing the first big data-driven holistic approach to joint planning, optimization, and deployment of community infrastructure for systems of critical importance, such as communication, energy, and transportation networks. By bringing together interdisciplinary domain experts from data science, electrical engineering, and civil and architectural engineering, this research will yield several innovations: 1) Novel big data techniques for faithfully creating spatio-temporal models for smart communities that integrate data from heterogeneous sources and shed light on the composition and operation of a given smart community, 2) Novel, data-driven performance metrics that advance powerful mathematical tools from stochastic geometry to explicitly quantify the health of smart communities via tractable notions of zero energy, zero outage, and zero congestion, 3) Advanced analytical tools that bring forward novel ideas from optimization theory to devise the most effective strategies for deploying, upgrading, and operating various community infrastructure nodes, given the scale, dynamics, and structure of both the data and the community, and 4) A virtual smart community testbed that can accurately reconstruct, simulate, and evaluate the theoretical framework by leveraging open non-proprietary real-world big data sets.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838179
Title: BIGDATA: F: Random and Adaptive Projections for Scalable Optimization and Learning
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 11, 2018
Latest Amendment Date: July 13, 2020
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $1,032,000
ARRA Amount: $
Investigator(s): Clayton Scott clayscot@umich.edu (Principal Investigator) Mert Pilanci (Co-Principal Investigator) Jeffrey Fessler (Co-Principal Investigator) Laura Balzano (Co-Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9251
Program Element Code(s): 8083
Abstract: Massive data sets typically have structure that allows them to be compressed with little loss in information. Examples include image, video, and audio data, as reflected by the ubiquitous .jpg, .mpeg, and .mp3 file formats, respectively. A major goal of modern data science is to exploit this compressibility to enable data processing algorithms to run more efficiently, thereby reducing the amount of data that is discarded or left unanalyzed. In other words, data scientists aim to adapt their algorithms to operate directly on the compressed data without loss in performance. Projections are important computational tool for effecting compression, but thus far they have only been incorporated into a handful of data processing algorithms. This project aims to substantially increase the range of data processing algorithms that can benefit from projections, and is specifically motivated by applications to medical image processing, computational biology, and analysis of surveillance video. The project will result in algorithms that are broadly applicable across the whole of data science. Furthermore, this research will support the cross-disciplinary development of a diverse cohort of PhD and undergraduate students at the University of Michigan, and the development of a graduate-level course on large-scale optimization for machine learning at the University of Michigan.<br/><br/>The technical aims of the project are divided into two thrusts. The first thrust develops a general approach for incorporating random projections into iterative optimization solvers for broad classes of optimization problems arising in machine learning. Our work focuses on nonconvex problems such as matrix factorization, manifold optimization, and training neural networks, building on recent work by the project team and others on convex problems. In particular, we will extend the principle of iterative sketching, which has been developed for convex optimization, to nonconvex problems. This principle finds ways to insert sketches (random projections) into iterative algorithms so as to reduce memory or computational complexity, while leveraging structures in the data to avoid losses in performance. The second thrust develops new adaptive projections for improved statistical and computational performance in big data, leveraging the algorithms developed under the first thrust. In particular, this thrust will develop new methods for supervised and streaming principle components analysis, and for learning sketches for optimization problems that must be solved repeatedly, as in medical image formation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940203
Title: Collaborative Research: I-AIM: Interpretable Augmented Intelligence for Multiscale Material Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: September 14, 2019
Award Instrument: Standard Grant
Program Manager: Giovanna Biscontin
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $418,000
ARRA Amount: $
Investigator(s): WaiChing Sun wsun@columbia.edu (Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Special Initiatives 
Program Reference Code(s): 062Z 085E 8021
Program Element Code(s): 099y, 1642
Abstract: The ability to model, predict, and improve the mechanical performance of engineering materials such as polymers, composites, and alloys can have a significant impact on manufacturing, with important economic and societal benefits. As advanced computational algorithms and data science approaches become available, they can be harnessed to disrupt the current approaches to materials modeling, and allow for the design and discovery of new high-strength, high-performance materials for manufacturing. Bringing together multidisciplinary teams of researchers can maximize the impact of these new tools and techniques. This Harnessing the Data Revolution Institutes for Data-Intensive Research in Science and Engineering (HDR-I-DIRSE) award supports the conceptualization of an Institute to develop novel data science methods, address fundamental scientific questions of Materials Engineering and Manufacturing, and build such multidisciplinary teams. The project will apply novel data science methods to advance the analysis of large sets of structural data of composite materials and alloys from the atomic scale to correlate with and predict mechanical properties. The methods are based on machine learning techniques and uncertainty quantification, and will help uncover underlying structural features in the materials that determine the properties and performance. The methods and results will help accelerate the development of ultra-high strength and lightweight carbon-based composites for aerospace applications, and multi-element superalloys for more durable engine parts, by navigating in the large possible design space and providing faster predictions than experiments and traditional simulation methods. The project will also lead to new methods and computational algorithms that will become publicly available. The investigators will train graduate and undergraduate students from various disciplines with a focus on engaging women and minorities in STEM fields, develop short courses that integrate novel Materials Science and Engineering applications and Data Science methods, and foster vertical integration of interdisciplinary research from undergraduate students to senior scientists.<br/><br/>This project aims at building an effective and interpretable learning framework for materials data across scales to solve a major challenge in current data-driven materials design. The combined Materials Science and Data Science approaches will synergistically contribute to the development and use of interpretable and physics-informed data science methodologies to gain new understanding of mechanical properties of polymer composites and alloys, with the potential to be expanded into different property sets and different systems. The PIs will utilize available data efficiently through combination with physical rules and prior knowledge, to develop an interpretable augmented intelligent system to learn principles behind the association of input structures with material properties with uncertainty quantification. The interconnected tasks involve the (1) collection and curation of large amounts of computational and experimental data for polymer/carbon nanotube composites and alloys from open data sources and targeted calculations and experiments, (2) the development of geometric and topological methods incorporating physical principles to generate a better, more sensitive low-dimensional representation of the multidimensional data and characterize the parameter space related to mechanical properties, (3) the development of a Bayesian deep reinforcement learning framework to generate interpretable knowledge graphs that depict the relational knowledge among physical quantities with uncertainty quantification, and (4) the prediction of mechanical properties to reveal design principles to improve materials performance, evaluate and validate the methods, and develop software for dissemination. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity and is co-funded by the Division of Civil, Mechanical and Manufacturing Innovation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1633318
Title: BIGDATA: Collaborative Research: F: RDMA-Based Datacenter Networks for Online Big Data Applications
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2016
Latest Amendment Date: July 28, 2021
Award Instrument: Standard Grant
Program Manager: Almadena Chtchelkanova
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $295,000
ARRA Amount: $
Investigator(s): Balajee Vamanan bvamanan@uic.edu (Principal Investigator) 
Organization: University of Illinois at Chicago
809 S MARSHFIELD RM 520, CHICAGO, IL 60612-4305, (312)996-2862
NSF Directorate: CSE
Program(s): Special Projects - CCF Big Data Science &Engineering 
Program Reference Code(s): 7433 7942 8083 9251
Program Element Code(s): 2878, 8083
Abstract: This project addresses the challenge of achieving extreme low latency in datacenter networks for Online Big Data (OLBD) applications which are critical workloads in datacenter computing. Remote Direct Memory Access (RDMA), which is a promising alternative to traditional TCP, significantly reduces datacenter network latencies by about an order-of-magnitude. However, RDMA adoption poses two major challenges as RDMA suffers from performance fragility under congestion, and  RDMA incurs either wasted memory or significant programmer burden for typical OLBD traffic. This project develops two novel networking technologies -- Blitz and RIMA -- which enable scalable datacenter networks that achieve the low latency benefits of RDMA while avoiding its drawbacks (performance fragility, programmer burden, and wasted memory).<br/><br/>Blitz addresses performance fragility by decoupling edge-congestion and in-network congestion. Blitz handles edge-congestion using receiver-directed congestion control (RDCC) unlike prior approaches where senders have to infer sending rates indirectly from round-trip-times and/or dropped packets. RDCC enables accurate and fast (within-one-round-trip-time) convergence, which leads to lower latency and higher throughput. Blitz handles transient in-network congestion by deflecting packets along longer yet less-congested paths.<br/>Remote Indirect Memory Access (RIMA)  addresses the second challenge by enabling reactive, on-demand memory allocation as opposed to RDMAs proactive memory allocation for the worst case, which minimizes the memory footprint without programmer effort. Together, Blitz and RIMA enable extreme low datacenter network latency for OLBD applications. The project will extensively involve Ph.D, Masters, and undergraduate students in cross-layer research activities. Results from the projects will be broadly disseminated via publication in scientific conferences.

Award Number: 2123343
Title: Collaborative Research: HDR DSC: Infusion of data science and computation into engineering curricula
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 05, 2021
Latest Amendment Date: November 02, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $354,127
ARRA Amount: $
Investigator(s): Rebecca Napolitano nap@psu.edu (Principal Investigator) Gregory Pavlak (Co-Principal Investigator) Ryan Solnosky (Co-Principal Investigator) Houtan Jebelli (Co-Principal Investigator) Wesley Reinhart (Co-Principal Investigator) Yuqing Hu (Former Co-Principal Investigator) Robert Kimel (Former Co-Principal Investigator) Nathan Brown (Former Co-Principal Investigator) 
Organization: Pennsylvania State Univ University Park
201 Old Main, University Park, PA 16802-1503, (814)865-1372
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a curricular framework for data science education and workforce development that is transferable between diverse institutions, so STEM-related programs can plug and play data science lessons with existing curricula without much overhead. These lessons will be created in conjunction with community stakeholders and industry partners to ensure a focus on real-world problem solving and include student organizations in course development to promote flexible learning pathways. The proposed additions to undergraduate STEM education will provide an evidence-based blueprint for best practices in integrating data science with existing engineering curricula. Implementation across multiple engineering departments will result in a significant impact on society through the training of a diverse, globally competitive STEM workforce with high data literacy. <br/><br/>The objectives of this project are to (1) facilitate data science education and workforce development for engineering and related topics, (2) provide opportunities for students to participate in practical experiences where they can learn new skills in a variety of environments, and (3) expand the data science talent pool by enabling the participation of undergraduate students with diverse backgrounds, experiences, skills, and technical maturity in the Data Science Corps. This work will support the Data Science Corps objective of building capacity for education and workforce development to harness the data revolution at local, state, and national levels. The institutions gathered for this project will develop training programs and curate datasets that will be made available so they can be included in undergraduate instruction nationwide. Furthermore, the training materials will be shared with industry partners, facilitating workforce development. The project team will develop a website to house data science training programs, didactic datasets, and other resources for educators. These resources are intended to reduce barrier to entry for faculty seeking to incorporate data science into their instruction, as recruiting and retaining faculty to create and teach integrated introductory courses in data science has been recognized as a significant hurdle by the National Academies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741390
Title: BIGDATA:F: Statistical Learning with Large Dynamic Tensor Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 29, 2017
Latest Amendment Date: July 05, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2023
Awarded Amount to Date: $1,000,000
ARRA Amount: $
Investigator(s): Rong Chen rongchen@stat.rutgers.edu (Principal Investigator) Cun-Hui Zhang (Co-Principal Investigator) Regina Liu (Co-Principal Investigator) Dan Yang (Former Co-Principal Investigator) 
Organization: Rutgers University New Brunswick
3 RUTGERS PLZA, NEW BRUNSWICK, NJ 08901-8559, (848)932-0150
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Time series analysis is mainly applied in the discovery of dependent and dynamic structure of observations over time, and in accurate prediction of potential outcomes of such data in the future. In the big-data era, modern data collection capabilities have led to massive amounts of time series data.   Large tensor (or multi-dimensional array) data are now routinely collected in a wide range of applications.  For example, a group of countries will report a set of economic indicators each quarter, forming a matrix (2-dimensional array) time series, with each column representing a country and each row representing an economic indicator. The import and export volume of different types of goods for a group of countries over time form a 3-dimensional array time series. The aim of the project is to lay a foundation and develop a general framework to systematically study the dynamics of such tensor systems, decipher the joint behavior of each individual time series in the tensor array, and provide methods for accurate prediction. The framework will include general and specific statistical models, practical applications, statistical methods and their theoretical and empirical properties, computational algorithms and software, and implementation in several data sets. The research can be applied to application areas ranging from finance and economics, environmental sciences, and human behavior (e.g. social networks) to neuroscience and engineering.  The project also addresses the training and education of future data scientists. <br/><br/>In the big-data era, large tensor time series are routinely observed in a wide range of applications. This project aims to develop state-of-the-art statistical tools to effectively and efficiently extract useful information from such big complex data. The work concerns a general framework of statistical learning with large dynamic tensor data.  Specifically, the project will develop a general class of tensor factor models, with modifications for specific applications, for modeling matrix- and tensor-valued time series, dynamic networks, and spatial temporal data. The results are expected to be directly applicable to economic tensor data, import-export volume time series, dynamic social networks, pollution monitoring, problems in fluid dynamics, and dynamic brain connectivity networks. Model estimation procedures, along with their theoretical foundations will be developed. The research will enrich the toolkit of statistical learning for a highly important and widely encountered class of big-data problems. The project also involves research training of graduate and undergraduate students in the field of statistical learning and its applications. The project will develop and disseminate free software, including an array of cleaned data sets for research, and a permanently maintained website as a hub for dissemination of future dynamic tensor research. An international conference on large dynamic tensor analysis will be organized.  Evaluation of the computational algorithms and implementation of the methods for large scale applications will leverage cloud computing resources provided through an agreement between commercial cloud service providers and NSF for the BIGDATA solicitation.

Award Number: 1838236
Title: BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2018
Latest Amendment Date: June 25, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2018
End Date: August 31, 2022
Awarded Amount to Date: $381,338
ARRA Amount: $
Investigator(s): John Paden paden@ku.edu (Principal Investigator) 
Organization: University of Kansas Center for Research Inc
2385 IRVING HILL RD, Lawrence, KS 66045-7552, (785)864-3441
NSF Directorate: CSE
Program(s): IIS Special Projects Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9150 9251
Program Element Code(s): 7484, 8083
Abstract: The objective of this research is to investigate artificial intelligence (AI) solutions for data collected by the Center for Remote Sensing of Ice Sheets (CReSIS) in order to provide an intelligent data understanding to automatically mine and analyze the heterogeneous dataset collected by CReSIS. Significant resources have been and will be spent in collecting and storing large and heterogeneous datasets from expensive Arctic and Antarctic fieldwork (e.g. through NSF Big Idea: Navigating the New Arctic). While traditional analyses provide some insight, the complexity, scale, and multidisciplinary nature of the data necessitate advanced intelligent solutions. This project will allow domain scientists to automatically answer questions about the properties of the data, including ice thickness, ice surface, ice bottom, internal layers, ice thickness prediction, and bedrock visualization. The planned approach will advance the broader big data research community by improving the efficiency of deep learning methods and in the investigation of methods to merge data-driven AI approaches with application-specific domain knowledge. Special attention will be given to women and minority involvement in the research and the project will develop new course materials for several classes in AI at a Hispanic and minority serving institute.<br/><br/>In polar radar sounder imagery, the delineation of the ice top and ice bottom and layering within the ice is essential for monitoring and modeling the growth of ice sheets and sea ice. The optimal approach to this problem should merge the radar sounder data with physical ice models and related datasets such as ice coverage and concentration maps, spatiotemporal meteorological maps, and ice velocity. Rather than directly engineering specific relations into the image analysis that require many parameters to be defined and tuned, data-dependent approaches let the machine learn these relationships. To devise intelligent solutions for navigating the big data from the Arctic and Antarctic and to scale up the current and traditional techniques to big data, this project plans several approaches for detecting ice surface, bottom, internal layers, 3D modeling of bedrock and spatial-temporal monitoring of the ice surface: 1) Devise new methodologies based on hybrid networks combining machine learning with traditional domain specific knowledge and transforming the entire deep learning network to the time-frequency domain. 2) Equip the machine with information that is not visible to the human eye or that is hard for a human operator to consider simultaneously, to be able to detect internal layers and 3D basal topography on a large scale. Using the results of the feature tracking of the ice surface in radar altimetry, the research effort will also develop new data-dependent techniques for predicting the ice thickness for following years based on deep recurrent neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934714
Title: Collaborative Research: Understanding Subatomic-Scale Quantum Matter Data Using Machine Learning Tools
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: August 23, 2021
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $1,211,285
ARRA Amount: $
Investigator(s): Eun-Ah Kim eun-ah.kim@cornell.edu (Principal Investigator) Kilian Weinberger (Co-Principal Investigator) Andrew Wilson (Co-Principal Investigator) Kilian Weinberger (Former Co-Principal Investigator) Christopher De Sa (Former Co-Principal Investigator) 
Organization: Cornell University
341 PINE TREE RD, ITHACA, NY 14850-2820, (607)255-5014
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: A central goal of modern quantum physics is to search for new systems and technological paradigms that utilize quantum mechanical aspects of matter rather than being limited by them. In particular, there is an active search for new materials that exhibit surprising physical properties because of strong interaction between individual electrons that leads to strong correlations in the motion of electrons and as a result, to strongly correlated quantum matter. The study of Strongly Correlated Quantum Matter (SCQM) has reached a tipping point through intense efforts over the last decade that have led to vast quantities of experimental data. The next breakthrough in the field will come from relating these experimental data to theoretical models using tools of data science. However, data-driven challenges in SCQM require a fundamentally new data science approaches for two reasons: first, quantum mechanical imaging is probabilistic; and second, inference from data should be subject to fundamental laws of physics. Hence the new data-driven challenges in the field of SCQM requires "Growing Convergent Research" and "Harnessing the Data Revolution", two of NSF's Ten Big Ideas. <br/><br/>The objective of the project is to develop and disseminate machine learning (ML) tools that can serve as a two-way highway connecting the data revolution in SCQM experiments at sub-atomic scale to a fundamental theoretical understanding of SCQM. The specific goals are: (1) Develop interpretable ML tools for position space image data; (2) Develop unsupervised ML tools for momentum space scattering data; (3) Design new imaging modality guided by the insight gained from ML; and (4) Integrate ML tools with in-operando human interface to the Cornell High Energy Synchrotron Source (CHESS) beamline. Goals (1) and (2) are within reach, while (3) and (4) are more ambitious visions for scaling up to a future institute that can involve more academic institutions and scattering experiment facilities nationwide. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741472
Title: BIGDATA: F: Audio-Visual Scene Understanding
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 24, 2017
Latest Amendment Date: May 08, 2019
Award Instrument: Standard Grant
Program Manager: Hector Munoz-Avila
Start Date: September 01, 2017
End Date: August 31, 2022
Awarded Amount to Date: $666,000
ARRA Amount: $
Investigator(s): Chenliang Xu chenliang.xu@rochester.edu (Principal Investigator) Zhiyao Duan (Co-Principal Investigator) 
Organization: University of Rochester
500 JOSEPH C WILSON BLVD, ROCHESTER, NY 14627-0001, (585)275-4031
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 9251
Program Element Code(s): 8083
Abstract: Understanding scenes around us, i.e., recognizing objects, human actions and events, and inferring their spatial, temporal, correlative and causal relations, is a fundamental capability in human intelligence. Similarly, designing computer algorithms that can understand scenes is a fundamental problem in artificial intelligence. Humans consciously or unconsciously use all five senses (vision, audition, taste, smell, and touch) to understand a scene, as different senses provide complimentary information. For example, watching a movie with the sound muted makes it very difficult to understand the movie; walking on a street with eyes closed without other guidance can be dangerous. Existing machine scene understanding algorithms, however, are designed to rely on just a single modality. Take the two most commonly used senses, vision and audition, as an example, there are scene understanding algorithms designed to deal with each single modality. However, no systematic investigations have been conducted to integrate these two modalities towards more comprehensive audio-visual scene understanding. Designing algorithms that jointly model audio and visual modalities towards a complete audio-visual scene understanding is important, not only because this is how humans understand scenes, but also because it will enable novel applications in many fields. These fields include multimedia (video indexing and scene editing), healthcare (assistive devices for visually and aurally impaired people), surveillance security (comprehensive monitoring of the suspicious activities), and virtual and augmented reality (generation and alternation of visuals and/or sound tracks). In addition, the investigators will involve graduate and undergraduate students in the research activities, integrate research results into the teaching curriculum, and conduct outreach activities to local schools and communities with an aim to broader participation in computer science. <br/><br/>This project aims to achieve human-like audio-visual scene understanding that overcomes the limitations of single-modality approaches through big data analysis of Internet videos. The core idea is to learn to parse a scene into elements and infer their relations, i.e., forming an audio-visual scene graph. Specifically, an element of the audio-visual scene can be a joint audio-visual component of an event when the event shows correlated audio and visual features. It can also be an audio component or a visual component if the event only appears in one modality. The relations between the elements include spatial and temporal relations at a lower level, as well as correlative and causal relations at a higher level. Through this scene graph, information across the two modalities can be extracted, exchanged and interpreted. The investigators propose three main research thrusts: (1) Learning joint audio-visual representations of scene elements; (2) Learning a scene graph to organize scene elements; and (3) Cross-modality scene completion. Each of the three research thrusts explores a dimension in the space of audio-visual scene understanding, yet they are also inter-connected. For example, the audio-visual scene elements are nodes in the scene graph, and the scene graph, in turn, guides the learning of relations among scene elements with structured information; the cross-modality scene completion generates missing data in the scene graph and is necessary for good audio-visual understanding of the scene. Expected outcomes of this proposal include: a software package for learning joint audio-visual representations of various scene elements; a web-deployed system for audio-visual scene understanding utilizing the learned scene elements and scene graphs, illustrated with text generation; a software package for cross-modality scene completion based on scene understanding; and a large-scale video dataset with annotations for audio-visual association, text generation and scene completion. Datasets, software and demos will be hosted on the project website.

Award Number: 1934675
Title: Collaborative Research: High-Dimensional Spatio-Temporal Data Science for a Resilient Power Grid: Towards Real-Time Integration of Synchrophasor Data
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $185,959
ARRA Amount: $
Investigator(s): Le Xie le.xie@tamu.edu (Principal Investigator) 
Organization: Texas A&M Engineering Experiment Station
3124 TAMU, COLLEGE STATION, TX 77843-3124, (979)862-6777
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu EPCN-Energy-Power-Ctrl-Netwrks 
Program Reference Code(s): 062Z 1653 7607
Program Element Code(s): 099y, 7607
Abstract: The project will establish an Institute at Arizona State University (ASU) with Texas A&M (TAMU) that considers the electric power grid and examines critical real-time decision-making by developing core data-driven science methods and applications.  This is motivated by the modern electric power system which is experiencing heightened unpredictability from increasing demand for renewable energy, efficiency, and resilience. To address this, industry stakeholders are deploying GPS-synchronized phasor measurement units (PMUs), or synchrophasors, that provide direct measurements of voltage and current phasors with high temporal granularity. However, the potential real-time situational awareness enabled by these measurements has been impeded by the massive scale of the time-series PMU data and have limited its use to passive, post-event forensics. The Institute meets this need for PMU-based real-time decision-making by examining five critical problems: (i) ensure data quality against bad, missing, or stale data; (ii) exploit the fine granularity of PMU data to track real-time changes in network parameters; (iii) detect, identify, localize, and visualize oscillation and failure events; (iv) assess and visualize cybersecurity threats and countermeasures specific to PMUs; and (v) create synthetic PMU datasets for testing and validation. The Institute leverages the PIs' synergistic multidisciplinary background in information sciences and statistics, machine learning, data visualization, cybersecurity, and power systems. The team will apply state-of-the-art techniques including hidden Markov models, LSTM neural networks, graphical models, errors-in-variables models, graph signal processing, adversarial examples, low-dimensional feature extraction, and constrained GANs. Another key research focus is the development of visual analytics for high-granularity spatio-temporal PMU data to enable improved operator review and decision-making. These innovations will be fueled by massive PMU datasets accessible to the PIs.<br/><br/>This Phase I institute has the potential to tip PMUs from a promising-but-mostly-underused resource into an essential part of power system best practices. The data science outcomes will impact application domains such as transportation networks, smart buildings, and manufacturing, each of which increasingly faces high-dimensional streaming data challenges. The PIs will disseminate their research to both academic and industry stakeholders and will continue their outreach on teaching AI and machine learning (ML) modules to underrepresented high school students. Finally, the multi-disciplinary strength of this institute lends itself naturally to a larger, integrated, and comprehensive Phase II institute focused on data-intensive research for critical infrastructure networks.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.  This effort is co-funded by the Division of Electrical, Communications and Cyber Systems within the Directorate for Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838083
Title: BIGDATA: IA: Enabling Large-Scale, Privacy-Preserving Genomic Computing with a Hardware-Assisted Secure Big-Data Analytics Framework
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 11, 2018
Latest Amendment Date: June 22, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $1,000,000
ARRA Amount: $
Investigator(s): XiaoFeng Wang xw7@indiana.edu (Principal Investigator) Haixu Tang (Co-Principal Investigator) Judy Fox (Co-Principal Investigator) 
Organization: Indiana University
107 S INDIANA AVE, BLOOMINGTON, IN 47405-7000, (317)278-3473
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Advances in DNA sequencing technologies are expected to make available a massive amount of human genomic data in the years to come, which need computation of a tremendous scale to process. This demand cannot be met by today's commercial clouds,  since they do not provide strong privacy guarantees,  or by using existing cryptography techniques, since they still cannot achieve the performance required for big-data analytics. The emergence of the new-generation hardware support for trusted execution environments presents a new opportunity for scalable data protection, through the processors designed to withstand the attacks even from a fully compromised operating system.  To seize this opportunity, this project aims at developing a distributed, parallel computing framework critical for executing data-intensive tasks on trusted execution environment-capable systems.  This research will be performed in collaboration with Intel, which will transfer the new methods developed for large-scale data protection to industry and genomic researchers.  Students from historically black colleges and universities will participate in the work.<br/><br/>The project focuses on developing a big-data analytics framework built on Intel Software Guard Extensions (SGX) and applying it to support privacy-preserving, large-scale genomic data analyses and other computing tasks. Based upon the understanding of unique performance impacts of SGX systems, including those incurred by enclave creation, management, trust establishment, cross-enclave communication and others, a new MPI-based cluster computing framework is built to automatically optimize the deployment of computing nodes across enclaves and CPU packages under resource constraints. This new framework supports a set of fundamental genomic computing tasks, ranging from reads-mapping to peptide identification, as well as machine-learning based models.  Also, its potential risks, side-channel leaks in particular, are analyzed and effectively controlled to provide high privacy assurance. The work will enable broad sharing of previously inaccessible data and help drive the new insights of individualized health care.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741355
Title: BIGDATA: F: Latent Structure and Dynamics of Big Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2017
Latest Amendment Date: June 27, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2023
Awarded Amount to Date: $900,000
ARRA Amount: $
Investigator(s): Dmitri Krioukov dima@krioukov.net (Principal Investigator) 
Organization: Northeastern University
360 HUNTINGTON AVE, BOSTON, MA 02115-5005, (617)373-3004
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Big data poses big challenges. Perhaps the biggest challenge is to extract small but useful information from big noisy data. What approach should be used to do that, and for what data, so that this extraction is scalable, and yields not spurious artifacts but provably reliable predictive knowledge? Numerous data science applications are blocked on these questions. For example, the prediction and control of opinions, (fake) news, and (mis)information is a practical problem that is becoming of increasingly high and broad impact these days of pervasion of online social media into everyday human life. This particular problem is largely blocked on general impossibility of disentangling those who naturally bond with others like themselves from those influenced by peers in social networks, except in some specific settings. The specific settings of this project -- real networks with latent-space structure -- are exactly the settings in which these theoretical and practical difficulties can be resolved.<br/><br/>The project will make a series of contributions in two areas. First, it will resolve a long-standing problem of obtaining a class of random graph models satisfying four requirements of realism: sparsity, exchangeability, projectivity and unbiasedness/maximum-entropy. Within this class, a set of graph-structural properties will be determined such that unbiased random graphs that have these properties are proved to have latent-geometric structure, thus rigorously linking discrete combinatorial structure of random graphs to smooth geometry of latent manifolds. The framework that the project will develop to prove this, will be quite general and applicable to other types of big data. The properties responsible for latent geometricity of random graphs are expected to characterize many real networks, meaning that such networks will be guaranteed to have latent geometries. The second part of the project will focus on developing scalable algorithms and software, with optimal computational complexity scaling linearly with the data size, and with proved accuracy guarantees, to learn the latent structure of a real network if the network has it, and apply these algorithms to large real networks. The outcomes of this latent-geometric learning will make it possible to map dynamical processes in real networks, such as spreading phenomena in social networks, to latent dynamics, while the knowledge of latent statistical factors behind this dynamic can then be used to predict and control it in practice with known accuracy bounds.

Award Number: 1940307
Title: Collaborative Research: Accelerating the Discovery of Electronic Materials through Human-Computer Active Search
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: June 02, 2020
Award Instrument: Standard Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $591,000
ARRA Amount: $
Investigator(s): Steven Lopez s.lopez@northeastern.edu (Principal Investigator) Semion Saikin (Co-Principal Investigator) 
Organization: Northeastern University
360 HUNTINGTON AVE, BOSTON, MA 02115-5005, (617)373-3004
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8249 8396 8611
Program Element Code(s): 099Y, 1712
Abstract: The overarching goal of this project is to accelerate the discovery of  materials with tailored electronic properties through human-computer active search. These efforts will lay the groundwork for accelerating materials discovery, and advance the capability to control electronic properties in materials with the potential for profound societal impact. The thermoelectric and photocatalytic materials predicted, synthesized, and characterized in this research can realize societal advances in the space of energy and solar fuels. High-efficiency thermoelectric materials can revolutionize how heat sources are transformed into electrical power by eliminating the traditional intermediate mechanical energy conversions.  Earth-abundant  light-responsive catalysts are emerging as  an alternative to costly, rare metal catalysts to store solar energy as  portable liquid fuels, like ethanol. These green reactions  are enabling low-cost, carbon-neutral fuels.  The team brings together expertise in materials science, chemistry, machine learning, visualization, metadata, and knowledge frameworks to develop multi-fidelity, expert-guided active search strategies within materials science and chemistry.  Resonances among the team's existing outreach programs will broaden inclusion of students from underrepresented groups and be moderated via the Alliance for Diversity in Science and Engineering.  The work will provide cross-disciplinary training to graduate students and postdocs in all aspects of material informatics, including participating in and leading team efforts, co-mentorship of Ph.D.  and postdoctoral researchers, inclusive symposia at national conferences, and a summer workshop focused on the intersection of visualization, machine learning, ontological engineering and materials science. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative. <br/><br/>An interdisciplinary team will create a search framework for scientific discovery that leverages recent advances in material databases, machine learning, visualization, human-machine interaction, and knowledge structures. To broadly assess the efficacy of this approach, the search effort will span the electronic behavior of both molecules and crystalline materials:  (i) new organic photocatalysts for solar fuels production and (ii) new thermoelectric materials for electricity generation.  Central to this effort is the engagement of domain experts and associated feedback in a human-in-the-loop active search process. Dynamic visualizations will enable the user to (i) understand the underlying reasons why the materials are being suggested and (ii) provide a user steering capability to identify and annotate specific aspects of the explored search space. Domain-expert annotations and feedback will be parsed against a suite of ontologies, further aiding the search process by providing relational insight between features. New molecules and materials will be explored through a combination of first principles calculations and high-throughput, automated experimentation; these results will be incorporated into a continually growing open-access database. Efficiently integrating and directing evolving data-streams from experiment, computation, and human steering during the search will be achieved with a multi-fidelity active search policy. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123244
Title: Collaborative Research: HDR DSC: Infusion of Data Science and Computation into Engineering Curricula
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 05, 2021
Latest Amendment Date: August 05, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $99,999
ARRA Amount: $
Investigator(s): Stephanie Paal spaal@civil.tamu.edu (Principal Investigator) 
Organization: Texas A&M Engineering Experiment Station
3124 TAMU, COLLEGE STATION, TX 77843-3124, (979)862-6777
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a curricular framework for data science education and workforce development that is transferable between diverse institutions, so STEM-related programs can plug and play data science lessons with existing curricula without much overhead. These lessons will be created in conjunction with community stakeholders and industry partners to ensure a focus on real-world problem solving and include student organizations in course development to promote flexible learning pathways. The proposed additions to undergraduate STEM education will provide an evidence-based blueprint for best practices in integrating data science with existing engineering curricula. Implementation across multiple engineering departments will result in a significant impact on society through the training of a diverse, globally competitive STEM workforce with high data literacy. <br/><br/>The objectives of this project are to (1) facilitate data science education and workforce development for engineering and related topics, (2) provide opportunities for students to participate in practical experiences where they can learn new skills in a variety of environments, and (3) expand the data science talent pool by enabling the participation of undergraduate students with diverse backgrounds, experiences, skills, and technical maturity in the Data Science Corps. This work will support the Data Science Corps objective of building capacity for education and workforce development to harness the data revolution at local, state, and national levels. The institutions gathered for this project will develop training programs and curate datasets that will be made available so they can be included in undergraduate instruction nationwide. Furthermore, the training materials will be shared with industry partners, facilitating workforce development. The project team will develop a website to house data science training programs, didactic datasets, and other resources for educators. These resources are intended to reduce barrier to entry for faculty seeking to incorporate data science into their instruction, as recruiting and retaining faculty to create and teach integrated introductory courses in data science has been recognized as a significant hurdle by the National Academies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741173
Title: BIGDATA: IA: Collaborative Research: From Bytes to Watts - A Data Science Solution to Improve Wind Energy Reliability and Operation
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 15, 2017
Latest Amendment Date: July 18, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $749,799
ARRA Amount: $
Investigator(s): Yu Ding yuding@tamu.edu (Principal Investigator) Bani Mallick (Co-Principal Investigator) Peng Li (Co-Principal Investigator) 
Organization: Texas A&M Engineering Experiment Station
3124 TAMU, COLLEGE STATION, TX 77843-3124, (979)862-6777
NSF Directorate: CSE
Program(s): Information Technology Researc Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 1640, 8083
Abstract: The collective efforts in aerospace, civil, electrical, and mechanical engineering areas have led to remarkable progresses in wind energy. Larger turbines are designed and installed, and wind farms are nowadays built at locations where wind is even more intermittent and maintenance equipment is less accessible. This adds new challenges to ensuring operational reliability. To cope with these challenges, along with the rapid advancement in microelectronics, modern wind farms are equipped with a large number and variety of sensors, including, at the turbine level, anemometers, tachometers, accelerometers, thermometers, strain sensors, and power meters, and at the farm level, anemometers, vanes, sonars, thermometers, humidity meters, pressure meters, among others. It is worth noting that all these data are currently analyzed/utilized only in their respective domains. The big data challenges in this project include how to best use spatio-temporal data for wind forecast, how to use data of different nature (wind, power, load etc.) and data of different sources (physical data versus computer simulation data) for power production assessment in a computationally efficient manner, and finally how to integrate these three sets of solutions into a reliable and efficient computational platform. The proposed research and education activities will make a paradigm shift in the wind industry by demonstrating how dramatically data science innovations can benefit the industry. The PIs will disseminate the research findings through classroom teaching, journal/conference publications, industry workshops, and data/software sharing. The summer internship opportunities and undergraduate research help train the next generation workforce to be better versed with data science methodologies.<br/><br/>The critical barrier to cost effective wind power and its general adoption is partly rooted in wind stochasticity, severely complicating wind power production optimization and cost reduction. The long-term viability of wind energy hinges upon a good understanding of its production reliability, which is affected in turn by the predictability of wind and power productivity of wind turbines. Furthermore, the productivity of a wind turbine comprises two aspects: its ability of converting wind into power during its operation and the availability of wind turbines. Three inter-related research efforts will enhance wind energy reliability and productivity): (1) spatio-temporal analysis (for wind forecast) (2) conditional density estimation (for wind-to-power conversion assessment); and (3) importance sampling (for turbine reliability assessment and improvement). Significant data resourced provided by industry partners in the research, coupled with models and computational resources, will enable better prediction of wind profiles and utilization.  In addition, the team will develop dedicated reconfigurable field programmable gate array (FPGA) processors that will be 50 to 500 times faster than general-purpose CPUs for both on-site and central control processing and have small form-factor, low cost and energy efficient to enable agile development under severe outdoor conditions at wind farms.

Award Number: 1916585
Title: BD Hubs: NORTHEAST: The Northeast Big Data Innovation Hub
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: May 31, 2019
Latest Amendment Date: June 22, 2021
Award Instrument: Cooperative Agreement
Program Manager: Martin Halbert
Start Date: June 01, 2019
End Date: May 31, 2023
Awarded Amount to Date: $3,070,454
ARRA Amount: $
Investigator(s): Jeannette Wing WING@COLUMBIA.EDU (Principal Investigator) James Hendler (Co-Principal Investigator) Vasant Honavar (Co-Principal Investigator) Andrew McCallum (Co-Principal Investigator) Florence Hudson (Co-Principal Investigator) Rene Baston (Former Co-Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): BD Spokes -Big Data Regional I HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 024Y, 099Y
Abstract: The BD Hubs foster regional networks of stakeholders and cooperate nationally on US priorities of importance to a region and to the nation. The activities of the BD Hubs contribute to a vibrant national data innovation ecosystem. The Northeast Big Data Innovation Hub serves as a uniquely neutral entity within this ecosystem, harnessing the data revolution by building strategic partnerships that advance innovative solutions to a broad range of societal, scientific, and industry challenges. This vision is empowered and strengthened through the Hub's collaboration with a diverse community of partners, including underserved populations, world-class institutions, and people of all backgrounds who rely on or are impacted by big data.<br/> <br/>Leveraging the distinctive characteristics and challenges of the northeastern United States, the Northeast Hub will design and facilitate multi-disciplinary, community-led activities and initiatives such as: <br/><br/>- Aggregating and helping to develop best practices for responsible data science; <br/>- Creating frameworks for data fluency; <br/>- Fostering better management of data security and privacy; <br/>- Integrating health data from traditional and novel sources; <br/>- Improving education through big data; and <br/>- Reducing barriers for data sharing within and between different sectors.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838222
Title: BIGDATA: F: Collaborative Research: Optimizing Log-Structured-Merge-Based Big Data Management Systems
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2018
Latest Amendment Date: May 12, 2020
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $1,390,073
ARRA Amount: $
Investigator(s): Evangelos Christidis evangelos.christidis@ucr.edu (Principal Investigator) Vassilis Tsotras (Co-Principal Investigator) Ahmed Eldawy (Co-Principal Investigator) 
Organization: University of California-Riverside
900 UNIVERSITY AVE, RIVERSIDE, CA 92521-9800, (951)827-5535
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7364 8083 9251
Program Element Code(s): 8083
Abstract: Modern big data management systems support fast read and write operations based on the unique identifier (key) of a record. That is, they are fast when inserting key-value pairs, and given a key they quickly return the value associated with that key. To do so, most such systems rely on a Log-Structured-Merge Tree (LSM) structure that batches writes together before writing them to persistent storage. This project will study how to efficiently support more sophisticated operations on LSM-based storage systems, that is, operations that do not simply specify the key of a record. Examples of such operations include searching for records based instead on their location or time. By optimizing the storage and management of big data, this project has the potential to cut the storage costs and energy consumption in data centers. Further, the successful completion of this work will allow users to manage more data with the existing hardware infrastructure, which is critical given the new wave of big data being generated by sensors and the Internet-of-Things.  The project will capitalize on the student diversity at two Hispanic Serving Institutions, and thus broaden the participation of under-represented groups in the research process.<br/><br/>To support richer data modeling and querying capabilities on top of LSM key-value stores, this project will develop novel LSM indexing and access algorithms to support query plans that utilize both primary and secondary LSM components. In addition, it will design and evaluate flow control policies to dampen or eliminate the notoriously bursty data ingestion behavior that LSM-based storage structures exhibit. It will also study how to automatically and dynamically change LSM compaction policies and parameters based on the query workload. Data-semantics-aware compaction techniques will also be studied. The project will additionally develop novel LSM-aware query optimization techniques; the LSM storage layer is currently treated as a black box by most query optimizers. The planned methods will be deployed and evaluated on the open source Apache AsterixDB system.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934757
Title: Collaborative Research: Advancing Science with Accelerated Machine Learning
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: May 06, 2021
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $600,311
ARRA Amount: $
Investigator(s): Zhizhen Zhao zhizhenz@illinois.edu (Principal Investigator) Eliu Huerta Escudero (Former Principal Investigator) Volodymyr Kindratenko (Co-Principal Investigator) Mark Neubauer (Co-Principal Investigator) Zhizhen Zhao (Former Co-Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099y, 7231
Abstract: In the next generation of big science experiments, the demands for computing resources are expected to outstrip the capabilities of existing computing infrastructure. In light of this, a radical rethinking of the cyberinfrastructure is needed to contend with these developments. With the onset of deep learning, parallelized processing architectures have emerged as a solution. Combined with deep learning algorithms, parallelized processing architectures, in particular, Field Programmable Gate Arrays (FPGAs) have been shown to give large speedups in computing when compared with conventional CPUs. This project aims to bring machine learning based accelerated computing with FPGAs into the scientific community by targeting two big-data physics experiments: the Large Hadron Collider (LHC) and the Laser Interferometer Gravitational-wave  Observatory (LIGO). This project will push the frontiers of deep learning at scale, demonstrating the versatility and scalability of these methods to accelerate and enable new physics in the big data era. This project serves the national interest, as stated by NSF's mission, by promoting the progress of science. The PIs and their collaborators will build upon their recent work to design and exploit state-of-the-art neural network models for real-time data analytics, reducing overall computing latency. This new computing paradigm aims to significantly increase the processing capability at the LHC and LIGO, leading to an increased scientific output of these devices and,  potentially, foundational discoveries. The students to be mentored and trained in this research will interact closely with industry partners, creating new career opportunities, and strengthening synergies between academia and industry. In addition to sharing algorithms with the community through open source repositories, the team will continue to educate the community regarding credit and citation of scientific software.<br/><br/>In this project, the PIs will build upon their recent work developing high quality deep learning algorithms for real-time data analytics of time-series and image datasets using Field Programmable Gate Arrays (FPGAs) to accelerate low-latency inference of machine learning algorithms. The team will develop machine learning based acceleration tools focusing on FPGAs to be used within LIGO and the LHC experiments. The team's immediate goal is to take benchmark examples of LHC high level trigger processing and LIGO gravitational wave processing and construct demonstrators in each scenario. For this benchmark, they aim to design and implement an FPGA based accelerator that can perform low latency gravitational wave identification and LHC event reconstruction.  Additionally, the PIs aim to add the capability of graph based neural network accelerators for FPGAs. The open source tools to be developed as part of these activities will be readily shared with LIGO, LHC, and LSST. The project will create an advisory group, including members of large and small projects,  members of the neutrino physics, multi-messenger astronomy community, industry partners, computer scientists, and computational biologists. This project aims to bring together representatives of the different communities that will benefit from and can contribute to this work. The PIs will organize deep learning workshops and boot camps to train students and researchers on how to use and contribute to the framework, creating a wide network of contributors and developers across key science missions.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924205
Title: HDR DSC: Collaborative Research: Central Coast Data Science Partnership: Training a New Generation of Data Scientists
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2019
Latest Amendment Date: July 31, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $970,104
ARRA Amount: $
Investigator(s): Ambuj Singh ambuj@cs.ucsb.edu (Principal Investigator) Michael Ludkovski (Co-Principal Investigator) Alexander Franks (Co-Principal Investigator) Yekaterina Kharitonova (Co-Principal Investigator) Sang-Yun Oh (Co-Principal Investigator) 
Organization: University of California-Santa Barbara
3227 CHEADLE HALL, SANTA BARBARA, CA 93106-0001, (805)893-4188
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Due to the societal and technological advances made possible by data-driven science, there is a strong demand for professionals versed in the tools and techniques needed for manipulating and understanding data. This project will develop an undergraduate curriculum in data science that spans and connects the three main public higher education systems in California: the research-driven University of California system, the practical and career-oriented California State University system, and the two-year California Community Colleges. The collaborative program will establish pathways for data science training through coursework and real-world projects. This project will impact students from diverse social, ethnic, cultural, and economic backgrounds and will improve the feeder pipelines from two-year colleges to four-year universities. This multi-campus approach to building a data science training program will foster collaborations for training a diverse workforce in data science. The resulting course materials and project outcomes will be made available so that other institutions can adopt best practices.<br/><br/>The partnership consists of four academic institutions on the West Coast: University of California, Santa Barbara (UCSB), California Polytechnic State University, San Luis Obispo (Cal Poly), Santa Barbara City College (SBCC), and California State University, San Bernardino (CSUSB). The alliance will expand training at UCSB and Cal Poly by building on existing strengths through a sequence of new capstone courses, as well as lay the groundwork for data science curriculum development at SBCC and CSUSB, whose students will participate in a summer internship program at UCSB. Over 100 undergraduate students will be supported by stipends during the course of the project. The developed courses will emphasize  programming and data inference within the context of application domains that is critical to training in data science. Students will be taught the underlying principles of data science, including data-generating processes and the role of measurement, ethics and privacy, information-processing tools for harnessing the power of big data, and the oral and written communication skills necessary for pursuing effective professional careers in the field. The program will culminate in a year-long capstone course for seniors, who will synthesize and apply previously learned data science tools and techniques in a large-scale project in a chosen domain area.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940179
Title: Collaborative Research: Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: March 31, 2023
Awarded Amount to Date: $325,000
ARRA Amount: $
Investigator(s): Roberto Rivera roberto.rivera30@upr.edu (Principal Investigator) 
Organization: University of Puerto Rico Mayaguez
259 BLVD ALFONSO VALDES, MAYAGUEZ, PR 00680-6475, (787)831-2065
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934633
Title: Collaborative Research: Knowledge Guided Machine Learning: A Framework for Accelerating Scientific Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: July 02, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $341,854
ARRA Amount: $
Investigator(s): Paul Hanson pchanson@wisc.edu (Principal Investigator) Hilary Dugan (Co-Principal Investigator) 
Organization: University of Wisconsin-Madison
21 N PARK ST STE 6301, MADISON, WI 53715-1218, (608)262-3822
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The success of machine learning (ML) in many applications where large-scale data is available has led to a growing anticipation of similar accomplishments in scientific disciplines. The use of data science is particularly promising in scientific problems involving processes that are not completely understood. However, a purely data-driven approach to modeling a physical process can be problematic. For example, it can create a complex model that is neither generalizable beyond the data on which it was trained nor physically interpretable. This problem becomes worse when there is not enough training data, which is quite common in science and engineering domains.  A machine learning model that is grounded by explainable theories stands a better chance at safeguarding against learning spurious patterns from the data that lead to non-generalizable performance. This is especially important when dealing with problems that are critical and associated with high risks (e.g., extreme weather or collapse of an ecosystem).  Hence, neither an ML-only nor a scientific knowledge-only approach can be considered sufficient for knowledge discovery in complex scientific and engineering applications. This project is developing novel techniques to explore the continuum between knowledge-based and ML models, where both scientific knowledge and data are integrated synergistically. Such integrated methods have the potential for accelerating discovery in a range of scientific and engineering disciplines. This project will train interdisciplinary scientists who are well versed in such methods and will disseminate results of the project via peer-reviewed publications, open-source software, and a series of workshops to engage the broader scientific community.<br/><br/>This project aims to develop a framework that uses the unique capability of data science models to automatically learn patterns and models from data, without ignoring the treasure of accumulated scientific knowledge. Specifically, the project builds the foundations of knowledge-guided machine learning (KGML) by exploring several ways of bringing scientific knowledge and machine learning models together using pilot applications from four domains: aquatic ecodynamics, climate and weather, hydrology, and translational biology. These pilot applications were selected because they are at tipping points where knowledge-guided machine learning can have a transformative effect.  KGML has the potential for providing scientists and engineers with new insights into their domains of interest and will require the development of innovative new machine learning approaches and architectures that can incorporate scientific principles. Scientific knowledge, KGML methods, and software developed in this project could potentially be extended to a wide range of scientific applications where mechanistic (also known as process-based) models are used.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837986
Title: BIGDATA: IA: Automating Analysis and Feedback to Improve Mathematics Teachers' Classroom Discourse
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 09, 2018
Latest Amendment Date: October 03, 2018
Award Instrument: Standard Grant
Program Manager: Tatiana Korelsky
Start Date: October 01, 2018
End Date: September 30, 2022
Awarded Amount to Date: $1,998,505
ARRA Amount: $
Investigator(s): Tamara Sumner sumner@colorado.edu (Principal Investigator) James Martin (Co-Principal Investigator) Wayne Ward (Co-Principal Investigator) Jennifer Jacobs (Co-Principal Investigator) Chenhao Tan (Co-Principal Investigator) William Foland (Former Co-Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): ECR-EHR Core Research Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 8817
Program Element Code(s): 7980, 8083
Abstract: This research project will develop and study an innovative application - TalkBack - for addressing a significant challenge in education: providing teachers with personalized feedback on classroom discussion strategies. The TalkBack application builds on advances in deep learning for natural language processing and speech recognition to automatically analyze classroom discussions and reliably generate information about specific classroom dialog between student and teacher that occur in active learning. This research will significantly extend existing machine learning from simple descriptions, and automated classification, of dialog to more complex descriptions, and automated classification, of dialog using deep learning. TalkBack will be a cloud application available to any teacher who has classroom video and who wants to improve active learning in the classroom.<br/><br/>The TalkBack application will consist of three interrelated components: a cloud-based big data infrastructure for managing and processing classroom recordings, deep learning models that reliably detect the use of talk moves, and an innovative interface that provides teachers with personalized, feedback on their use of discussion strategies during individual teaching episodes and longitudinally over multiple episodes. Two user studies will be conducted to gather information from math teachers related to the design and impact of the application. These user studies will include a pilot study in year 2 (n = 20 teachers) and a field study in year 3 (n = 100 teachers). The TalkBack application will provide an exemplar for a new type of translational activity enabled by big data: the reification of existing, well-researched theoretical frameworks in deep learning models. Building on NSF's investment in research on talk moves, including the Accountable Talk and the IQA frameworks, this work demonstrates how analyses of teaching practices using these frameworks can be fully automated and scaled up to support large numbers of teachers longitudinally over time. Furthermore, this effort will demonstrate how a cloud-based infrastructure supporting the detailed analysis of classroom recordings using speech and language processing can be used to develop next generation learning environments (in this case, personalized feedback on teaching practices) and to uncover new insights into teaching practices at scale. Specifically, this research will provide unprecedented insight into the ways that classroom discussions and student participation changes as teachers develop and expand their use of talk moves over time. This study will develop the big data application, TalkBack, providing immediate and actionable feedback to teachers based on self-recordings of their mathematics lessons.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934766
Title: Collaborative Research: High-Dimensional Spatio-Temporal Data Science for a Resilient Power Grid: Towards Real-Time Integration of Synchrophasor Data
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Donald Wunsch
Start Date: September 01, 2019
End Date: August 31, 2023
Awarded Amount to Date: $1,330,040
ARRA Amount: $
Investigator(s): Lalitha Sankar lalithasankar@asu.edu (Principal Investigator) Oliver Kosut (Co-Principal Investigator) Anamitra Pal (Co-Principal Investigator) Gautam Dasarathy (Co-Principal Investigator) Christopher Bryan (Co-Principal Investigator) 
Organization: Arizona State University
660 S MILL AVE STE 312, TEMPE, AZ 85281-3670, (480)965-5479
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu EPCN-Energy-Power-Ctrl-Netwrks 
Program Reference Code(s): 062Z 1653 7607 9102 9251
Program Element Code(s): 099y, 7607
Abstract: The project will establish an Institute at Arizona State University (ASU) with Texas A&M (TAMU) that considers the electric power grid and examines critical real-time decision-making by developing core data-driven science methods and applications.  This is motivated by the modern electric power system which is experiencing heightened unpredictability from increasing demand for renewable energy, efficiency, and resilience. To address this, industry stakeholders are deploying GPS-synchronized phasor measurement units (PMUs), or synchrophasors, that provide direct measurements of voltage and current phasors with high temporal granularity. However, the potential real-time situational awareness enabled by these measurements has been impeded by the massive scale of the time-series PMU data and have limited its use to passive, post-event forensics. The Institute meets this need for PMU-based real-time decision-making by examining five critical problems: (i) ensure data quality against bad, missing, or stale data; (ii) exploit the fine granularity of PMU data to track real-time changes in network parameters; (iii) detect, identify, localize, and visualize oscillation and failure events; (iv) assess and visualize cybersecurity threats and countermeasures specific to PMUs; and (v) create synthetic PMU datasets for testing and validation. The Institute leverages the PIs' synergistic multidisciplinary background in information sciences and statistics, machine learning, data visualization, cybersecurity, and power systems. The team will apply state-of-the-art techniques including hidden Markov models, LSTM neural networks, graphical models, errors-in-variables models, graph signal processing, adversarial examples, low-dimensional feature extraction, and constrained GANs. Another key research focus is the development of visual analytics for high-granularity spatio-temporal PMU data to enable improved operator review and decision-making. These innovations will be fueled by massive PMU datasets accessible to the PIs.<br/><br/>This Phase I institute has the potential to tip PMUs from a promising-but-mostly-underused resource into an essential part of power system best practices. The data science outcomes will impact application domains such as transportation networks, smart buildings, and manufacturing, each of which increasingly faces high-dimensional streaming data challenges. The PIs will disseminate their research to both academic and industry stakeholders and will continue their outreach on teaching AI and machine learning (ML) modules to underrepresented high school students. Finally, the multi-disciplinary strength of this institute lends itself naturally to a larger, integrated, and comprehensive Phase II institute focused on data-intensive research for critical infrastructure networks.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.  This effort is co-funded by the Division of Electrical, Communications and Cyber Systems within the Directorate for Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838061
Title: BIGDATA: F: Multiaffine Constrained Optimization for High-Dimensional Big Data Models
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 11, 2018
Latest Amendment Date: September 11, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2018
End Date: September 30, 2022
Awarded Amount to Date: $699,952
ARRA Amount: $
Investigator(s): Donald Goldfarb goldfarb@columbia.edu (Principal Investigator) John Wright (Co-Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: This project addresses fundamental questions about properties of optimization models involving multiaffine functions and algorithms for solving them. Multiaffine functions are functions of variables, or blocks of variables, that are linear in them when all other variables, or blocks of variables, are held fixed. Optimization problems of this type arise in a wide variety of big data applications in science, engineering, medicine, statistics and social media, including machine learning, computer vision, medical and hyperspectral imaging, and tensor models to name just a few. Because these problems often involve massive amounts of data and huge numbers of variables, this project will attempt to develop efficient distributed and probabilistic approaches, enabling solutions to be obtained more rapidly than is currently possible. It is expected that the methodology that is developed will have a pervasive influence on practice in the interdisciplinary field of data science. The project will demonstrate this methodology on data sets from specific applications from a wide range of fields and disseminate the results through websites, code release and conference talks and tutorials, as well as through interactions with faculty and students from various applied disciplines in Columbia University's Data Science Institute, female students through the Society of Women Engineers at Columbia, and the hosting of high school students from under-represented minorities through Columbia University's Young Scholars Program.<br/><br/>While providing important tools for solving real world problems, the project is also expected to have a major impact on the theoretical underpinnings of the Alternating Direction Method of Multipliers (ADMM) and an understanding of the optimization landscape of multiaffine problems arising in data analysis. ADMM has become a major algorithmic approach for solving problems in both parallel and distributed computational settings, because of its ability to transform the computationally intensive process of solving a difficult problem into an iterative procedure that involves solving simpler problems that are coupled by a system of linear equations. The project will expand ADMMs applicability by enabling these problems to be coupled by multiaffine constraints. The project will combine this multiaffine ADMM (M-ADMM) approach with stochastic and/or distributed approaches that are provably efficient and scalable.  For stochastic M-ADMM methods, how to reduce variance and importance sampling will be studied. For distributed settings, how to incorporate both centralized and decentralized concensus constraints into an M-ADMM framework will be investigated, as will asynchronous variants. The project will empirically study how to distribute the the computational effort of M-ADMM, both according to blocks of data and groups of parameters in high dimensional models. Because multiaffine problems are highly nonconvex, the solutions obtained by M-ADMM are in general only guaranteed to be local optima. It is known however, that for certain  multiaffine optimization problems, every local minimum is a global minimum and every saddle point has a direction of strict negative curvature under reasonable assumptions. The project will attempt to expand these kinds of results to more general multiaffine constrained problems and study the ability of M-ADMM for avoiding stagnating near saddle points.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1908198
Title: BIGDATA: Collaborative Research: F: Efficient and Exact Methods for Big Data Reduction
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: February 12, 2019
Latest Amendment Date: June 09, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 16, 2018
End Date: August 31, 2022
Awarded Amount to Date: $396,849
ARRA Amount: $
Investigator(s): Shuiwang Ji sji@tamu.edu (Principal Investigator) 
Organization: Texas A&M Engineering Experiment Station
3124 TAMU, COLLEGE STATION, TX 77843-3124, (979)862-6777
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Abstract<br/><br/>Research in big data involves analyzing growing data sets with huge numbers of samples, very high-dimensional feature vectors, and complex and diverse structures. The ever-growing volume and complexity of these data sets make many traditional techniques inadequate to extract knowledge from them. An emerging area, known as sparse learning, has achieved great success in learning from big data by identifying a small set of explanatory features and/or samples. Typical examples include selecting features that are most indicative of users? preferences for recommendation systems, identifying brain regions that are predictive of neurological disorders based on imaging data, and extracting semantic information from raw images for object recognition. However, training sparse learning models can be computationally prohibitive due to the sparsity-inducing regularization, which is non-smooth and can be highly complex when incorporating complex structures. This project aims at developing algorithms and tools to significantly accelerate the training process of sparse learning models for big data applications. The key idea is to efficiently identify redundant features and/or samples, which can be removed from the training phase without losing useful information of interests. Success in these unique techniques is expected to dramatically scaling up sparse learning for big data by orders of magnitude in terms of both time and space. The PIs plan to integrate the big data reduction tools developed in this project into their education and outreach activities, including development of new courses and integration of project components into existing courses. The PIs will make special efforts to recruit female and underrepresented students to this project.<br/><br/>The major technical innovations of this project include the following components: (1) the PIs will develop efficient feature reduction methods for the generic scenario where the structures of both input and output can be represented by directed acyclic graphs; the proposed formulations include many existing approaches as special cases; (2) the PIs will develop efficient methods to reduce the numbers of features and samples simultaneously under a unified formulation, which can also incorporate various structures; (3) the PIs will develop efficient methods to discard irrelevant data subspaces to accelerate the process of uncovering low-rank structures commonly seen in big data. All the proposed data reduction methods are exact, i.e., the models learned on the reduced data sets are identical to the ones learned on the full data sets. This project heavily relies on optimization theory, especially on sensitivity analysis and convex geometry. The outcome of this project includes a unified approach to accelerate sparse learning and provide a systematic framework for developing efficient and exact data reduction methods. The systematic study and in-depth exploration of redundant data identification is expected to deepen the understanding of sparse learning techniques and dramatically enhance their applications in big data analytics.

Award Number: 1934986
Title: HDR TRIPODS: Illinois Institute for Data Science and Dynamical Systems (iDS2)
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 11, 2019
Latest Amendment Date: August 18, 2021
Award Instrument: Continuing Grant
Program Manager: Zhengdao Wang
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Maxim Raginsky maxim@illinois.edu (Principal Investigator) Rayadurgam Srikant (Co-Principal Investigator) Yuguo Chen (Co-Principal Investigator) Oluwasanmi Koyejo (Co-Principal Investigator) Niao He (Co-Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: This project establishes the Illinois Institute for Data Science and Dynamical Systems (iDS2) at the University of Illinois at Urbana Champaign (UIUC) that combines research in data science with dynamical systems. iDS2 is composed of researchers in electrical engineering, computer science, statistics and mathematics.  Data science already exerts considerable influence over daily life. As the age of autonomous vehicles, smart cities, personalized medicine, and artificial intelligence continues to emerge, both data-driven algorithms and dynamical feedback loops will permeate every aspect of human existence. It is becoming increasingly clear that the study of dynamical systems is at the heart of fundamental challenges arising in data science. Indeed, system dynamics occur in every facet of data science, from data generation, modeling, and inference, all the way to learning and automation. Since the study of dynamical systems cuts across the disciplines of engineering, mathematics, statistics, and computer science, a synthesis of data science and dynamical systems will be a powerful catalyst for further advances in all of these fields.<br/><br/>The aim of this project is to initiate this synthesis through iDS2, which will leverage the multidisciplinary expertise and strengths at UIUC in these two fields. The overall vision of iDS2 is to create and foster a transdisciplinary program that breaks the boundaries between the fields of data science and dynamical systems by developing new foundational principles for both fields and by broadening their applicability. The Phase I activities of the institute will focus on four interrelated research themes: (1) data modeling and dynamical systems; (2) sampling, inference, and dynamical systems; (3) algorithm design and dynamical systems; (4) decision-making and dynamical systems. The institute will foster synergies with existing research and education entities at UIUC in order to catalyze and scale up interactions between the TRIPODS communities of electrical engineering, mathematics, statistics, and theoretical computer science, both at UIUC and in the Midwest.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934612
Title: Collaborative Research: Physics-Based Machine Learning for Sub-Seasonal Climate Forecasting
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Amy Walton
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $399,992
ARRA Amount: $
Investigator(s): Robert Nowak rdnowak@wisc.edu (Principal Investigator) Stephen Wright (Co-Principal Investigator) 
Organization: University of Wisconsin-Madison
21 N PARK ST STE 6301, MADISON, WI 53715-1218, (608)262-3822
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: While the past few decades have seen major advances in weather forecasting on time scales of days to about a week, making high quality forecasts of key climate variables such as temperature and precipitation on sub-seasonal time scales, the time range between 2 weeks and 2 months, continues to challenge operational forecasters. Skillful climate forecasts on sub-seasonal time scales would have immense societal value in areas such as agricultural productivity, hydrology and water resource management, transportation and aviation systems, and emergency planning for extreme events such as Atlantic hurricanes and midwestern tornadoes. In spite of the scientific, societal, and financial importance of sub-seasonal climate forecasting, progress on the problem has been limited. The project has initiated a systematic investigation of physics-based machine learning with specific focus on advancing sub-seasonal climate forecasting. In particular, this project is developing novel machine learning (ML) approaches for sub-seasonal forecasting by leveraging both limited observational data as well as vast amounts of dynamical climate model output data. Further, the project is focusing on improving the dynamical climate models themselves based on ML with specific emphasis on learning model parameterizations suitable for accurate sub-seasonal forecasting. The principles, models, and methodology for physics-based machine learning being developed in the project will benefit other scientific domains which rely on dynamical models. The project is establishing a public repository of a benchmark dataset for sub-seasonal forecasting to engage the wider data science community and accelerate progress in this critical area. The project is training a new generation of interdisciplinary scientists who can cross the traditional boundaries between computer science, statistics, and climate science.<br/><br/>The project works with two key sources of data for sub-seasonal forecasting: limited amounts of observational data and vast amounts of output data from dynamical model simulations, which capture physical laws and dynamics based on large coupled systems of partial differential equations (PDEs). The project is investigating the following central question: what is the best way to learn simultaneously from limited observational data and imperfect dynamical models for improving sub-seasonal forecasts? The project is building a framework for physics-based machine that has two inter-linked components: (1) deduction, in which ML models are trained on dynamical model outputs as well as limited observations, and (2) induction, in which ML models are used to improve dynamical models. Across the two components, the project is making fundamental advances in learning representations, functional gradient descent, transfer learning, derivative-free optimization and multi-armed bandits, Monte Carlo tree search, and block coordinate descent. On the climate side, the project is building an idealized dynamical climate model and doing an in depth investigation on learning suitable parameterizations for the dynamical model with ML methods to improve forecast accuracy in the sub-seasonal time scales. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838200
Title: BigData:IA:Collaborative Research: TIMES: A tensor factorization platform for spatio-temporal data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: August 05, 2019
Award Instrument: Continuing Grant
Program Manager: Wei-Shinn Ku
Start Date: October 01, 2018
End Date: September 30, 2022
Awarded Amount to Date: $950,337
ARRA Amount: $
Investigator(s): Joyce Ho joyce.c.ho@emory.edu (Principal Investigator) Li Xiong (Co-Principal Investigator) 
Organization: Emory University
201 DOWMAN DR, ATLANTA, GA 30322-1007, (404)727-2503
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083 9102
Program Element Code(s): 8083
Abstract: Spatio-temporal analyses can enable many discoveries including reducing traffic congestion, identifying hotspot areas to deploy mobile clinics, and urban planning. Unfortunately, the data poses many computational challenges.  Standard assumptions in machine learning and data mining algorithms are violated by the complex nature of spatio-temporal data.  These include spatial and temporal correlation of observations, dynamic and abrupt changes in observations, variability in measurements with respect to length and frequency, and multi-sourced data that spans multiple sources of information. In recognition of these challenges, various efforts have been undertaken to develop specialized spatiotemporal models. Yet, to date, these algorithms are predominately designed to analyze small- to medium-sized datasets. The goal of this project is to develop a comprehensive computational tensor platform to perform automated, data-driven discovery from spatio-temporal data across a broad range of applications. The project also includes a set of integrated educational activities such as a Massive Open Online Course that covers cross-disciplinary topics at the confluence of computer science and geospatial applications, annual spatio-temporal data challenges and hackathons, and an annual event at the Atlanta Science Festival to create public awareness and encourage participation by women and minorities.<br/><br/>The project will contain algorithmic innovations that reflect appropriate assumptions of spatio-temporal data without sacrificing real-time performance, computational scalability, and cross-site learning even under privacy constraints. The proposed platform will generalize tensor modeling to encompass the complex nature of spatio-temporal data including time irregularity, spatiotemporal correlations, and evolving distributions. It will enable the integration of multi-sourced data from heterogeneous sources to yield robust and cohesive learned patterns. The novel algorithms will also facilitate learning in decentralized settings while preserving privacy. The computational platform will contain interchangeable modules that can adapt to new spatio-temporal settings and incorporate additional contextual information.  The accompanying suite of algorithms will enable predictive learning, pattern mining, and change detection from large-sized spatio-temporal data.  The broad applicability of the project will be demonstrated on a diverse range of data including urban transportation services, real estate market transactions, and population health. The algorithmic innovations introduced can be used to scale other machine learning models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924008
Title: HDR DSC: Collaborative Research: Central Coast Data Science Partnership: Training a New Generation of Data Scientists
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2019
Latest Amendment Date: September 19, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $243,638
ARRA Amount: $
Investigator(s): Jonathan Ventura jventu09@calpoly.edu (Principal Investigator) Alexander Dekhtyar (Co-Principal Investigator) Foaad Khosmood (Co-Principal Investigator) Hunter Glanz (Co-Principal Investigator) Dennis Sun (Co-Principal Investigator) 
Organization: California Polytechnic State University Foundation
1 GRAND AVE, SAN LUIS OBISPO, CA 93407-9000, (805)756-2982
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Due to the societal and technological advances made possible by data-driven science, there is a strong demand for professionals versed in the tools and techniques needed for manipulating and understanding data. This project will develop an undergraduate curriculum in data science that spans and connects the three main public higher education systems in California: the research-driven University of California system, the practical and career-oriented California State University system, and the two-year California Community Colleges. The collaborative program will establish pathways for data science training through coursework and real-world projects. This project will impact students from diverse social, ethnic, cultural, and economic backgrounds and will improve the feeder pipelines from two-year colleges to four-year universities. This multi-campus approach to building a data science training program will foster collaborations for training a diverse workforce in data science. The resulting course materials and project outcomes will be made available so that other institutions can adopt best practices.<br/><br/>The partnership consists of four academic institutions on the West Coast: University of California, Santa Barbara (UCSB), California Polytechnic State University, San Luis Obispo (Cal Poly), Santa Barbara City College (SBCC), and California State University, San Bernardino (CSUSB). The alliance will expand training at UCSB and Cal Poly by building on existing strengths through a sequence of new capstone courses, as well as lay the groundwork for data science curriculum development at SBCC and CSUSB, whose students will participate in a summer internship program at UCSB. Over 100 undergraduate students will be supported by stipends during the course of the project. The developed courses will emphasize  programming and data inference within the context of application domains that is critical to training in data science. Students will be taught the underlying principles of data science, including data-generating processes and the role of measurement, ethics and privacy, information-processing tools for harnessing the power of big data, and the oral and written communication skills necessary for pursuing effective professional careers in the field. The program will culminate in a year-long capstone course for seniors, who will synthesize and apply previously learned data science tools and techniques in a large-scale project in a chosen domain area.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939263
Title: HDR: DIRSE-IL: Collaborative Research: Harnessing data advances in systems biology to design a biological 3D printer: the synthetic coral
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $260,081
ARRA Amount: $
Investigator(s): Lenore Cowen cowen@eecs.tufts.edu (Principal Investigator) 
Organization: Tufts University
169 HOLLAND ST FL 3, SOMERVILLE, MA 02144-2401, (617)627-3696
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: Corals are important natural resources that are key to the ocean's vast biodiversity and provide economic, cultural, and scientific benefits. As a result of human activities, locally and globally, coral reefs are declining rapidly. The complexity of corals makes conserving and restoring reefs very challenging. Corals are made up of thousands of different organisms, including the animal host and the algae, bacteria, viruses, and fungi that coexist as a so-called holobiont. Thus, corals are more like cities than individual animals, as they provide factories, housing, restaurants, nurseries, and more for an entire ecosystem. This project brings together experts in computer science, materials science, and biology to harness the data revolution in biology with machine learning to study how corals grow and function, when viewed as if they were manufacturing sites in the ocean. The study will focus on three key coral capabilities: (1) they create calcium carbonate skeletons that provide 3D structures for diverse sea life to live in, (2) they can heal damage to their tissues, and, (3) they live with the other organisms in a process referred to as symbiosis. Through these remarkable abilities, corals can 'print' resources for themselves and hundreds of thousands of other species, just like a 3D printer. The goal of this project is to understand these processes well enough to control them in the lab. This project may allow finding new ways to help coral survival, by deciphering the reasons why certain conditions damage them and find ways of repairing them. Furthermore, by synthetically growing corals, new types of materials may be identified for manufacturing. This project offers an opportunity to educate a diverse scientific workforce and the public by creating and disseminating the outcomes of a convergent research environment and will train postdoctoral researchers, graduate, and undergraduate students. Results of this research will be made available to the broader scientific community through web interfaces, peer-reviewed publications and workshops/conferences and shared with the public through outreach activities online, at schools, and public aquariums.<br/>    <br/>Through convergence of three disciplines, computer science, material science and biology, this project will provide a data-driven framework and toolset to learn from, control, engineer, and manufacture a combined form of living material, the 'synthetic coral', thereby opening new avenues for material synthesis and manufacturing. The research methodology will offer new analytical approaches to identify and quantify the parameters that govern coral growth and foster innovative new tools for controlling their growth. To understand the key functions of coral biology of biomineralization, wound healing, and symbiosis, this research will : (1) harness and analyze large amounts of coral '-omics' data to decipher critical molecules and their interactions for the aforementioned key functions, (2) experimentally validate the resulting predictions in coral individuals and cell lines, (3) manipulate the material properties of the calcium carbonate structures of the coral individuals and cell lines, and (4) test the biological and physical interactions in a network model of the 'synthetic coral'. This project develops and integrates fundamental building blocks that are essential for  an integrated computational and experimental validation system. Specifically, using machine learning, diverse data will be harnessed to identify physical conditions (e.g., surface characteristics), environmental conditions (e.g., temperature, pH), and key biological constituents (e.g., small molecule ligands and proteins encoded in the DNA) that are correlated to key structural and functional properties of the coral holobiont. These predicted conditions and molecules will be verified experimentally by perturbing individual coral nodes in a network of a 3D printed array of intact corals or their constituent cells and measuring their effects on the network of interactions and resulting structures. The results from this prediction-validation cycle will then be transferred back as input to manufacture novel adaptive materials fully embracing the organic/inorganic interface. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924337
Title: HDR DSC: Earth Data Science Corps - Fulfilling Workforce Demand at the Intersection of Environmental Science and Data Science
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 09, 2019
Latest Amendment Date: June 02, 2022
Award Instrument: Continuing Grant
Program Manager: John Jackman
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $1,180,445
ARRA Amount: $
Investigator(s): Jennifer Balch jennifer.balch@colorado.edu (Principal Investigator) Leah Wasser (Former Principal Investigator) Nathan Quarderer (Co-Principal Investigator) Jennifer Balch (Former Co-Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 083Z 8209 9178
Program Element Code(s): 099Y
Abstract: This project aims to develop an open, scalable, and adaptable model for data science education to address the growing demand for a 21st-century data-capable workforce in Earth and Environmental Sciences. The model will be structured around an online educational framework for Earth Data Science (DS). The Earth Data Science Corps (EDSC) framework includes modular courses, an interactive open textbook, internships, and workshops for faculty and instructors from partner colleges. University of Colorado at Boulder as the coordinating organization will work closely with United Tribes Technical College, Oglala Lakota College, Front Range Community College, Metropolitan State University of Denver as implementing institutions. This project serves underrepresented students in the sciences including Hispanic, Tribal, community college, and non-traditional students. The EDSC plans to provide the community with two open tools. The first will make grading student coding assignments easier. The second will make analyzing evaluation survey data more efficient. A public, online discussion forum will provide students across implementing institutions with community support. Further, it will facilitate discussions between faculty on challenges and opportunities associated with teaching data science to diverse groups. This effort will encourage diversity and equitable opportunity in the national 21st-century data-literate workforce, contributing to bridging the data-to-knowledge gap in environmental science. If successful, it has the potential to reveal answers to some of society's most pressing environmental challenges.<br/> <br/>The objectives of this project are two-fold. Students will gain knowledge in data science, problem-solving skills, hands-on experience, and rigorous research training. Instructors to have access to the training that will enable them to build data science capacity in the context of their own institutions. EDSC will be structured around five activities: 1) a modular Earth Data Science course supported by online computer processing power (cloud computing), a companion interactive, free online textbook, and an autograding platform; 2) data skills and career workshops for teachers and students; 3) paid hands-on undergraduate student internships; 4) faculty instructor training; and 5) program-wide evaluation. If successful, these activities will allow five diverse higher education institutions to adopt different elements depending on their current capacity. The project builds on existing efforts of the University of Colorado Earth Lab Education Initiative. Curricular materials will be designed for portability, sustainability, and easy dissemination to ensure their expanded impact. They will be evaluated for measurable outcomes and tailored to support non-traditional students, who form a large portion of the potential data science workforce in the regions surrounding the participating institutions. Course curriculum, including career development webinars, Introduction to Earth Data Science course modules, and instructor training, will be published on the EDS Learning Portal, leveraging the existing and rapidly growing user base.  The EDSC plans to directly support 75 undergraduate students, train 15 faculty in data-intensive teaching, and provide data skill and career-development training to 400 or more participants across the five institutions. NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741317
Title: BIGDATA: F: Collaborative Research: Taming Big Networks via Embedding
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2017
Latest Amendment Date: August 30, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2018
End Date: December 31, 2022
Awarded Amount to Date: $400,001
ARRA Amount: $
Investigator(s): Jiawei Han hanj@cs.uiuc.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: In the Internet Age, information entities and objects are interconnected, thereby forming gigantic information networks. Recently, network embedding methods, that create low-dimensional feature representations that preserve the structure of data points in their original space, have been shown to be greatly beneficial for many data mining and machine learning problems over networks. Despite significant research progress, we are still lacking powerful network embedding techniques with theoretical guarantees to effectively deal with massive, heterogeneous, complex and dynamic networks. The PIs aim to develop a new generation of network embedding methods for analyzing massive networks. The research project has the potential to significantly transform graph mining and network analysis. The PIs also plan to develop open course materials and open source software tools that integrate information network analysis and machine learning. <br/><br/>This project consists of four synergistic research thrusts. First, it develops model-based network embedding to leverage the first-order and second-order proximity of networks. Second, it devises a family of inductive network embedding methods that are able to leverage both linkage information and side information. Third, it develops both local clustering and deep learning based network embedding methods to attack the complex structure of networks such as locality and non-linearity. Fourth, it develops online and stochastic optimization algorithms for different network embedding methods to tackle the fast growth and evolution of modern massive networks. The new methods developed in this project enjoy faster rates of convergence in optimization, lower computational complexities, and statistical learning guarantees. The targeted applications include but are not limited to semantic search and information retrieval in social/information network analysis, expert finding in bibliographical database, and recommendation systems.

Award Number: 1758149
Title: Data Corps Workshop
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: November 29, 2017
Latest Amendment Date: October 13, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: December 01, 2017
End Date: November 30, 2022
Awarded Amount to Date: $49,900
ARRA Amount: $
Investigator(s): Michael Bailey baileyma@georgetown.edu (Principal Investigator) 
Organization: Georgetown University
MAIN CAMPUS, WASHINGTON, DC 20057-0001, (202)625-0100
NSF Directorate: CSE
Program(s): ECR-EHR Core Research Big Data Science &Engineering 
Program Reference Code(s): 7556 8083
Program Element Code(s): 7980, 8083
Abstract: A workshop will be held in Washington, DC on December 7-8, 2017 to plan for the creation of a Data Science Corps. The Data Science Corps will help build the capacity of organizations at the local, state, national and international levels to utilize data to advance science and to help solve social problems. The Data Science Corps would offer practical experiences and teaching opportunities to U.S. data scientists and data science students, who would serve as volunteers working on data science projects in a variety of venues including, academia, industry, government, and various urban and rural communities. <br/><br/>The workshop will bring together a wide variety of stakeholders to discuss the vision and implementation of such a Data Science Corps. It will provide the opportunity to define the organizational and implementation details of the Data Science Corps, and will elaborate upon how the initiative can best serve the volunteers as well as the program beneficiaries. The workshop will include presentations by speakers representing a variety of stakeholders, and will include discussions sessions to help develop ideas for establishment of the program.<br/><br/>Via the Data Science Corps, volunteers--including data science professionals as well as data science students--will be able to offer assistance to real world data science problems, and will provide data science training to users across a wide variety of sectors. By providing assistance to projects in academia, industry, government in communities at the local, state and national levels, Data Science Corps volunteers would gain practical experience on real world data science problems, as well as gain experience as data science teachers and trainers.<br/><br/>The Data Science Corps program can help enhance existing internship programs at academic institutions by providing a data science theme and focus. The Data Science Corps would complement existing NSF programs, including the Big Data Regional Innovation Hubs, Spokes, and Smart and Connected Communities.<br/><br/>Such a program will help with improved data collection and data analysis across all applications areas, whether in urban or rural communities, and at the local, state, national and international levels. As a result, these communities will have greater capacity to implement data-driven solutions.

Award Number: 1934725
Title: DELTA: Descriptors of Energy Landscape by Topological Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 20, 2020
Award Instrument: Continuing Grant
Program Manager: Rebecca Peebles
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $1,600,000
ARRA Amount: $
Investigator(s): Aurora Clark auclark@wsu.edu (Principal Investigator) Markus Pflaum (Co-Principal Investigator) Yang Zhang (Co-Principal Investigator) Ravishankar Sundararaman (Co-Principal Investigator) Henry Adams (Co-Principal Investigator) 
Organization: Washington State University
240 FRENCH ADMINISTRATION BLDG, PULLMAN, WA 99164-0001, (509)335-9661
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 8037 9216 9263
Program Element Code(s): 099y, 1978
Abstract: Twenty years ago, machine learning (ML) began a trajectory of theoretical/algorithmic improvements that have led to advanced materials for energy efficiency and molecular machines that synthesize molecules in ways unfathomable by the human hand. Those key advances were based upon a foundation of statistical methods that now mirror the field of topological data analysis (TDA) - which combines algebraic topology with computational methods to extract new knowledge by characterizing the global shape of data. Professor Clark at Washington State University, Professor Adam at Colorado State, Professor Pflaum at University Colorado Boulder, Professor Sundararaman at Rensselaer Polytechnic Institute, and Professor Zhang at University of Illinois Urbana Champagne are developing the Institute for Data-Intensive Research in Science and Engineering - Frameworks entitled "Descriptors of Energy Landscapes Using Topological Data Analysis" (DELTA).  They are working on advancing TDA for the study of intensive and complex data sets found in Chemistry by focusing upon the development of methods and software tools that characterize the function that describes energy flow during chemical transformations, known as the energy landscape. Scalable and extensible TDA tools are used to extract new information from the energy landscape, understanding how it changes under different applied conditions and supporting a new paradigm in Chemistry, including the long-standing challenge of real-time optimization and control of chemical systems. At the intersection of Math, Data Science, and Chemistry, students trained under DELTA and its collaborative partners develop the skills and the foundation for a new community of practice.<br/><br/>Chemists generally do not know how the underlying energy landscape of transformation changes as a function of system conditions, nor are there quantifiable relationships between intra- and intermolecular interactions and its topological features. Topological data analysis (TDA) is uniquely poised to extract new information from the energy landscape (EL), as it combines algebraic topology with computational methods to characterize its global shape of data. The Descriptors of Energy Landscapes Using Topological Data Analysis (DELTA) Institute Frameworks adapts TDA for chemistry applications, invoking persistent homology, Morse theory, catastrophe theory, and other topological descriptors and creating new software tools that are accessible by domain experts. Tackling the 3N-dimensional energy surface necessitates scalable and extensible tools that first reduce its dimensionality (Objective 1), then yield geometric and topological descriptors that quantify the way in which the EL is perturbed under different chemical conditions (Objective 2). This provides the basis for new predictive methods that accelerate sampling of large regions of the EL and have have learned how to optimize landscape topology to control the fate of reacting molecules and phase behavior (Objective 3). <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity. The effort is jointly funded by the Division of Chemistry within the NSF Directorate for Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924292
Title: HDR DSC: Collaborative Research: Connecting the Dots
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $747,947
ARRA Amount: $
Investigator(s): Jeffrey Errington jerring@buffalo.edu (Principal Investigator) Liesl Folks (Former Principal Investigator) Bina Ramamurthy (Co-Principal Investigator) Liesl Folks (Co-Principal Investigator) Kristen Moore (Co-Principal Investigator) Erin Rowley (Co-Principal Investigator) Jeffrey Errington (Former Co-Principal Investigator) 
Organization: SUNY at Buffalo
520 LEE ENTRANCE STE 211, AMHERST, NY 14228-2577, (716)645-2634
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu IIS Special Projects 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 7484
Abstract: There is significant demand for a workforce that is proficient in data science and analytics. Employers seek graduates with an ability to (1) understand, interpret, and analyze data, (2) effectively communicate results that stem from the analysis of data, (3) practice the ethical use of data, and (4) apply data science concepts to solve practical problems with real-world relevance. Data from job search sites indicate that the demand in New York State is particularly acute. A 2018 report from the National Academies of Sciences, Engineering, and Medicine entitled "Data Science for Undergraduates: Opportunities and Options" calls for institutions to advance the so-called "data acumen" of graduates. While the dissemination of data science competencies has been emphasized in some disciplines (e.g., computer science), the broad delivery of these skills to college graduates has been slow to evolve. The aim of this project is to develop and implement a scalable, innovative program, termed "Connecting the Dots", for delivery of data science competencies to students pursuing an undergraduate engineering degree.<br/><br/>Connecting the Dots (CTD) is a highly collaborative project between the flagships schools in the State University of New York (SUNY) system, the largest higher education system in the nation, and the City University of New York (CUNY) system. CTD teams the University at Buffalo (UB) with the City College of New York (CCNY) with the goals to (a) strengthen the ability to understand and use data effectively to inform decisions among diverse undergraduate students from across the engineering disciplines, while (b) simultaneously increasing the capacity of regional community partners to incorporate data analytical methods into their business or strategic planning objectives. The signature academic data science track to be created by the CTD project team is an undergraduate certificate program, the New York Data Science Scholars program, that is readily integrated with any engineering major and that complements existing computer science majors at both the undergraduate and graduate level. A broad range of community partners are served via novel Data Science Community Labs, which act as "pop-up" summer facilities on the UB and CCNY campuses wherein students perform internship projects for community partners who have challenging data science problems for students to work on, but are not well-positioned to host a conventional intern. The team's ultimate scaling objective is to develop a program that is easily adopted by other SUNY and CCNY campuses that host 4-year engineering programs and by campuses outside of New York State with similar degree program structures. <br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934600
Title: Collaborative Research: Knowledge Guided Machine Learning: A Framework for Accelerating Scientific Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: July 02, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $342,000
ARRA Amount: $
Investigator(s): Aidong Zhang aidong@virginia.edu (Principal Investigator) Kevin Janes (Co-Principal Investigator) 
Organization: University of Virginia Main Campus
1001 N EMMET ST, CHARLOTTESVILLE, VA 22903-4833, (434)924-4270
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The success of machine learning (ML) in many applications where large-scale data is available has led to a growing anticipation of similar accomplishments in scientific disciplines. The use of data science is particularly promising in scientific problems involving processes that are not completely understood. However, a purely data-driven approach to modeling a physical process can be problematic. For example, it can create a complex model that is neither generalizable beyond the data on which it was trained nor physically interpretable. This problem becomes worse when there is not enough training data, which is quite common in science and engineering domains.  A machine learning model that is grounded by explainable theories stands a better chance at safeguarding against learning spurious patterns from the data that lead to non-generalizable performance. This is especially important when dealing with problems that are critical and associated with high risks (e.g., extreme weather or collapse of an ecosystem).  Hence, neither an ML-only nor a scientific knowledge-only approach can be considered sufficient for knowledge discovery in complex scientific and engineering applications. This project is developing novel techniques to explore the continuum between knowledge-based and ML models, where both scientific knowledge and data are integrated synergistically. Such integrated methods have the potential for accelerating discovery in a range of scientific and engineering disciplines. This project will train interdisciplinary scientists who are well versed in such methods and will disseminate results of the project via peer-reviewed publications, open-source software, and a series of workshops to engage the broader scientific community.<br/><br/>This project aims to develop a framework that uses the unique capability of data science models to automatically learn patterns and models from data, without ignoring the treasure of accumulated scientific knowledge. Specifically, the project builds the foundations of knowledge-guided machine learning (KGML) by exploring several ways of bringing scientific knowledge and machine learning models together using pilot applications from four domains: aquatic ecodynamics, climate and weather, hydrology, and translational biology. These pilot applications were selected because they are at tipping points where knowledge-guided machine learning can have a transformative effect.  KGML has the potential for providing scientists and engineers with new insights into their domains of interest and will require the development of innovative new machine learning approaches and architectures that can incorporate scientific principles. Scientific knowledge, KGML methods, and software developed in this project could potentially be extended to a wide range of scientific applications where mechanistic (also known as process-based) models are used.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123447
Title: Collaborative Research: HDR DSC: The Metropolitan Chicago Data Science Corps (MCDC): Learning from Data to Support Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 20, 2021
Latest Amendment Date: September 23, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $400,001
ARRA Amount: $
Investigator(s): Suzan van der Lee suzan@northwestern.edu (Principal Investigator) Bennett Goldberg (Co-Principal Investigator) Michelle Birkett (Co-Principal Investigator) Diane Schanzenbach (Co-Principal Investigator) 
Organization: Northwestern University
633 CLARK, EVANSTON, IL 60208-0001, (312)503-7955
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc Unallocated Program Costs 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y, 1640, 9199
Abstract: Diverse experts from five universities in, or with a presence in, the Chicago area are collaborating as the Metropolitan Chicago Data-science Corps to 1) help local non-profit organizations take advantage of increasing data volume and data complexity, 2) train data science students in how to effectively apply their academic knowledge to real data challenges in the non-profit sector, 3) exchange data science curriculum and expertise among these universities and with local community colleges. An organization can submit a Request for Data Services (RDS) and receive help to develop it. MCDC particularly welcomes RDS in areas related to environment, health, and our social well-being. Each RDS is assigned to a team of students. Teams of students with a foundation in data science are formed within a practicum course or as part of a summer internship. MCDC will develop the practicum course, where each team has one or more expert mentors and forms a partnership with the requesting organization. At the end of the term, each team will deliver a solution to each of the requesting organizations.<br/><br/>MCDC is an interdisciplinary partnership between universities, myriad community organizations, and two expansion colleges and aims to strengthen the national data science workforce by integrating community needs with academic learning. By supporting infrastructure to unite diverse students and faculty across institutions and disciplines, by prioritizing the engagement of community, and embedding real-world team-based data science projects into the curriculum, the MCDC will be a uniquely powerful educational experience which will support societal progress. To realize this goal, existing curricula are grouped into multiple pathways to prepare a diverse range of students for participation in MCDC. MCDC students acquire both data acumen and societal knowledge that is intended to lead to a well-prepared and engaged workforce. The MCDC project directors combine extensive, proven, funded, and diverse expertise in curriculum development, inclusive learning practices, integrating real-world data into courses, learning systems, data science, as well as in health, social, and environmental sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1923934
Title: HDR DSC: Collaborative Research: The Data Science WAV: Experiential Learning with Local Community Organizations
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $135,858
ARRA Amount: $
Investigator(s): Valerie Barr vbarr@mtholyoke.edu (Principal Investigator) 
Organization: Mount Holyoke College
50 COLLEGE ST, SOUTH HADLEY, MA 01075-1423, (413)538-2000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: This project simultaneously addresses two problems: 1) the inability of community-based and non-profit organizations to tackle data science problems; and 2) the lack of real world experience gained by students studying data science. The increased availability of data, combined with increased computing power at lower costs, has brought to the desktop tremendous analytical and problem solving capabilities. Yet many organizations are not able to take advantage of these developments because they often lack appropriate staffing to wrestle with complex data science problems. Meanwhile, as students increasingly gravitate toward data science programs, much of their course-based problem solving experience focuses on clean problems with simple data sets. This leaves them unprepared for the reality of the data science applications they will face in professional settings. This project addresses both issues by deploying teams of data science students to assist local organizations, thereby increasing the long-term capacity of the data science workforce.<br/><br/>This is a multifaceted project that will provide immediate impact to local organizations and long-term benefit for students through valuable hands-on data science experience. There are two major components of the proposed project. First, Data Science WAV teams of four specially-trained undergraduate students will be deployed to community-based organizations to Wrangle, Analyze, and Visualize their data. Second, this project will offer summer faculty development workshops designed to help new instructors, especially those at community colleges, teach data science at their institutions. Curricular innovations that bring experiential data science learning into the curriculum will lead to sustained impact at the partnering academic institutions and in the larger Pioneer Valley region. This proposal is diverse across both institutions and student populations. It comprises one major research university (The University of Massachusetts, Amherst), four liberal arts colleges (Amherst, Hampshire, Mount Holyoke, and Smith), and three local community colleges (Greenfield, Holyoke, and Springfield Technical). The inclusion of two women's colleges (Smith and Mount Holyoke) and two Hispanic-serving institutions (Holyoke and Springfield Technical) will help ensure that a diverse student population is engaged in the project. <br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741174
Title: BIGDATA: IA: Collaborative Research: From Bytes to Watts - A Data Science Solution to Improve Wind Energy Reliability and Operation
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 15, 2017
Latest Amendment Date: September 22, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $274,999
ARRA Amount: $
Investigator(s): Jiong Tang jtang@engr.uconn.edu (Principal Investigator) 
Organization: University of Connecticut
438 WHITNEY RD EXTENSION UNIT 11, STORRS, CT 06269-1133, (860)486-3622
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: The collective efforts in aerospace, civil, electrical, and mechanical engineering areas have led to remarkable progresses in wind energy. Larger turbines are designed and installed, and wind farms are nowadays built at locations where wind is even more intermittent and maintenance equipment is less accessible. This adds new challenges to ensuring operational reliability. To cope with these challenges, along with the rapid advancement in microelectronics, modern wind farms are equipped with a large number and variety of sensors, including, at the turbine level, anemometers, tachometers, accelerometers, thermometers, strain sensors, and power meters, and at the farm level, anemometers, vanes, sonars, thermometers, humidity meters, pressure meters, among others. It is worth noting that all these data are currently analyzed/utilized only in their respective domains. The big data challenges in this project include how to best use spatio-temporal data for wind forecast, how to use data of different nature (wind, power, load etc.) and data of different sources (physical data versus computer simulation data) for power production assessment in a computationally efficient manner, and finally how to integrate these three sets of solutions into a reliable and efficient computational platform. The proposed research and education activities will make a paradigm shift in the wind industry by demonstrating how dramatically data science innovations can benefit the industry. The PIs will disseminate the research findings through classroom teaching, journal/conference publications, industry workshops, and data/software sharing. The summer internship opportunities and undergraduate research help train the next generation workforce to be better versed with data science methodologies.<br/><br/>The critical barrier to cost effective wind power and its general adoption is partly rooted in wind stochasticity, severely complicating wind power production optimization and cost reduction. The long-term viability of wind energy hinges upon a good understanding of its production reliability, which is affected in turn by the predictability of wind and power productivity of wind turbines. Furthermore, the productivity of a wind turbine comprises two aspects: its ability of converting wind into power during its operation and the availability of wind turbines. Three inter-related research efforts will enhance wind energy reliability and productivity): (1) spatio-temporal analysis (for wind forecast) (2) conditional density estimation (for wind-to-power conversion assessment); and (3) importance sampling (for turbine reliability assessment and improvement). Significant data resourced provided by industry partners in the research, coupled with models and computational resources, will enable better prediction of wind profiles and utilization.  In addition, the team will develop dedicated reconfigurable field programmable gate array (FPGA) processors that will be 50 to 500 times faster than general-purpose CPUs for both on-site and central control processing and have small form-factor, low cost and energy efficient to enable agile development under severe outdoor conditions at wind farms.

Award Number: 1931628
Title: BIGDATA: Collaborative Research: F: Efficient Distributed Computation of Large-Scale Graph Problems in Epidemiology and Contagion Dynamics
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: July 23, 2019
Latest Amendment Date: July 23, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: February 27, 2019
End Date: August 31, 2022
Awarded Amount to Date: $346,832
ARRA Amount: $
Investigator(s): Anil Kumar Vullikanti asv9v@virginia.edu (Principal Investigator) 
Organization: University of Virginia Main Campus
1001 N EMMET ST, CHARLOTTESVILLE, VA 22903-4833, (434)924-4270
NSF Directorate: CSE
Program(s): Algorithmic Foundations Big Data Science &Engineering 
Program Reference Code(s): 7433 7796 7934 8083 9251
Program Element Code(s): 7796, 8083
Abstract: A number of phenomena of societal importance, such as the spread of diseases and<br/>contagion processes, can be modeled by stochastic processes on networks. The analysis <br/>and control of such network phenomena involve, at their heart, fundamental graph-theoretic problems. <br/>The graphs encountered are typically of large-scale (having tens of millions of nodes); <br/>further, typical experimental analyses involve large designs with a number of parameters, <br/>leading to hundreds of thousands of graph computations. Novel methods for solving these problems<br/>are needed, since fast response times are critical to effective decision making.<br/>The overarching goal of this project is to develop efficient distributed algorithms <br/>and associated lower bounds for graph-theoretic problems that arise in computational <br/>epidemiology and contagion dynamics.  This will have a significant impact on these specific <br/>applications, through more efficient algorithmic tools for enabling complex analyses.  <br/>The project will also make fundamental contributions to the design and analysis of <br/>distributed algorithms for graph problems in large-scale networks, and will<br/>result in an algorithmic toolkit with building blocks for performing large-scale <br/>distributed graph computation.  The project will lead to significant curriculum development <br/>for undergraduate as well as graduate students, as well as public health analysts. <br/>Finally, the project will help in involving minority and underrepresented students in research. <br/><br/>The technical focus of the project will be on distributed algorithms for fundamental topics <br/>in graph algorithms such as graph connectivity, distances, subgraph analysis, and different<br/>kinds of centrality measures.  These topics underlie some of the recurring problems in the <br/>modeling, simulation and analysis and control of different kinds of contagion processes.  <br/>For all these problems, the project will focus on developing provably efficient distributed <br/>algorithms and showing lower bounds under a message-passing distributed computing model. <br/>The PIs will also develop efficient implementations of these algorithms, and evaluate their <br/>performance and solution quality in real-world graphs arising in epidemiology.  The graphs <br/>that arise in these applications have several novel characteristics, which will present new <br/>challenges as well as opportunities for distributed computing.

Award Number: 2039794
Title: Collaborative Research: I-AIM: Interpretable Augmented Intelligence for Multiscale Material Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2020
Latest Amendment Date: October 14, 2020
Award Instrument: Standard Grant
Program Manager: Alexis Lewis
Start Date: July 01, 2020
End Date: September 30, 2022
Awarded Amount to Date: $357,730
ARRA Amount: $
Investigator(s): Yusu Wang yusuwang@ucsd.edu (Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The ability to model, predict, and improve the mechanical performance of engineering materials such as polymers, composites, and alloys can have a significant impact on manufacturing, with important economic and societal benefits. As advanced computational algorithms and data science approaches become available, they can be harnessed to disrupt the current approaches to materials modeling, and allow for the design and discovery of new high-strength, high-performance materials for manufacturing. Bringing together multidisciplinary teams of researchers can maximize the impact of these new tools and techniques. This Harnessing the Data Revolution Institutes for Data-Intensive Research in Science and Engineering (HDR-I-DIRSE) award supports the conceptualization of an Institute to develop novel data science methods, address fundamental scientific questions of Materials Engineering and Manufacturing, and build such multidisciplinary teams. The project will apply novel data science methods to advance the analysis of large sets of structural data of composite materials and alloys from the atomic scale to correlate with and predict mechanical properties. The methods are based on machine learning techniques and uncertainty quantification, and will help uncover underlying structural features in the materials that determine the properties and performance. The methods and results will help accelerate the development of ultra-high strength and lightweight carbon-based composites for aerospace applications, and multi-element superalloys for more durable engine parts, by navigating in the large possible design space and providing faster predictions than experiments and traditional simulation methods. The project will also lead to new methods and computational algorithms that will become publicly available. The investigators will train graduate and undergraduate students from various disciplines with a focus on engaging women and minorities in STEM fields, develop short courses that integrate novel Materials Science and Engineering applications and Data Science methods, and foster vertical integration of interdisciplinary research from undergraduate students to senior scientists.<br/><br/>This project aims at building an effective and interpretable learning framework for materials data across scales to solve a major challenge in current data-driven materials design. The combined Materials Science and Data Science approaches will synergistically contribute to the development and use of interpretable and physics-informed data science methodologies to gain new understanding of mechanical properties of polymer composites and alloys, with the potential to be expanded into different property sets and different systems. The PIs will utilize available data efficiently through combination with physical rules and prior knowledge, to develop an interpretable augmented intelligent system to learn principles behind the association of input structures with material properties with uncertainty quantification. The interconnected tasks involve the (1) collection and curation of large amounts of computational and experimental data for polymer/carbon nanotube composites and alloys from open data sources and targeted calculations and experiments, (2) the development of geometric and topological methods incorporating physical principles to generate a better, more sensitive low-dimensional representation of the multidimensional data and characterize the parameter space related to mechanical properties, (3) the development of a Bayesian deep reinforcement learning framework to generate interpretable knowledge graphs that depict the relational knowledge among physical quantities with uncertainty quantification, and (4) the prediction of mechanical properties to reveal design principles to improve materials performance, evaluate and validate the methods, and develop software for dissemination. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity and is co-funded by the Division of Civil, Mechanical and Manufacturing Innovation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940096
Title: Collaborative Research: From Brains to Society: Neural Underpinnings of Collective Behaviors Via Massive Data and Experiments
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: August 26, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $561,086
ARRA Amount: $
Investigator(s): Catherine Stamoulis caterina.stamoulis@childrens.harvard.edu (Principal Investigator) 
Organization: Children's Hospital Corporation
300 LONGWOOD AVE, BOSTON, MA 02115-5724, (617)919-2729
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Info Integration & Informatics 
Program Reference Code(s): 062Z 9102 9251
Program Element Code(s): 099Y, 7364
Abstract: Despite thousands of investigations on the neural basis of individual behaviors and even more studies on collective behaviors, a clear bridge between the organization of individual brains and their combinational impact on group behaviors, such as cooperation and conflict and ultimately collective action, is lacking. To address the grand challenge of inferring group cooperation from the functional neuroarchitecture of individual brains, this project will harness advances in data, experiment and computation. Specifically, it will integrate, for the first time, existing large-scale human functional neuroimaging data, prospectively collected individual and group behavioral data from a large cohort, with cutting-edge machine learning tools, hierarchical models and large-scale simulations. This is a collaborative effort between a team of neuroscientists, social scientists and data scientists, that aims to elucidate the neural basis of cooperation, a fundamental process in a functioning society and at the core of social environments. <br/><br/>The project will first harness the combined wealth of existing neuroimaging and behavioral data from large-scale studies, including the Human Connectome-Lifespan (HCP-L) and the Adolescent Brain Cognitive Development (ABCD) and will leverage recent breakthroughs in machine learning to characterize the diversity, individuality and commonality of neural circuits (the connectome) supporting cognitive function across the lifespan. It will then conduct large-scale (~10,000 individuals) online behavioral experiments to identify connections between individual behaviors, decisions and group behaviors during a Public Goods Game. The experiments will measure individual proclivity towards cooperation and the social welfare obtained by cooperation, leading to potentially transformative insights into the emergence of cooperation within groups via individual behaviors. The resulting first-of-its-kind dataset may become a very valuable resource to the research community. Large-scale simulations based on statistical models estimated from this and the assembled neuroimaging datasets will then assess the direct or indirect relationships between individual connectomes and cooperation in group settings, and will elucidate the role of group processes in amplifying or ameliorating individual differences towards collective outcomes. Findings from this project may have a transformative impact on the scientific community's currently incomplete understanding of how individual brains shape societal behavior via cognitive, social, and interactive mechanisms.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123271
Title: Collaborative Research: HDR DSC: DS-PATH: Data Science Career Pathways in the Inland Empire
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 17, 2021
Latest Amendment Date: August 17, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2021
End Date: September 30, 2024
Awarded Amount to Date: $138,692
ARRA Amount: $
Investigator(s): Yunfei Hou yunfei.hou@csusb.edu (Principal Investigator) Jeremy Aikin (Co-Principal Investigator) Qingquan Sun (Co-Principal Investigator) Hani Aldirawi (Co-Principal Investigator) Ronald Salloum (Co-Principal Investigator) 
Organization: University Enterprises Corporation at CSUSB
5500 UNIVERSITY PKWY, SAN BERNARDINO, CA 92407-2318, (909)537-5929
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: This project brings together six partnering institutions to advance Data Science education in the Inland Empire, one of the most populous and diverse regions in California and the nation. The partnership includes the University of California Riverside, California State University San Bernardino, the three community colleges of the Riverside Community College District, and San Bernardino Valley College. All six partners are Hispanic Serving Institutions. The objective is develop and deploy ?The Data Science Career Pathways in the Inland Empire? (DS-PATH), a DSC program that aims to: (i) create flexible pathways for Data Science education in the Inland Empire region of Southern California, (ii) provide students with experiential learning opportunities, (iii) develop a community of partners that will provide local, tangible, and impactful Data Science projects, and (iv) broaden participation of females and under-represented minorities in Data Science. <br/><br/>The team of diverse PIs and co-PIs puts forward a program centered around more flexible educational pathways, along with course alignments, articulations, and shared experiential learning opportunities. DS-PATH will create a pipeline that starts with outreach opportunities at the high-school level, continues<br/>with undergraduate experiences and innovative bridge pathways from other majors, and culminates in professional Master?s degrees. Bridging these together is a Summer Fellowship program that will train 120 student participants at all levels. These pathways and the long-lasting relationships developed with local industry and community partners will continue to offer workforce development, educational advancement, and project-based learning opportunities not only for DS-PATH fellows but for all future aspiring Data Scientists in the region. Moreover, a workshop focused on Data Science pedagogy will<br/>offer best and inclusive teaching strategies to Inland Empire teachers/faculty.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837985
Title: BIGDATA: F: Algorithms for Tensor-Based Modeling of Large Scale Structured Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 11, 2018
Latest Amendment Date: September 07, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2018
End Date: September 30, 2022
Awarded Amount to Date: $1,418,872
ARRA Amount: $
Investigator(s): Kayvan Najarian kayvan@umich.edu (Principal Investigator) Harm Derksen (Former Principal Investigator) Harm Derksen (Co-Principal Investigator) Kevin Ward (Co-Principal Investigator) Kayvan Najarian (Former Co-Principal Investigator) Timothy Cornell (Former Co-Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: The project aims to develop efficient algorithms for big data applications by exploiting its rich structure. Big data often contains higher-dimensional arrays. One dimensional arrays are vectors and two dimensional arrays are matrices. Arrays of dimension three or more are called tensors and have a complex structure. Some of the challenges that the research team will address are noise removal, recovery of missing data by inference and data size reduction by distilling relevant information. The resulting methods will be applied to early detection of sepsis, which contributes to the death of 200,000 people in the United States every year.<br/><br/>Most algorithms for low rank structured tensors are based on the Canonical Polyadic decomposition (also known as CP, Parafac or Candecomp). These algorithms may converge slowly, are numerically unstable and are difficult to scale to big data. The theoretical framework for tensor decompositions that is used is based on an algebraic graphical calculus that utilizes colored Brauer diagrams to obtain explicit formulas. The graphical calculus will also be used to give accurate estimates for the computational and memory complexity of these algorithms. The investigators will design efficient, numerically stable and computationally feasible algorithms for crucial tensor operations that are widely applicable to big data applications. Specifically, the project isexpected to create fast, scalable and reliable algorithms for tensor analysis, and apply them to crucial big data tasks including noise removal, dimension reduction, imputation of missing data and classification in a variety of applications with structured data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934979
Title: HDR TRIPODS: Institute for the Foundations of Graph and Deep Learning
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 13, 2019
Latest Amendment Date: September 02, 2021
Award Instrument: Continuing Grant
Program Manager: Christopher Stark
Start Date: October 01, 2019
End Date: September 30, 2023
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Rene Vidal rvidal@cis.jhu.edu (Principal Investigator) Carey Priebe (Co-Principal Investigator) Mauro Maggioni (Co-Principal Investigator) Raman Arora (Co-Principal Investigator) Enrique Mallada (Co-Principal Investigator) 
Organization: Johns Hopkins University
3400 N CHARLES ST, BALTIMORE, MD 21218-2608, (443)997-1898
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: Classical data-analysis methods were based on mathematical, physical or statistical models for the data-generation process, which were developed under the assumption that the data were relatively clean and collected for a specific task. Over the past few decades, advances in data acquisition have led to massive, noisy, high-dimensional datasets, which were not necessarily collected for a specific task. This has lead to the emergence of data-driven methods, such as deep learning, which use massive amounts of labeled data to learn 'black-box' models, which do not provide an explicit description of the process being modeled. Such data-driven methods have led to dramatic improvements in the performance of pattern-recognition systems for applications in computer vision and speech recognition for which massive amounts of labeled data can be generated. However, existing models are not very interpretable, and their predictions are not robust to adversarial perturbations. Moreover, there are many applications in science and engineering where data labeling is extremely costly, and the ability to interpret model predictions and produce estimates of uncertainty is essential. To address these challenges, a TRIPODS Institute on the Theoretical Foundations of Data Science will be created at Johns Hopkins University. The goals of the institute will be to (1) develop the foundations for the next generation of data analysis methods, which will integrate model-based and data-driven approaches, (2) foster interactions among data scientists through a monthly seminar series, semester-long research themes, an annual research symposium, and a summer research school and workshop on the foundations of data science, and (3) create new undergraduate and graduate curricula on the foundations of data science.<br/><br/>The institute brings together a multidisciplinary team of mathematicians, statisticians, theoretical computer scientists, and electrical engineers with expertise in the foundations of machine learning, deep learning, statistical learning and inference on graphs, optimization, approximation theory, signal processing, dynamical systems and controls, to develop the foundations for the next generation of data-analysis methods, which will integrate model-based and data-driven approaches. In particular, the institute will focus on studying the foundations of deep neural models (e.g., feedforward networks, recurrent networks, generative adversarial networks) and generative models of structured data (e.g., graphical models, random graphs, dynamical systems), with the ultimate goal of arriving at integrated models that are more interpretable, robust to perturbations, and learnable with minimal supervision. The goals of the Phase I Institute will be to (1) study generalization, optimization and approximation properties of feedforward networks, (2) develop the foundations of statistical inference and learning on and of graphs, and (3) study the integration of deep networks and graphs for learning maps between structured datasets.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741341
Title: BIGDATA: F: Towards Automating Data Analysis: Interpretable, Interactive, and Scalable Learning via Discrete Probability
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2017
Latest Amendment Date: September 19, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $1,024,363
ARRA Amount: $
Investigator(s): Suvrit Sra suvrit@mit.edu (Principal Investigator) Stefanie Jegelka (Co-Principal Investigator) 
Organization: Massachusetts Institute of Technology
77 MASSACHUSETTS AVE, CAMBRIDGE, MA 02139-4301, (617)253-1000
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: As machine learning (ML) permeates all areas of science and technology, demands in diverse data domains, inference questions, resource limitations and reliability fuel several new conceptual and algorithmic challenges. Examples of current shortcomings that limit the full use of machine learning include suboptimal use of data and algorithms; painstaking hand-tuning and model search; validation of results and  difficulties in generalization; limited interactivity with humans; encoding of domain knowledge; and lack of interpretability, among others. Progress on these questions has the potential to impact the successful adoption and use of machine learning in a broad range of fields. With the above motivation, the goal of this project is to create a novel suite of models and algorithms for analyzing complex datasets, with a particular focus on the following three factors crucial for next-generation machine learning: (1) interpretability; (2) interactivity; and (3) automated learning. The overarching technical concept underlying this proposal is the concept of negative dependence in discrete probability. This project lays theoretical foundations for a new set of tools grounded in this concept. Besides practical impacts, the methods to be studied in the project motivate new theoretical questions, and will help increase interest in the underlying mathematics.<br/><br/>The practical impact of the proposed work has the potential to benefit society on multiple fronts. Via collaborations, the PIs will evaluate the developed methods in healthcare (seeking to ultimately impact patient care and well-being), systems biology (to help with research on cancer and diabetes, among others), and materials science (to help discover safer, functional materials more efficiently). The project will also directly have educational impact: training of graduate students, providing material for data science courses at all levels, and outreach to the community via general talks as well as focused lectures at conferences and workshops, including workshops and events targeted at women in Data Science. <br/><br/>Technically, the PIs will develop: (1) New tools, models, and algorithms for interactive data analysis, especially for experimental design, information collection, interpretable machine learning, hypothesis testing, performance validation, and architecture learning; (2) Theoretical analysis, such as convergence and complexity (statistical and computational); and (3) Open-source implementations of all key algorithms and frameworks.

Award Number: 1940093
Title: Collaborative Research: Precision Learning: Data-Driven Experimentation of Learning Theories using Internet-of-Videos
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Finbarr Sloane
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $400,000
ARRA Amount: $
Investigator(s): Xintao Wu xintaowu@uark.edu (Principal Investigator) 
Organization: University of Arkansas
1125 WEST MAPLE STE 210, FAYETTEVILLE, AR 72701-3124, (479)575-3845
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu IUSE 
Program Reference Code(s): 062Z 7645 9178
Program Element Code(s): 099Y, 1998
Abstract: This is a project to study what works to help students learn more effectively in the context of the ASSISTments system. ASSISTments is an online system that provides both assistance to students and real time assessment data to teachers. ASSISTments now supports 100,000 students who have completed more than 12 million mathematics problems. The system uses teacher input and artificial intelligence to provide assistance to students who are attempting to solve mathematics problems. This project will increase the assistance provided by the teacher and machine learning by incorporating video suggestions, such as those produced by the Kahn academy, targeted to the needs of the student. The experimentation will take content from three Open Educational Resource textbooks that are openly licensed and free to schools.<br/><br/>More specifically, the researchers will identify a large collection of videos that address mathematics skills in the textbooks and will extract features of these videos including language complexity, speaking rate, and other features. These videos and features will be checked by both teachers and through a Mechanical Turk process for usability before they are presented to students. Additionally, the project will develop a suite of novel technologies for precision learning including fine grained video feature extraction, student feature learning from heterogeneous raw data, causal modeling, and fairness aware and causal relationship enhanced optimized personalized recommendation. The research will advance theoretical understanding of fundamental issues related to personalized learning and will enable data-driven experimentation of learning theories. Causal modeling will enable the researchers to learn the features of video that are correlated with learning effectiveness. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity and is co-funded by the Division of Undergraduate Education and the Division of Research on Learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123401
Title: Collaborative Research: HDR DSC: The Metropolitan Chicago Data Science Corps (MCDC): Learning from Data to Support Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 20, 2021
Latest Amendment Date: August 20, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $170,287
ARRA Amount: $
Investigator(s): Mark Potosnak mpotosna@depaul.edu (Principal Investigator) Daniela Raicu (Co-Principal Investigator) Sungsoon Hwang (Co-Principal Investigator) Philip Yates (Co-Principal Investigator) 
Organization: DePaul University
1 E JACKSON BLVD, CHICAGO, IL 60604-2201, (312)362-7388
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Diverse experts from five universities in, or with a presence in, the Chicago area are collaborating as the Metropolitan Chicago Data-science Corps to 1) help local non-profit organizations take advantage of increasing data volume and data complexity, 2) train data science students in how to effectively apply their academic knowledge to real data challenges in the non-profit sector, 3) exchange data science curriculum and expertise among these universities and with local community colleges. An organization can submit a Request for Data Services (RDS) and receive help to develop it. MCDC particularly welcomes RDS in areas related to environment, health, and our social well-being. Each RDS is assigned to a team of students. Teams of students with a foundation in data science are formed within a practicum course or as part of a summer internship. MCDC will develop the practicum course, where each team has one or more expert mentors and forms a partnership with the requesting organization. At the end of the term, each team will deliver a solution to each of the requesting organizations.<br/><br/>MCDC is an interdisciplinary partnership between universities, myriad community organizations, and two expansion colleges and aims to strengthen the national data science workforce by integrating community needs with academic learning. By supporting infrastructure to unite diverse students and faculty across institutions and disciplines, by prioritizing the engagement of community, and embedding real-world team-based data science projects into the curriculum, the MCDC will be a uniquely powerful educational experience which will support societal progress. To realize this goal, existing curricula are grouped into multiple pathways to prepare a diverse range of students for participation in MCDC. MCDC students acquire both data acumen and societal knowledge that is intended to lead to a well-prepared and engaged workforce. The MCDC project directors combine extensive, proven, funded, and diverse expertise in curriculum development, inclusive learning practices, integrating real-world data into courses, learning systems, data science, as well as in health, social, and environmental sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934464
Title: Collaborative Research: Framework for Integrative Data Equity Systems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $550,000
ARRA Amount: $
Investigator(s): Julia Stoyanovich stoyanovich@nyu.edu (Principal Investigator) 
Organization: New York University
70 WASHINGTON SQ S, NEW YORK, NY 10012-1019, (212)998-2121
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231 9102
Program Element Code(s): 099y, 7231
Abstract: Data Science continues to have a transformative impact on Science and Engineering, and on society at large, by enabling evidence-based decision making, reducing costs and errors, and improving objectivity. The techniques and technologies of data science also have enormous potential for harm if they reinforce inequity or leak private information.  As a result, sensitive datasets in the public and private sector are restricted from research use, slowing progress in those areas that have the most to gain: human services in the public sector.  Furthermore, the misuse of data science techniques and technologies will disproportionately harm underrepresented groups across race, gender, physical ability, sexual orientation, education, and more. These data equity issues are pervasive, and represent an existential risk for the use of data-driven methods in science and engineering. This project will establish a  Framework for Integrative Data Equity Systems (FIDES): an Institute for the study of systems that enable research on sensitive data while preventing misuse and misinterpretation. <br/><br/><br/>FIDES will enable interdisciplinary community convergence around data equity systems, with an initial study in critical domains such as mobility, housing, education, economic indicators, and government transparency, leading to the development of a novel data analytics infrastructure that supports responsibility in integrative data science.  Towards this goal, the project will address several technically challenging problems: (1) To be able to use data from multiple sources, risks related to privacy, bias, and the potential for misuse must be addressed. This project will develop principled methods for dataset processing to overcome these concerns.  (2) Individual datasets are difficult to integrate for use in advanced multi-layer network models.  This project considers methods to create pre-trained tensors over large collections of spatially and temporally coherent datasets, making them easier to incorporate while controlling for fairness and equity.  (3) Any dataset or model must be equipped with sufficient information to determine fitness for use, communicate limitations, and describe underlying assumptions.  This project will develop tools and techniques to produce "nutritional labels" for data and models, formalizing and standardizing ad hoc metadata approaches to provenance, specialized for equity issues. In addition to supporting methodological innovation in data science, the Institute will become a focal point for sharing expertise in data equity systems.  It will do so by establishing interfaces for interaction between data science and domain experts to promote expertise development and sharing of best practices, and by consistently supporting efforts on diversity and equity.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity.  The effort is jointly funded by the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940099
Title: Collaborative Research: Integrating Physics and Generative Machine Learning Models for Inverse Materials Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: August 11, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $408,736
ARRA Amount: $
Investigator(s): Jianjun Hu jianjunh@cse.sc.edu (Principal Investigator) 
Organization: University of South Carolina at Columbia
1600 HAMPTON ST # 414, COLUMBIA, SC 29208-3403, (803)777-7093
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 054Z 062Z 8396 8399 9150
Program Element Code(s): 099Y
Abstract: This project is aimed to address a grand challenge in data-intensive materials science and engineering to find better materials with desired properties, often with the goal to enhance performance in specific applications. This project addresses this grand challenge with a specific focus on finding metal organic framework (MOF) materials that are used to separate gas mixtures and finding better battery materials for energy storage. The PIs will combine theoretical methods from statistical mechanics and condensed-matter physics, and physics-based models, to generate information-rich materials data which is integrated with generative machine learning (ML) algorithms to search a complex chemical design space efficiently and to train deep learning models for fast screening of materials properties. This project will be carried out by a multidisciplinary collaboration involving researchers from physics, materials science and engineering, computer science, and mathematics. The resulting multidisciplinary environment fosters training the next generation data savvy scientists who will engage in collaborative multidisciplinary research.  <br/><br/>Existing approaches for computational design of metal organic frameworks (MOF) and solid-state electrolyte materials are largely based on screening of known materials or enumerative search of hypothetical materials. This project develops a new approach that integrates first principles calculations, experimental data and abundant data generated by physics-based models to train generalized antagonistic network (GAN) models for efficient search of the materials design space, and to train deep convolutional neural network (DCNN) models for fast and accurate screening of properties of the GAN-generated candidate materials. Additionally, graph-based GAN models will be used for MOF topology exploration and can be applied to other nanomaterials designs. More specifically, the investigators will: 1) develop and exploit physics-based models for fast calculation of properties such as diffusivity, ion conductivity, and mechanical stability; 2) develop generative adversarial network (GAN) models with built-in physics rules for efficient exploration of the chemical design space for both MOF materials and solid electrolytes; 3) use persistence homology and Bravais lattice sequence representations of MOF materials and solid electrolytes, respectively, to build Deep Convolutional Neural Network (DCNN) models for fast and accurate prediction of the physical properties of generated materials; 4)  apply high-level quantum-mechanical calculations for verification of discovered materials. Accomplishments from this project will lead to accelerated discovery of novel nanostructured materials for gas separation and energy storage, materials for lithium-ion batteries, novel data-driven scheme for materials design, and theoretical methods enabling implementation of advanced data science techniques. The highly interdisciplinary collaboration will offer students unique opportunities to interact with a variety of disciplines, and training the next-generation scientists with the mindset for multidiscipline collaborations. Educational and outreach activities will be developed and undertaken in conjunction with the proposed research activities.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741191
Title: BIGDATA: F: Statistical Foundation of Predictivity: A Novel Architecture for Big Data Learning
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 29, 2017
Latest Amendment Date: December 13, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2018
End Date: December 31, 2022
Awarded Amount to Date: $900,000
ARRA Amount: $
Investigator(s): Shaw-Hwa Lo slo@stat.columbia.edu (Principal Investigator) Tian Zheng (Co-Principal Investigator) Xuan Di (Co-Principal Investigator) 
Organization: Columbia University
202 LOW LIBRARY 535 W 116 ST MC, NEW YORK, NY 10027-, (212)854-6851
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Identifying variables that are good for prediction, especially in the context of BIG DATA, is an important challenge. The scientific literature currently lacks research that directly considers a variable set's potential ability to predict, referred to as "predictivity", as a parameter to be estimated. This project sets out to lay down statistical foundations for measures of predictivity, and proposes a novel framework for maximizing predictivity in big data learning. The research includes an application to big data in urban planning, addressing prediction problems in New York City's Vision Zero project. In collaboration with the NYC Department of Transportation, the PI and his team will identify risk factors and their combinations that are associated with traffic accidents and their outcomes, and improve accident prevention and victim outcome prediction. <br/><br/>A novel sample-based measure of predictivity, the I-score, that is effective in differentiating between noisy and predictive variables in big data is proposed.   This measure can be related to a lower bound for the correct prediction rate. Guided by this I-score, variable sets of high potential predictivity can be identified. This high predictivity often resides within complex interactions among the variables. To fully leverage the predictivity in an identified variable set, powerful classifiers based on deep architectures will be constructed. Novel strategies are proposed for scalable computational implementation of the proposed framework. Systematic evaluation of the proposed methods, comparing with current strategies, will be carried out using simulations and benchmark real data sets.

Award Number: 1940243
Title: Collaborative Research: Integrating Physics and Generative Machine Learning Models for Inverse Materials Design
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: August 12, 2020
Award Instrument: Continuing Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $338,320
ARRA Amount: $
Investigator(s): Michael Lawler mlawler@binghamton.edu (Principal Investigator) 
Organization: SUNY at Binghamton
4400 VESTAL PKWY E, BINGHAMTON, NY 13902-4400, (607)777-6136
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8396 8399
Program Element Code(s): 099Y, 1712
Abstract: This project is aimed to address a grand challenge in data-intensive materials science and engineering to find better materials with desired properties, often with the goal to enhance performance in specific applications. This project addresses this grand challenge with a specific focus on finding metal organic framework (MOF) materials that are used to separate gas mixtures and finding better battery materials for energy storage. The PIs will combine theoretical methods from statistical mechanics and condensed-matter physics, and physics-based models, to generate information-rich materials data which is integrated with generative machine learning (ML) algorithms to search a complex chemical design space efficiently and to train deep learning models for fast screening of materials properties. This project will be carried out by a multidisciplinary collaboration involving researchers from physics, materials science and engineering, computer science, and mathematics. The resulting multidisciplinary environment fosters training the next generation data savvy scientists who will engage in collaborative multidisciplinary research.  <br/><br/>Existing approaches for computational design of metal organic frameworks (MOF) and solid-state electrolyte materials are largely based on screening of known materials or enumerative search of hypothetical materials. This project develops a new approach that integrates first principles calculations, experimental data and abundant data generated by physics-based models to train generalized antagonistic network (GAN) models for efficient search of the materials design space, and to train deep convolutional neural network (DCNN) models for fast and accurate screening of properties of the GAN-generated candidate materials. Additionally, graph-based GAN models will be used for MOF topology exploration and can be applied to other nanomaterials designs. More specifically, the investigators will: 1) develop and exploit physics-based models for fast calculation of properties such as diffusivity, ion conductivity, and mechanical stability; 2) develop generative adversarial network (GAN) models with built-in physics rules for efficient exploration of the chemical design space for both MOF materials and solid electrolytes; 3) use persistence homology and Bravais lattice sequence representations of MOF materials and solid electrolytes, respectively, to build Deep Convolutional Neural Network (DCNN) models for fast and accurate prediction of the physical properties of generated materials; 4)  apply high-level quantum-mechanical calculations for verification of discovered materials. Accomplishments from this project will lead to accelerated discovery of novel nanostructured materials for gas separation and energy storage, materials for lithium-ion batteries, novel data-driven scheme for materials design, and theoretical methods enabling implementation of advanced data science techniques. The highly interdisciplinary collaboration will offer students unique opportunities to interact with a variety of disciplines, and training the next-generation scientists with the mindset for multidiscipline collaborations. Educational and outreach activities will be developed and undertaken in conjunction with the proposed research activities.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940145
Title: Collaborative Research: Machine Learning methods for multi-disciplinary multi-scales problems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $872,008
ARRA Amount: $
Investigator(s): Olivier Pauluis pauluis@cims.nyu.edu (Principal Investigator) Debra Laefer (Co-Principal Investigator) 
Organization: New York University
70 WASHINGTON SQ S, NEW YORK, NY 10012-1019, (212)998-2121
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Big Data Science &Engineering 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 8083
Abstract: This project addresses two of the most pressing challenges in modern scientific research: (a) modeling natural phenomena across a broad range of space and time scales, and (b) the application of data science to discover physically meaningful relationships from large datasets. It will leverage knowledge from related and disparate disciplines, connecting them through data science. Four specific problems will be studied: cloud formation and evolution, movement of particles through random media, frustrated magnetic systems, and the reconstruction of urban topography. These benchmark problems have been selected as they capture different disciplinary aspects of multi-scale challenges. State-of-the-art methods in machine learning (including Artificial Neural Networks) will be used to develop new mathematical representation for small-scale processes. If successful, this project will substantially increase the capability of scientific computing to address a wide variety of important problems from the natural and social sciences, and will be disseminated widely through a pair of workshops, multiple campus visits across the 5-institution consortium, high impact peer-reviewed publications and presentations and the training of a cadre of more than a dozen post-docs and students.<br/><br/>This project will develop, implement and evaluate a new constrained optimization framework to discover and test physical phenomena at different resolutions and scales, including new machine learning algorithms aimed at discovering the stochastic differential equations underlying noisy data. This will be used to train physical parameterizations that account for the effects of small-scale processes in coarse resolution models. Core to this will be the design of a new framework to constrain artificial neural networks to deliver solutions that are interpretable and meaningful in the domain sciences and that can be directly associated with differential operators.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1841758
Title: BIGDATA: IA: Collaborative Research: In Situ Data Analytics for Next Generation Molecular Dynamics Workflows
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: July 21, 2018
Latest Amendment Date: August 26, 2021
Award Instrument: Standard Grant
Program Manager: Almadena Chtchelkanova
Start Date: June 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $1,079,986
ARRA Amount: $
Investigator(s): Michela Taufer taufer@utk.edu (Principal Investigator) 
Organization: University of Tennessee Knoxville
1331 CIR PARK DR, Knoxville, TN 37916-3801, (865)974-3466
NSF Directorate: CSE
Program(s): Software & Hardware Foundation Big Data Science &Engineering 
Program Reference Code(s): 7433 7924 7942 8083 9102 9150
Program Element Code(s): 7798, 8083
Abstract: Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers.  Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now.  This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br/><br/>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).

Award Number: 1740990
Title: BIGDATA:  IA:  Collaborative Research: In Situ Data Analytics for Next Generation Molecular Dynamics Workflows
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2017
Latest Amendment Date: August 27, 2021
Award Instrument: Standard Grant
Program Manager: Almadena Chtchelkanova
Start Date: October 01, 2017
End Date: September 30, 2023
Awarded Amount to Date: $547,056
ARRA Amount: $
Investigator(s): Harel Weinstein haw2002@med.cornell.edu (Principal Investigator) Harel Weinstein (Former Principal Investigator) Michel Cuendet (Former Principal Investigator) Michel Cuendet (Co-Principal Investigator) Harel Weinstein (Former Co-Principal Investigator) 
Organization: Joan and Sanford I. Weill Medical College of Cornell University
1300 YORK AVE, NEW YORK, NY 10065-4805, (646)962-8290
NSF Directorate: CSE
Program(s): Software & Hardware Foundation Big Data Science &Engineering 
Program Reference Code(s): 7433 7924 7942 8083
Program Element Code(s): 7798, 8083
Abstract: Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers.  Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now.  This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br/><br/>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).

Award Number: 1741129
Title: BIGDATA: F: Collaborative Research: Design and Computation of Scalable Graph Distances in Metric Spaces: A Unified Multiscale Interpretable Perspective
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 05, 2017
Latest Amendment Date: September 05, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2023
Awarded Amount to Date: $599,249
ARRA Amount: $
Investigator(s): Jose Bento bentoayr@bc.edu (Principal Investigator) 
Organization: Boston College
140 COMMONWEALTH AVE, CHESTNUT HILL, MA 02467-3800, (617)552-8000
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Representations of real-world phenomena as graphs (a.k.a. networks) are ubiquitous, ranging from social and information networks, to technological, biological, chemical, and brain networks. Many graph mining tasks -- including clustering, anomaly detection, nearest neighbor, similarity search, pattern recognition, and transfer learning -- require a distance measure between graphs to be computed efficiently. The existing distance measures between graphs leave a lot to be desired. They are overwhelmingly based on heuristics.  Many do not scale to graphs with millions of nodes; others do not satisfy the metric properties of non-negativity, positive definiteness, symmetry, and triangle inequality. This project studies a formal mathematical foundation covering a family of graph distances that overcome these limitations, focusing on real-world applications in biology and social network analysis. It also provides a universal methodology for parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes, and scaling it over cloud computing resources.<br/><br/>This project studies, designs, and evaluates graph distances that satisfy the following six properties: (1) They are scalable -- i.e., they are strictly subquadratic in runtime and achieve a speedup when computed in parallel. (2) They are metrics -- i.e., they satisfy<br/>non-negativity, positive definiteness, symmetry, and triangle inequality. (3) They are discriminative, as measured by comparisons to the "chemical distance", which finds the optimal mapping between two graphs that minimizes edge discrepancies. (4) They are statistically<br/>robust -- i.e., they have confidence intervals. (5) They can incorporate auxiliary information available on nodes and links. (6) They are interpretable to subject matter experts. Rather than providing a single metric, this project explores a family of such graph distance metrics. It also provides a universal methodology, using the Alternating Directions Method of Multipliers (ADMM), to parallelizing the computation of graph distance metrics within this family over massive graphs with millions of nodes. The proposed metrics are evaluated over massive real-world graphs using Apache Spark on a cloud computing infrastructure.

Award Number: 2219975
Title: Collaborative Research: Framework: Data: NSCI: HDR: GeoSCIFramework: Scalable Real-Time Streaming Analytics and Machine Learning for Geoscience and Hazards Research
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: March 15, 2022
Latest Amendment Date: March 15, 2022
Award Instrument: Standard Grant
Program Manager: Alejandro Suarez
Start Date: October 01, 2021
End Date: March 31, 2023
Awarded Amount to Date: $803,971
ARRA Amount: $
Investigator(s): Ivan Rodero irodero@cac.rutgers.edu (Principal Investigator) 
Organization: University of Utah
201 PRESIDENTS CIR, SALT LAKE CITY, UT 84112-9049, (801)581-6903
NSF Directorate: CSE
Program(s): Data Cyberinfrastructure EarthCube Big Data Science &Engineering 
Program Reference Code(s): 062Z 077Z 7925 8083
Program Element Code(s): 7726, 8074, 8083
Abstract: This project develops a real-time processing system capable of handling a large mix of sensor observations. The focus of this system is automation of the detection of natural hazard events using machine learning, as the events are occurring.  A four-organization collaboration (UNAVCO, University of Colorado, University of Oregon, and Rutgers University) develops a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  This work will support rapid analysis and understanding of data associated with hazardous events (earthquakes, volcanic eruptions, tsunamis).  <br/><br/>This project uses a collaboration between computer scientists and geoscientists to develop a data framework for generalized real-time streaming analytics and machine learning for geoscience and hazards research.  It focuses on the aggregation and integration of a large number of data streams into a coherent system that supports analysis of the data streams in real-time. The framework will offer machine-learning-based tools designed to detect signals of events, such as earthquakes and tsunamis, that might only be detectable when looking at a broad selection of observational inputs.  The architecture sets up a fast data pipeline by combining a group of open source components that make big data applications viable and easier to develop. Data sources for the project draw primarily upon the 1500+ sensors from the EarthScope networks currently managed by UNAVCO and the Incorporated Research Institutions for Seismology (IRIS), as well as the Ocean Observatories Initiative (OOI) cabled array data managed by Rutgers University.  Machine learning (ML) algorithms will be researched and applied to the tsunami and earthquake use cases.  Initially, the project plans to employ an advanced convolutional neural network method in a multi-data environment.  The method has only been applied to seismic waveforms, so the project will explore extending the method to a multi-data environment.  The approach is expected to be extensible beyond detection and characterization of earthquakes to include the onset of other geophysical signals such as slow-slip events or magmatic intrusion, expanding the potential for new scientific discoveries.  The framework is applied to use cases in the Cascadia subduction zone and Yellowstone: these locations combine the expertise of the science team with locations where EarthScope and OOI have the greatest concentration of instruments.  The architecture will be transportable and scalable, running in a Docker environment on laptops, local clusters and the cloud.  Integral to the project will be development, documentation and training using collaborative online resources such as GitLab and Jupyter Notebooks, and utilizing NSF XSEDE resources to make larger datasets and computational resources more widely available.<br/><br/>This award by the NSF Office of Advanced Cyberinfrastructure is jointly supported by the Cross-Cutting Program and Division of Earth Sciences within the NSF Directorate for Geosciences, the Big Data Science and Engineering Program within the Directorate for Computer and Information Science and Engineering, and the EarthCube Program jointly sponsored by the NSF Directorate for Geosciences and the Office of Advanced Cyberinfrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123503
Title: Collaborative Research: HDR DSC: The Metropolitan Chicago Data Science Corps (MCDC): Learning from Data to Support Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 20, 2021
Latest Amendment Date: August 20, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $185,000
ARRA Amount: $
Investigator(s): Eunice Santos eesantos@illinois.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: Diverse experts from five universities in, or with a presence in, the Chicago area are collaborating as the Metropolitan Chicago Data-science Corps to 1) help local non-profit organizations take advantage of increasing data volume and data complexity, 2) train data science students in how to effectively apply their academic knowledge to real data challenges in the non-profit sector, 3) exchange data science curriculum and expertise among these universities and with local community colleges. An organization can submit a Request for Data Services (RDS) and receive help to develop it. MCDC particularly welcomes RDS in areas related to environment, health, and our social well-being. Each RDS is assigned to a team of students. Teams of students with a foundation in data science are formed within a practicum course or as part of a summer internship. MCDC will develop the practicum course, where each team has one or more expert mentors and forms a partnership with the requesting organization. At the end of the term, each team will deliver a solution to each of the requesting organizations.<br/><br/>MCDC is an interdisciplinary partnership between universities, myriad community organizations, and two expansion colleges and aims to strengthen the national data science workforce by integrating community needs with academic learning. By supporting infrastructure to unite diverse students and faculty across institutions and disciplines, by prioritizing the engagement of community, and embedding real-world team-based data science projects into the curriculum, the MCDC will be a uniquely powerful educational experience which will support societal progress. To realize this goal, existing curricula are grouped into multiple pathways to prepare a diverse range of students for participation in MCDC. MCDC students acquire both data acumen and societal knowledge that is intended to lead to a well-prepared and engaged workforce. The MCDC project directors combine extensive, proven, funded, and diverse expertise in curriculum development, inclusive learning practices, integrating real-world data into courses, learning systems, data science, as well as in health, social, and environmental sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940287
Title: Collaborative Research: Machine Learning methods for multi-disciplinary multi-scales problems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: August 12, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $331,136
ARRA Amount: $
Investigator(s): Dallas Trinkle dtrinkle@illinois.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y
Abstract: This project addresses two of the most pressing challenges in modern scientific research: (a) modeling natural phenomena across a broad range of space and time scales, and (b) the application of data science to discover physically meaningful relationships from large datasets. It will leverage knowledge from related and disparate disciplines, connecting them through data science. Four specific problems will be studied: cloud formation and evolution, movement of particles through random media, frustrated magnetic systems, and the reconstruction of urban topography. These benchmark problems have been selected as they capture different disciplinary aspects of multi-scale challenges. State-of-the-art methods in machine learning (including Artificial Neural Networks) will be used to develop new mathematical representation for small-scale processes. If successful, this project will substantially increase the capability of scientific computing to address a wide variety of important problems from the natural and social sciences, and will be disseminated widely through a pair of workshops, multiple campus visits across the 5-institution consortium, high impact peer-reviewed publications and presentations and the training of a cadre of more than a dozen post-docs and students.<br/><br/>This project will develop, implement and evaluate a new constrained optimization framework to discover and test physical phenomena at different resolutions and scales, including new machine learning algorithms aimed at discovering the stochastic differential equations underlying noisy data. This will be used to train physical parameterizations that account for the effects of small-scale processes in coarse resolution models. Core to this will be the design of a new framework to constrain artificial neural networks to deliver solutions that are interpretable and meaningful in the domain sciences and that can be directly associated with differential operators.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741022
Title: BIGDATA: F: Collaborative Research: Foundations of Responsible Data Management
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 21, 2017
Latest Amendment Date: August 21, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2017
End Date: August 31, 2022
Awarded Amount to Date: $385,000
ARRA Amount: $
Investigator(s): H Jagadish jag@umich.edu (Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Big Data technology promises to improve people's lives, accelerate scientific discovery and innovation, and bring about positive societal change. Yet, if not used responsibly, this same technology can reinforce inequity, limit accountability and infringe on the privacy of individuals: irreproducible results can influence global economic policy; algorithmic changes in search engines can sway elections and incite violence; models based on biased data can legitimize and amplify discrimination in the criminal justice system; algorithmic hiring practices can silently reinforce diversity issues and potentially violate the law; privacy and security violations can erode the trust of users and expose companies to legal and financial consequences. The focus of this project is on using Big Data technology responsibly -- in accordance with ethical and moral norms, and legal and policy considerations. This project establishes a foundational new role for data management technology, in which managing the responsible use of data across the lifecycle becomes a core system requirement. The broader goal of this project is to help usher in a new phase of data science, in which the technology considers not only the accuracy of the model but also ensures that the data on which it depends respect the relevant laws, societal norms, and impacts on humans. <br/><br/>This project defines properties of responsible data management, which include fairness (and the related concepts of representativeness and diversity), transparency (and accountability), and data protection. It complements what is done in the data mining and machine learning communities, where the focus is on analyzing fairness, accountability and transparency of the final step in the data analysis lifecycle, and considers the problems that can be introduced upstream from data analysis: during dataset selection, cleaning, pre-processing, integration, and sharing. This project develops conceptual frameworks and algorithmic techniques that support fairness, transparency and data protection properties through all stages of the data usage lifecycle: beginning with data discovery and acquisition, through cleaning, integration, querying, and ultimately analysis. The contributions are structured along three aims. Aim 1 considers responsible dataset discovery, profiling, and integration. Aim 2 considers responsible query processing and develops a general framework for declarative specification, checking and enforcement of fairness, representativeness and diversity. Aim 3 incorporates data protection into the lifecycle, develops techniques to facilitate sharing of sensitive data, and considers the tradeoffs between privacy and transparency. This project is poised to establish a multidisciplinary research agenda around responsible data management as a critical factor in enabling fairness, accountability and transparency in decision-making and prediction systems. Additional information about the project is available at DataResponsibly.com.

Award Number: 2123321
Title: HDR DSC: National Data Mine Network
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 01, 2021
Latest Amendment Date: September 01, 2021
Award Instrument: Continuing Grant
Program Manager: Christopher Stark
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $600,000
ARRA Amount: $
Investigator(s): Mark Ward mdw@purdue.edu (Principal Investigator) Katherine Ensor (Co-Principal Investigator) Monica Jackson (Co-Principal Investigator) Talitha Washington (Co-Principal Investigator) Donna LaLonde (Co-Principal Investigator) 
Organization: American Statistical Association
732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943, (703)684-1221
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu INFRASTRUCTURE PROGRAM 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1260
Abstract: The data science community has a timely opportunity to reimagine the impact of the data sciences on the economy, and to improve outcomes for communities, by ensuring that students at Minority Serving Institutions have access to cutting edge courses, research opportunities, and industry partnerships. In 2018, Purdue University established The Data Mine, a university-wide undergraduate learning community that teaches data science to participating undergraduates from all majors, regardless of their previous experience. It will scale naturally to a nationwide model because it is accessible, supportive, but also offers genuine data science challenges that motivate students to learn the required competencies. The National Data Mine Network (NDMN) will directly fund 300 undergraduate students at Minority Serving Institutions with research stipends (100 stipends per year), administered directly to students by the American Statistical Association. The leadership team leverages collaborative strengths of the American Statistical Association, the Math Alliance, Purdue University, American University, and the Atlanta University Center Data Science Initiative. The students will use high-performance computing to solve data-driven challenges that arise in every sector of industry, including biomedical engineering, healthcare engineering, image processing, manufacturing, supply chain management, and transportation.<br/><br/>This project will enable undergraduate students to learn data science with hands-on work, in research or data science projects informed by industry partners. Each participating institution will have a node led by faculty members and 3-4 undergraduate students. All faculty members will share their best practices about mentoring research, how to establish mutually beneficial relationships with industry partners in their community, and how to develop institutional mechanics to support the work and to build data science programs. Some of the key deliverables of this HDR DSC project will be: well-documented projects for courses and for student research, a robust online training resource of data science projects, an instructor handbook that accompanies the data science projects, a development curriculum for the faculty to grow their own skills, and promising best practices on how faculty can develop relationships with mentors from industry for real-world data-driven projects. A key benefit of the NDMN to faculty is the ability to inject data science skills into their careers, to gain knowledge and expertise about how to carry out hands-on, data-intensive research projects, as well as the potential to develop new industry partnerships, while also building their own data science courses and programs. Another key impact will be a tightly knit community supporting a new generation of 300 diverse undergraduate trainees in the data sciences. A third key impact will be a nationwide network of faculty who work together to build these data science courses, programs, and industry partnerships at Minority Serving Institutions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940260
Title: Collaborative Research: Machine Learning methods for multi-disciplinary multi-scales problems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $234,681
ARRA Amount: $
Investigator(s): Michael Lawler mlawler@binghamton.edu (Principal Investigator) 
Organization: SUNY at Binghamton
4400 VESTAL PKWY E, BINGHAMTON, NY 13902-4400, (607)777-6136
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y
Abstract: This project addresses two of the most pressing challenges in modern scientific research: (a) modeling natural phenomena across a broad range of space and time scales, and (b) the application of data science to discover physically meaningful relationships from large datasets. It will leverage knowledge from related and disparate disciplines, connecting them through data science. Four specific problems will be studied: cloud formation and evolution, movement of particles through random media, frustrated magnetic systems, and the reconstruction of urban topography. These benchmark problems have been selected as they capture different disciplinary aspects of multi-scale challenges. State-of-the-art methods in machine learning (including Artificial Neural Networks) will be used to develop new mathematical representation for small-scale processes. If successful, this project will substantially increase the capability of scientific computing to address a wide variety of important problems from the natural and social sciences, and will be disseminated widely through a pair of workshops, multiple campus visits across the 5-institution consortium, high impact peer-reviewed publications and presentations and the training of a cadre of more than a dozen post-docs and students.<br/><br/>This project will develop, implement and evaluate a new constrained optimization framework to discover and test physical phenomena at different resolutions and scales, including new machine learning algorithms aimed at discovering the stochastic differential equations underlying noisy data. This will be used to train physical parameterizations that account for the effects of small-scale processes in coarse resolution models. Core to this will be the design of a new framework to constrain artificial neural networks to deliver solutions that are interpretable and meaningful in the domain sciences and that can be directly associated with differential operators.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940178
Title: Collaborative Research: From Brains to Society: Neural Underpinnings of Collective Behaviors Via Massive Data and Experiments
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: August 06, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: January 31, 2023
Awarded Amount to Date: $213,091
ARRA Amount: $
Investigator(s): Mark Wilson wilson.mark.c@gmail.com (Principal Investigator) 
Organization: University of Massachusetts Amherst
COMMONWEALTH AVE, AMHERST, MA 01003-, (413)545-0698
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1640
Abstract: Despite thousands of investigations on the neural basis of individual behaviors and even more studies on collective behaviors, a clear bridge between the organization of individual brains and their combinational impact on group behaviors, such as cooperation and conflict and ultimately collective action, is lacking. To address the grand challenge of inferring group cooperation from the functional neuroarchitecture of individual brains, this project will harness advances in data, experiment and computation. Specifically, it will integrate, for the first time, existing large-scale human functional neuroimaging data, prospectively collected individual and group behavioral data from a large cohort, with cutting-edge machine learning tools, hierarchical models and large-scale simulations. This is a collaborative effort between a team of neuroscientists, social scientists and data scientists, that aims to elucidate the neural basis of cooperation, a fundamental process in a functioning society and at the core of social environments. <br/><br/>The project will first harness the combined wealth of existing neuroimaging and behavioral data from large-scale studies, including the Human Connectome-Lifespan (HCP-L) and the Adolescent Brain Cognitive Development (ABCD) and will leverage recent breakthroughs in machine learning to characterize the diversity, individuality and commonality of neural circuits (the connectome) supporting cognitive function across the lifespan. It will then conduct large-scale (~10,000 individuals) online behavioral experiments to identify connections between individual behaviors, decisions and group behaviors during a Public Goods Game. The experiments will measure individual proclivity towards cooperation and the social welfare obtained by cooperation, leading to potentially transformative insights into the emergence of cooperation within groups via individual behaviors. The resulting first-of-its-kind dataset may become a very valuable resource to the research community. Large-scale simulations based on statistical models estimated from this and the assembled neuroimaging datasets will then assess the direct or indirect relationships between individual connectomes and cooperation in group settings, and will elucidate the role of group processes in amplifying or ameliorating individual differences towards collective outcomes. Findings from this project may have a transformative impact on the scientific community's currently incomplete understanding of how individual brains shape societal behavior via cognitive, social, and interactive mechanisms.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939929
Title: Collaborative Research: Accelerating Synthetic Biology Discovery & Exploration through Knowledge Integration
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $211,699
ARRA Amount: $
Investigator(s): John Downie jdownie@uiuc.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: The scientific challenge for this project is to accelerate discovery and exploration of the synthetic biology design space.  In particular, many parts used in synthetic biology come from or are initially tested in a simple bacteria, E. coli, but many potential applications in energy, agriculture, materials, and health require either different bacteria or higher level organisms (yeast for example). Currently, researchers use a trial-and-error approach because they cannot find reliable information about prior experiments with a given part of interest. This process simply cannot scale. Therefore, to achieve scale, a wide range of data must be harnessed to allow confidence to be determined about the likelihood of success. The quantity of data and the exponential increase in the publications generated by this field is creating a tipping point, but this data is not readily accessible to practitioners. To address this challenge, our multidisciplinary team of biological engineers, machine learning experts, data scientists, library scientists, and social scientists will build a knowledge system integrating disparate data and publication repositories in order to deliver effective and efficient access to collectively available information; doing so will enable expedited, knowledge-based synthetic biology design research.<br/><br/>This project will develop an open and integrated synthetic biology knowledge system (SBKS) that leverages existing data repositories and publications to create a single interface that transforms the way researchers access this information. Access to up-to-date information in multiple, heterogeneous sources will be provided via a federated approach. New methods based on machine learning will be developed to automatically generate ontology annotations in order to create connections between data in various repositories and information extracted from publications.  Provenance for each entity in SBKS will be tracked, and it will be utilized by new methods that are developed to assess bias and assign confidence scores to knowledge returned for each entity. An intuitive, natural-language-based interface and visualization functionality will be implemented for users to easily access and explore SBKS contents.  Additionally, as ethics is necessarily a part of synthetic biology research, data from text sources related to ethical concerns in synthetic biology will also be incorporated to inform researchers about ethical debates relevant to their search queries.  Finally, to test the SBKS API, a new genetic design tool, Kimera, will be developed that leverages the knowledge in SBKS to produce better designs.  The proposed SBKS will accelerate discovery and innovation by enabling researchers to learn from others' past experiences and to maximize the productivity of valuable experimental time on testing designs that have a higher likelihood of working when transformed to a new organism.  This research thus provides the potential for transformative research outcomes in the field of synthetic biology by leveraging data science to improve the field's epistemic culture. For more information please see https://synbioks.github.io.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838215
Title: BIGDATA: IA: Collaborative Research: Understanding the Financial Market Ecosystem
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 12, 2018
Latest Amendment Date: September 12, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: October 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $407,585
ARRA Amount: $
Investigator(s): John Towns jtowns@ncsa.illinois.edu (Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: This is an interdisciplinary project involving computer science and economics. The big data problem to be addressed concerns how to analyze and understand financial trading, and its effects on the stock market. The project introduces new behavioral models of financial trading and applies big data techniques to implement them.  The project will foster research on the financial ecosystem of machine-machine and machine-human interactions by bringing financial economists and data scientists together in a series of workshops.<br/><br/>The PIs will work with the National Center for Supercomputing and develop a new and more accurate taxonomy of trading frequencies by categorizing high frequency traders (HFT), buy-side algorithmic traders (BAT) and human traders using two proprietary high frequency datasets. The workshops will foster research on the implications of the new financial ecosystem for the overall financial system and the economy in general, as well as creating new metrics and data for the discipline of finance in economics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1535167
Title: A Big Data-Theoretic Approach to Quantify Organizational Failure Mechanisms in Probabilistic Risk Assessment
NSF Org: SES Divn Of Social and Economic Sciences
Initial Amendment Date: August 25, 2015
Latest Amendment Date: September 11, 2019
Award Instrument: Continuing Grant
Program Manager: Tara Behrend
Start Date: September 01, 2015
End Date: August 31, 2022
Awarded Amount to Date: $899,996
ARRA Amount: $
Investigator(s): Zahra Mohaghegh zahra13@illinois.edu (Principal Investigator) Cheri Ostroff (Co-Principal Investigator) Catherine Blake (Co-Principal Investigator) 
Organization: University of Illinois at Urbana-Champaign
506 S WRIGHT ST, URBANA, IL 61801-3620, (217)333-2187
NSF Directorate: SBE
Program(s): Cross-Directorate  Activities SoO-Science Of Organizations Big Data Science &Engineering 
Program Reference Code(s): 9179
Program Element Code(s): 1397, 8031, 8083
Abstract: Nontechnical Description<br/>Catastrophic events such as Fukushima and Katrina have made it clear that integrating physical and social causes of failure into a cohesive modeling framework is critical in order to prevent complex technological accidents and to maintain public safety and health. In this research, experts in Probabilistic Risk Assessment (PRA), Organizational Behavior and Information Science and Data Analytics disciplines will collaborate to provide answers to the following key questions: (a) what social and organizational factors affect technical system risk? (b) how and why do these factors influence risk? and (c) how much do they contribute to risk?  Existing PRA models do not include a complete range of organizational factors. This research investigates organizational root causes of failure and models their paths of influence on technical system performance, resulting in more comprehensive incorporation of underlying organizational failure mechanisms into PRA. The field of PRA has progressed the quantification of equipment failure and human error for modeling risk of complex systems; however, the current organizational risk contributors lack reliable data analytics that go beyond safety climate and safety culture surveys. This research fills that gap by developing predictive causal modeling and big-data theoretic technologies for PRA, expanding the classic approach of data management for risk analysis by utilizing techniques such as text mining, data mining and data analytics. In addition to scientific contributions to organizational science, PRA, and data analytics, this research provides regulatory and industry decision-makers with important organizational factors that contribute to risk and leads to optimized decision making. Other applications include real-time monitoring of organizational safety indicators, efficient safety auditing, in-depth root cause analysis, and risk-informed emergency preparedness, planning and response. The multidisciplinary approach of this project can serve as an educational model, empowering students to pursue research across disciplinary boundaries.  Finally, the proposed research represents a successful model of industry-academia collaboration. A nuclear power plant has committed to this project and provides unique access to data and information necessary to complete the research. The proposed methodology is generic and applicable for any high-risk industry (e.g., aviation, healthcare, oil and gas), and will be used for the improvement of organizational safety performance in order to protect workers, the public and the environment. <br/><br/>Technical Description<br/>Organizations produce, process and store a large volume of wide-ranging, unstructured data as a result of business activities and compliance requirements (i.e., corrective action programs, root cause analysis reports, oversight and inspection data, etc.). This research leverages those data resources for the quantification of organizational failure mechanisms and their integration with the technical system risk scenarios generated by PRA. The research is based on a socio-technical risk theory to prevent misleading results from solely data-informed approaches. Combining socio-technical risk theory, systematic modeling and semantic data analytics strategies will greatly enhance risk analysis of complex systems. We will conduct our research based on following steps: (1) Expand factors, sub-factors, and causal relationships in the Socio-Technical Risk Analysis (SoTeRiA) framework, (2) Develop measurement techniques for factors, sub-factors and their causal relationships in SoTeRiA (e.g., integrating text mining with the Bayesian Belief Network; conducting scientific reduction to identify important factors; measuring of important factors), (3) Establish a dynamic, predictive socio-technical causal modeling technique, (4) Perform uncertainty analysis, (5) Conduct verification and validation, (6) Integrate the quantitative socio-technical causal model with PRA, and (7) Conduct sensitivity and importance measure analyses. As the pioneer study on the integration of big data with PRA, this research addresses and quantifies risk emerging from the interface of social and technical systems.

Award Number: 1940236
Title: Collaborative Research: Precision Learning: Data-Driven Experimentation of Learning Theories using Internet-of-Videos
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: March 18, 2020
Award Instrument: Standard Grant
Program Manager: Finbarr Sloane
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $708,316
ARRA Amount: $
Investigator(s): Neil Heffernan nth@wpi.edu (Principal Investigator) 
Organization: Worcester Polytechnic Institute
100 INSTITUTE RD, WORCESTER, MA 01609-2247, (508)831-5000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu IUSE Discovery Research K-12 
Program Reference Code(s): 062Z 7645 9178
Program Element Code(s): 099Y, 1998, 7645
Abstract: This is a project to study what works to help students learn more effectively in the context of the ASSISTments system. ASSISTments is an online system that provides both assistance to students and real time assessment data to teachers. ASSISTments now supports 100,000 students who have completed more than 12 million mathematics problems. The system uses teacher input and artificial intelligence to provide assistance to students who are attempting to solve mathematics problems. This project will increase the assistance provided by the teacher and machine learning by incorporating video suggestions, such as those produced by the Kahn academy, targeted to the needs of the student. The experimentation will take content from three Open Educational Resource textbooks that are openly licensed and free to schools.<br/><br/>More specifically, the researchers will identify a large collection of videos that address mathematics skills in the textbooks and will extract features of these videos including language complexity, speaking rate, and other features. These videos and features will be checked by both teachers and through a Mechanical Turk process for usability before they are presented to students. Additionally, the project will develop a suite of novel technologies for precision learning including fine grained video feature extraction, student feature learning from heterogeneous raw data, causal modeling, and fairness aware and causal relationship enhanced optimized personalized recommendation. The research will advance theoretical understanding of fundamental issues related to personalized learning and will enable data-driven experimentation of learning theories. Causal modeling will enable the researchers to learn the features of video that are correlated with learning effectiveness. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution Big Idea activity and is co-funded by the Division of Undergraduate Education and the Division of Research on Learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940059
Title: Collaborative Research: Converging Genomics, Phenomics, and Environments Using Interpretable Machine Learning Models
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $400,000
ARRA Amount: $
Investigator(s): Arun Ross rossarun@cse.msu.edu (Principal Investigator) 
Organization: Michigan State University
426 AUDITORIUM RD RM 2, EAST LANSING, MI 48824-2600, (517)355-5040
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 1165
Program Element Code(s): 099Y
Abstract: Mitigating the effects of climate change on public health and conservation calls for a better understanding of the dynamic interplay between biological processes and environmental effects. The state-of-the-art, which has led to many important discoveries, utilizes numerical or statistical models for making predictions or performing in silico experimentation, but these techniques struggle to capture the nonlinear response of natural systems. Machine learning (ML) methods are better able to cope with nonlinearity and have been used successfully in biological applications, but several barriers still exist, including the opaque nature of the algorithm output and the absence of ML-ready data. This project seeks to significantly advance technologies in ML and create a new interdisciplinary field, computational ecogenomics. This will be accomplished by designing ML techniques for encoding heterogeneous genomic and environmental data and mapping them to multi-level phenotypic traits, reducing the amount of necessary training data, and then developing interactive visualizations to better interpret ML models and their outputs.  These advances will responsibly and transparently inform policy to maximize resources during this crucial window for planetary health, while revealing underlying biological mechanisms of response to stress and evolutionary pressure.<br/><br/>The long-term vision for this project is to develop predictive analytics for organismal response to environmental perturbations using innovative data science approaches and change the way scientists think about gene expression and the environment. The goal for this two-year award is to develop a proof-of-concept for an institute focused on predicting emergent properties of complex systems; an institute that would itself foster the development of many new sub-disciplines.  The core of this activity is developing a machine learning framework capable of predicting phenotypes based on multi-scale data about genes and environments.  Available data, ranging from simple vectors to complex images to sequences, will be ingested into this framework by applying proven semantic data integration tools and algorithmic data transformation methods.  The central hypothesis of this research is that deep learning algorithms and biological knowledge graphs will predict phenotypes more accurately across more taxa and more ecosystems than do current numerical and traditional statistical modeling methods.  The rationale for this project is that a timely investment in data science will push through a bottleneck in life science, accelerating discovery of gene-phenotype-environment relationships, and catalyzing a new computational discipline to uncover the complex "rules of life."<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940190
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $254,964
ARRA Amount: $
Investigator(s): Chaopeng Shen cxs1024@psu.edu (Principal Investigator) 
Organization: Pennsylvania State Univ University Park
201 Old Main, University Park, PA 16802-1503, (814)865-1372
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940074
Title: Collaborative Research: Science-Aware Computational Methods for Accelerating Data-Intensive Discovery: Astroparticle Physics as a Test Case
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Vyacheslav (Slava) Lukin
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $320,701
ARRA Amount: $
Investigator(s): Waheed Bajwa waheed.bajwa@rutgers.edu (Principal Investigator) 
Organization: Rutgers University New Brunswick
3 RUTGERS PLZA, NEW BRUNSWICK, NJ 08901-8559, (848)932-0150
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The rapid technological advances of the last two decades have ushered in an era of data-rich science for several disciplines.  One such discipline is astroparticle physics, where researchers aim to discover what our Universe is made of by trying to directly detect Dark Matter. This discovery can be hastened if data science tools are used to extract significant domain-specific information from data, and to reliably test scientific hypotheses at scale. The overarching goal of this two-year project is to lay the groundwork for incorporating scientific knowledge into machine learning and data science methods in the context of scientific disciplines in which discovery requires effective, efficient analysis of lots of noisy data gathered by multiple imperfect sensors. In doing so, it not only advances the state-of-the-art in data science, machine learning, and astrophysics, but it also has the potential to accelerate data-driven discoveries in other scientific disciplines where data shares similar characteristics.<br/><br/>This project will develop innovative domain-enhanced data science methods that will be based on probabilistic graphical models and graph-regularized inverse problems. Using the leading astroparticle experiment XENON as a test bed, the investigators will explore and demonstrate approaches for incorporating domain knowledge into machine learning and data science methods. In doing so, the investigators will address major data-analysis challenges in the context of dark matter identification. Additionally, the investigators will invest significant effort reaching out to other data-intensive science communities, such as materials science, oceanography, and meteorology, that can benefit from the new methods and ideas. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940291
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $303,027
ARRA Amount: $
Investigator(s): Rajesh Gupta gupta@cs.ucsd.edu (Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940176
Title: Collaborative Research: Predictive Risk Investigation SysteM (PRISM) for Multi-layer Dynamic Interconnection Analysis
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Amy Walton
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $201,722
ARRA Amount: $
Investigator(s): Deborah Sunter deborah.sunter@tufts.edu (Principal Investigator) 
Organization: Tufts University
169 HOLLAND ST FL 3, SOMERVILLE, MA 02144-2401, (617)627-3696
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: The natural-human world is characterized by highly interconnected systems, in which a single discipline is not equipped to identify broader signs of systemic risk and mitigation targets. For example, what risks in agriculture, ecology, energy, finance and hydrology are heightened by climate variability and change? How might risks in, for example, space weather, be connected with energy, water and finance? Recent advances in computing and data science, and the data revolution in each of these domains have now provided a means to address these questions. The investigators jointly establish the PRISM Cooperative Institute for pioneering the integration of large-scale, multi-resolution, dynamic data across different domains to improve the prediction of risks (potentials for extreme outcomes and system failures). The investigators' vision is to develop a trans-domain framework that harnesses big data in the context of domain expertise to discover new critical risk indicators, holistically identify their interconnections, predict future risks and spillover potential, and to measure systemic risk broadly. The investigators will work with stakeholders to ultimately create early warnings and targets for critical risk mitigation and grow preparedness for devastating events worldwide; form wide and unique partnerships to educate the next generation of data scientists through postdoctoral researcher and student exchanges, research retreats, and workshops; and broaden participation through recruiting and training of those under-represented in STEM, including women and underrepresented minority students, and impact on stakeholder communities via methods, tools and datasets enabled by PRISM Data Library web services.<br/><br/>The PRISM Cooperative Institute's data-intensive cross-disciplinary research directions include: (i) Critical Risk Indicators (CRIs); The investigators define CRIs as quantifiable information specifically associated with cumulative or acute risk exposure to devastating, ruinous losses resulting from a disastrous (cumulative) activity or a catastrophic event.  PRISM aims to identify critical risks and existing indicators in many domains, and develop new CRIs by harnessing the data revolution; (ii) Dynamic Risk Interconnections; The investigators will dynamically model and forecast CRIs and PRISM aims to robustly identify a sparse, interpretable lead-lag risk dependence structure of critical societal risks, using state-of-the-art methods to accommodate CRI complexities such as nonstationary, spatiotemporal, and multi-resolution attributes; (iii) Systemic Risk Indicators (SRIs); PRISM will model trans-domain systemic risk, by forecasting critical risk spillovers and via the creation of SRIs for facilitating stakeholder intervention analysis; (iv) Validation & Stakeholder Engagement; The investigators will deploy the PRISM analytical framework on integrative case studies with distinct risk exposure (acute versus cumulative) and catastrophe characteristics (immediate versus sustained), and will solicit regular input from key stakeholders regarding critical risks and their decision variables, to better inform their operational understanding of policy versus practice.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837991
Title: BIGDATA: F: Compositional Learning, Maps and Transfer: Statistical and Machine Learning on Collections of Data Sets
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $700,000
ARRA Amount: $
Investigator(s): Mauro Maggioni mauro.maggioni@jhu.edu (Principal Investigator) 
Organization: Johns Hopkins University
3400 N CHARLES ST, BALTIMORE, MD 21218-2608, (443)997-1898
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: One of the landmarks of human intelligence is the ability to not only find solutions to hard problems, but to learn from past experiences and accumulate knowledge that may be (partially) transferred for quickly solving new problems. This project will develop novel foundational techniques for learning compositional rules, from collections of data sets and machine learning problems. The building blocks that the investigator will develop enable sharing of learning across multiple data sets and modalities. A first building block will enable machine learning algorithms to store solutions to past problems and use maps and abstractions to transfer knowledge to new problems. This requires efficient techniques for learning maps, how to compose them to enable knowledge transfer, all in a way that is compatible with the representation of the problems and their solutions, which also need to be automatically learned. These ideas will be tested on problems ranging from object and pattern recognition of images to behavior of interacting agent systems, from fusing data sets acquired with different sensors to controlling virtual and real agents.  This project will provide general, foundational results in machine learning, which can be applied to applications in virtually any domain of human endeavor. <br/><br/>The investigator will develop new techniques focused on representation and transfer learning, in particular: (i) Compositional Learning: the ability to learn and factorize through composition maps between data sets, and of functions (for classification and regression tasks) on data sets (e.g. the task f may be learned by using the map h to one data set on which learning already occurred and the already-learned function g on that data), in order to enhance both learning rates, knowledge extraction and transfer across data sets and data types; (ii) Map Learning: the ability to efficiently learn, represent, store, recall and apply maps between complex data sets, possibly of different modalities; but also learn maps that transform, at least approximately, one task into another, and transfer knowledge from one task to another; (iii) Representation Learning: the ability to learn how to efficiently represent, store and recall complex data sets, across multiple sensor modalities, and across different levels of abstractions -- for example, learning efficient representations of data from multiple types of sensors, learning of classifiers and regression functions, or learning interaction kernels in agent-based systems, as well as transfer those functions across sensor modalities, data sets, dynamical systems.  While advancing current state of art techniques in each of these learning abilities, the research will tackle applications in learning invariances and performing object recognition tasks in images, detecting whether objects in an image are new or known, learn interaction rules from observing trajectories of interacting agent systems, and implement the ideas of compositional learning in the context of learning systems both virtual (for examples, using the OpenAI challenges) and real (for example, using robots), on sequences of tasks of increasing difficulty.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934578
Title: The Stanford Data Science Collaboratory
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $2,000,000
ARRA Amount: $
Investigator(s): Emmanuel Candes candes@stanford.edu (Principal Investigator) Fiorenza Micheli (Co-Principal Investigator) Chiara Sabatti (Co-Principal Investigator) Jurij Leskovec (Co-Principal Investigator) 
Organization: Stanford University
450 Jane Stanford Way, Stanford, CA 94305-2004, (650)723-2300
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Data-driven inquiry is key to all aspects of science and discovery, and data-based decisions are becoming integral to society. The challenges and the importance of meeting them are especially critical when the goal is to obtain relevant, valid, reproducible scientific insights. The Stanford Data Science Collaboratory will confront these challenges by creating a community of faculty, postdoctoral scholars, students, and research fellows that leverage data science methods and domain knowledge to tackle pressing problems.  In the Collaboratory, data scientists will work closely with scholars from other fields who rely on large, accurate, dependable datasets and data science techniques.  The Collaboratory will foster the work of researchers who study the ethical issues related to data collection and use, and will use data to solve societal and scientific problems. A hallmark will be thorough validation of data and a careful statistical calibration of the evidence to avoid misinterpretations that could have adverse consequences.  A second major goal of the Collaboratory is the growth of a citizenry literate in data science: universities have an obligation to ensure the next generation understands how to interpret and learn from data, and how to collect and manage it.<br/><br/>The Collaboratory identifies a set of five high-profile, high-impact projects that domain scientists deem important, and where they believe they are unable to make progress without a paradigm shift in the way they approach data sets. The first two concern a sustainable relation between humans and the environment, namely, (1) the problem of managing coral reefs in a changing climate and (2) reducing illegal fishing and forced labor in tuna supply chains. To make progress, the project will leverage new data sources: satellite remote sensing, ground monitoring stations based on soundscape, and genomic measurements that track biodiversity and evolution.  The other three projects are about fractures in society and steps towards a sustainable one: (3) How to understand the determinants of poverty in the U.S.; (4) How to detect and track political framing in digital media; and (5) How to develop data science tools that support equitable treatment between individuals.  Public data streams (e.g., social media apps, Wikipedia and Wikidata and moderate-resolution satellite imagery) as well as private-sector data (e.g., cell phone records, Facebook activity, internet search queries, drone imagery and fine-resolution satellite data) will inform understanding of the mechanisms causing poverty. To meet the research goals, the Collaboratory will incentivize faculty, students and postdocs to come together to find new data science solutions by supporting collaborative research teams and brainstorming working groups. The Collaboratory will also engage the undergraduate community by providing hands-on guided scientific research experience. To enlarge collaboration beyond Stanford, the Collaboratory will host outside visitors and invite scientists to campus for an annual symposium.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924001
Title: HDR DSC: Collaborative Research: Creating and Integrating Data Science Corps to Improve the Quality of Life in Urban Areas
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 19, 2019
Latest Amendment Date: September 19, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $173,790
ARRA Amount: $
Investigator(s): Michael McGuire mmcguire@towson.edu (Principal Investigator) 
Organization: Towson University
8000 YORK RD, BALTIMORE, MD 21252-0001, (410)704-2236
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The goal of this project is to develop a team-based data science corps program for undergraduate students from Computer Science, Information Systems, and Business integrating both academic training as well as hands-on experience through real-world data science projects. This project is a collaborative effort with the University of Maryland Baltimore County as the coordinating as well as an implementing organization, and the University of Baltimore, Towson University, and Bowie State University as implementing organizations.  This project focuses on the city of Baltimore as an exemplar for other cities in the US and across the globe.   The project team will collaborate with a number of communities in the city of Baltimore to integrate real-world data science projects into classroom instruction in data science. The specific objectives of this project are as follows: (i) Develop the technical, analytical, modeling, and critical thinking skills that are key to success as a data science professional; (ii) Connect a cohort of students to communities, organizations, and projects that can benefit from the power of data science; (iii) Nurture and support innovative thinking in solving some of the key challenges facing the real world; (iv) Promote a better understanding of the power and pitfalls of data-driven discoveries to improve the quality of life in urban communities; (v) Increase the data science workforce capacity to support this critical area that is of growing importance in society; and finally, (vi) Evaluate the effect of the proposed data science corps on student learning. <br/><br/>This project will create a core set of knowledge that will be valuable in developing solutions for real-world urban settings with the understanding that not all projects will require the application or use of every topic covered in the data science corps program. The core set of knowledge includes data collection and cleaning, data analysis using machine learning and deep learning techniques, data visualization including geospatial data and virtual reality, data privacy and security, and infrastructure for smart cities including IoT-based sensor networks.   The proposed data science corps program will have two main phases: instructional phase (10 modules in total) and real-world team projects (5 modules in total). The project teams consist of students who have taken a course in at least one of the following areas: data collection and analysis, big data, machine learning including deep learning, smart cities, cybersecurity, geospatial data analysis and visualization, and virtual reality. Examples of team projects include: (i) developing community-based indicators that are compiled from open data portals and parametric and non-parametric statistical techniques to understand the relationship between urban sustainability and a range of factors including cleanliness and environment, crime and safety, business and economics, social and political, housing, health, and education; (ii) combining deep learning models such as convolutional neural networks (CNN) and long term short term memory recurrent neural networks (LSTM-RNN) to develop prediction models for derelict buildings that are likely to become vacant; (iii) combining sensor data and social media for automated information extraction, validation, and quality checks that can be beneficial to both citizens and emergency managers in crisis situations such as flash floods; (iv) developing smart streetlights that are networked LED systems that can be adjusted based on time of day and motion and can report outages back to central operations; and (v) developing augmented reality-based systems that leverage systems such as Microsoft HoloLens and mobile devices for building evacuation.<br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838183
Title: BIGDATA: IA: Collaborative Research: Understanding the Financial Market Ecosystem
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 12, 2018
Latest Amendment Date: September 12, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: October 01, 2018
End Date: September 30, 2023
Awarded Amount to Date: $422,288
ARRA Amount: $
Investigator(s): Mao Ye maoye@illinois.edu (Principal Investigator) Adam Clark-Joseph (Co-Principal Investigator) Alex Chinco (Co-Principal Investigator) 
Organization: National Bureau of Economic Research Inc
1050 MASSACHUSETTS AVE, CAMBRIDGE, MA 02138-5359, (617)868-3900
NSF Directorate: CSE
Program(s): Economics Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 1320, 8083
Abstract: This is an interdisciplinary project involving computer science and economics. The big data problem to be addressed concerns how to analyze and understand financial trading, and its effects on the stock market. The project introduces new behavioral models of financial trading and applies big data techniques to implement them.  The project will foster research on the financial ecosystem of machine-machine and machine-human interactions by bringing financial economists and data scientists together in a series of workshops.<br/><br/>The PIs will work with the National Center for Supercomputing and develop a new and more accurate taxonomy of trading frequencies by categorizing high frequency traders (HFT), buy-side algorithmic traders (BAT) and human traders using two proprietary high frequency datasets. The workshops will foster research on the implications of the new financial ecosystem for the overall financial system and the economy in general, as well as creating new metrics and data for the discipline of finance in economics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940199
Title: Collaborative Research: Accelerating the Discovery of Electronic Materials through Human-Computer Active Search
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: March 23, 2022
Award Instrument: Standard Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: October 31, 2023
Awarded Amount to Date: $419,937
ARRA Amount: $
Investigator(s): Eric Toberer etoberer@mines.edu (Principal Investigator) 
Organization: Colorado School of Mines
1500 ILLINOIS ST, GOLDEN, CO 80401-1887, (303)273-3000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8249 8396 8611
Program Element Code(s): 099Y, 1712
Abstract: The overarching goal of this project is to accelerate the discovery of  materials with tailored electronic properties through human-computer active search. These efforts will lay the groundwork for accelerating materials discovery, and advance the capability to control electronic properties in materials with the potential for profound societal impact. The thermoelectric and photocatalytic materials predicted, synthesized, and characterized in this research can realize societal advances in the space of energy and solar fuels. High-efficiency thermoelectric materials can revolutionize how heat sources are transformed into electrical power by eliminating the traditional intermediate mechanical energy conversions.  Earth-abundant  light-responsive catalysts are emerging as  an alternative to costly, rare metal catalysts to store solar energy as  portable liquid fuels, like ethanol. These green reactions  are enabling low-cost, carbon-neutral fuels.  The team brings together expertise in materials science, chemistry, machine learning, visualization, metadata, and knowledge frameworks to develop multi-fidelity, expert-guided active search strategies within materials science and chemistry.  Resonances among the team's existing outreach programs will broaden inclusion of students from underrepresented groups and be moderated via the Alliance for Diversity in Science and Engineering.  The work will provide cross-disciplinary training to graduate students and postdocs in all aspects of material informatics, including participating in and leading team efforts, co-mentorship of Ph.D.  and postdoctoral researchers, inclusive symposia at national conferences, and a summer workshop focused on the intersection of visualization, machine learning, ontological engineering and materials science. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative. <br/><br/>An interdisciplinary team will create a search framework for scientific discovery that leverages recent advances in material databases, machine learning, visualization, human-machine interaction, and knowledge structures. To broadly assess the efficacy of this approach, the search effort will span the electronic behavior of both molecules and crystalline materials:  (i) new organic photocatalysts for solar fuels production and (ii) new thermoelectric materials for electricity generation.  Central to this effort is the engagement of domain experts and associated feedback in a human-in-the-loop active search process. Dynamic visualizations will enable the user to (i) understand the underlying reasons why the materials are being suggested and (ii) provide a user steering capability to identify and annotate specific aspects of the explored search space. Domain-expert annotations and feedback will be parsed against a suite of ontologies, further aiding the search process by providing relational insight between features. New molecules and materials will be explored through a combination of first principles calculations and high-throughput, automated experimentation; these results will be incorporated into a continually growing open-access database. Efficiently integrating and directing evolving data-streams from experiment, computation, and human steering during the search will be achieved with a multi-fidelity active search policy. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838147
Title: BIGDATA: F: Collaborative Research: Collective Mining of Vertical Social Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: September 15, 2018
End Date: August 31, 2022
Awarded Amount to Date: $305,963
ARRA Amount: $
Investigator(s): Arjun Mukherjee amukher6@Central.UH.EDU (Principal Investigator) 
Organization: University of Houston
4800 W CALHOUN ST STE 316, HOUSTON, TX 77004-, (713)743-5773
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: A large fraction of internet social media content is found in thousands of specialized communities that are hosted by news outlets, typically in the form of reader forums or comments on news articles. The users of the such a site are said to form a vertical social community (VSC), because they deeply engage with a single media source.  While each VSC is tiny compared to broad communities such as Facebook, they are important because they expose how different segments of society feel about various world events. This can be a very useful resource for downstream intelligence and predictive analytics.  However, current web crawlers cannot effectively access VSCs. Thus their data is invisible to search engines, and remains hidden from analytics tools.  The goals of this project are to enable effective access to vertical social communities coalesced at news reports online, and to mine their comments and debates. This project will provide researchers with tools to collect data from these communities and analyze them.  The educational component of the project includes the involvement of graduate and undergraduate student training and research and the incorporation of research projects and results in courses.<br/><br/>The researchers will develop algorithms to unearth the content generated at thousands of vertical social communities and make their content transparently accessible to data management and analytics tools. The researchers will develop novel deep learning techniques for content detection, and build a novel scalable end-to-end system for real-time access and collective mining of these communities, capable of handling large parallel data streams based on shifting ideas. The specific algorithms will include user population estimation, bootstrap communication patterns for automatic crawling of content, and fine-grained sentiment analysis for intelligence and predictive analytics. Software tools will be made available to researchers in academe and industry. Distribution of free, open-source software for implementing the techniques developed will enhance existing research infrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940239
Title: Collaborative Research: Accelerating the Discovery of Electronic Materials through Human-Computer Active Search
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Daryl Hess
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $211,328
ARRA Amount: $
Investigator(s): Jane Greenberg janeg@drexel.edu (Principal Investigator) 
Organization: Drexel University
3141 CHESTNUT ST, PHILADELPHIA, PA 19104-2816, (215)895-6342
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu DMR SHORT TERM SUPPORT 
Program Reference Code(s): 054Z 062Z 8249 8396 8611
Program Element Code(s): 099Y, 1712
Abstract: The overarching goal of this project is to accelerate the discovery of  materials with tailored electronic properties through human-computer active search. These efforts will lay the groundwork for accelerating materials discovery, and advance the capability to control electronic properties in materials with the potential for profound societal impact. The thermoelectric and photocatalytic materials predicted, synthesized, and characterized in this research can realize societal advances in the space of energy and solar fuels. High-efficiency thermoelectric materials can revolutionize how heat sources are transformed into electrical power by eliminating the traditional intermediate mechanical energy conversions.  Earth-abundant  light-responsive catalysts are emerging as  an alternative to costly, rare metal catalysts to store solar energy as  portable liquid fuels, like ethanol. These green reactions  are enabling low-cost, carbon-neutral fuels.  The team brings together expertise in materials science, chemistry, machine learning, visualization, metadata, and knowledge frameworks to develop multi-fidelity, expert-guided active search strategies within materials science and chemistry.  Resonances among the team's existing outreach programs will broaden inclusion of students from underrepresented groups and be moderated via the Alliance for Diversity in Science and Engineering.  The work will provide cross-disciplinary training to graduate students and postdocs in all aspects of material informatics, including participating in and leading team efforts, co-mentorship of Ph.D.  and postdoctoral researchers, inclusive symposia at national conferences, and a summer workshop focused on the intersection of visualization, machine learning, ontological engineering and materials science. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative. <br/><br/>An interdisciplinary team will create a search framework for scientific discovery that leverages recent advances in material databases, machine learning, visualization, human-machine interaction, and knowledge structures. To broadly assess the efficacy of this approach, the search effort will span the electronic behavior of both molecules and crystalline materials:  (i) new organic photocatalysts for solar fuels production and (ii) new thermoelectric materials for electricity generation.  Central to this effort is the engagement of domain experts and associated feedback in a human-in-the-loop active search process. Dynamic visualizations will enable the user to (i) understand the underlying reasons why the materials are being suggested and (ii) provide a user steering capability to identify and annotate specific aspects of the explored search space. Domain-expert annotations and feedback will be parsed against a suite of ontologies, further aiding the search process by providing relational insight between features. New molecules and materials will be explored through a combination of first principles calculations and high-throughput, automated experimentation; these results will be incorporated into a continually growing open-access database. Efficiently integrating and directing evolving data-streams from experiment, computation, and human steering during the search will be achieved with a multi-fidelity active search policy. Through enabling the acceleration of the discovery of new materials, this project supports the goals of the Materials Genome Initiative.  <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Materials Research within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934759
Title: Collaborative Research: Near Term Forecasts of Global Plant Distribution, Community Structure, and Ecosystem Function
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $294,356
ARRA Amount: $
Investigator(s): Amy Frazier Amy.Frazier@asu.edu (Principal Investigator) 
Organization: Arizona State University
660 S MILL AVE STE 312, TEMPE, AZ 85281-3670, (480)965-5479
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: This project is the first to explore how plant species distributions across the entire globe may respond to global change. The project brings together ecologists, environmental engineers, data scientists, and conservation stakeholders to determine optimal ways to integrate these data sources to make near term forecasts for all plants globally by addressing changes in (1) species' abundance and geographic distribution, (2) community structure, and (3) ecosystem function. This three-pronged approach is designed to span a range of approaches to understand the spectrum of possible futures consistent with current knowledge while integrating knowledge across scales of biological organization. These forecasts will be used along with input from conservation stakeholders to assess how differing conservation decisions can minimize the impacts of global change responses. An ultimate goal of the project is to automate a pipeline to ingest new incoming data, update forecasts, and serve these to end-users to enable a near-real time forecasting workflow to provide best-available predictions at any given time to inform conservation decisions. <br/><br/>A key aspect of these forecasts is their reliance on novel environmental information that better characterize the conditions that influence plant performance, including soil moisture and extreme weather events based on NASA satellite observations. These species-level predictions will be linked to community demography models that integrate a variety of relatively untapped data sources for understanding global change, including plant trait data, community plot data across the globe, highly detailed plot data from National Ecological Observatory Network (NEON) and Long Term Ecological Research (LTER) sites, and global biomass data from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. By integrating this wide variety of data sources, the mechanistic understanding needed to make robust near term forecasts can be made, to understand ecosystem properties like Net Primary productivity, Carbon stock, and resilience. Based on workshops with conservation stakeholders, researchers will determine how best to use this unique suite of forecasts to best inform different conservation questions in different regions of the world. The project will also result in an open, cleaned and curated database on global plant distributions. This will aid others in exploring data and predictions by delivering and visualizing complex future scenarios in an easy to use portal. All results of the project can be found at the website for the Biodiversity Informatics and Forecasting Institute or BIFI, at https://enquistlab.github.io/BIFI .<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838177
Title: BIGDATA: F:  Collaborative Research: Theory and Practice of Randomized Algorithms for Ultra-Large-Scale Signal Processing
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: September 10, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: December 01, 2018
End Date: November 30, 2022
Awarded Amount to Date: $800,000
ARRA Amount: $
Investigator(s): Anshumali Shrivastava as143@rice.edu (Principal Investigator) Richard Baraniuk (Co-Principal Investigator) 
Organization: William Marsh Rice University
6100 MAIN ST, Houston, TX 77005-1827, (713)348-4820
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: The dramatic increases in our abilities to observe massive amounts of measurements coming from distributed and disparate high-resolution sensors have been instrumental in enhancing our understanding of many physical phenomena. Signal processing has been the primary driving force in this knowledge of the unseen from observed measurements. However, in the last decade, the exponential increase in observations has outpaced our computing abilities to process, understand, and organize this massive but useful information. In this project the investigators plan to blend efficient hashing algorithms with Randomized Numerical Linear Algebra, which can overcome these computational barriers. The project will engage diverse graduate and undergraduate students in computer science, statistics, ECE, and applied mathematics both at UCB and Rice. The efforts of this project will also be utilized to push data science for social good, through collaborations with a human rights data analysis group in leveraging hashing algorithms to reduce human efforts in estimating the extent of war crimes. The results of the project will be made available to a wide audience through OpenStax CNX, which will to disseminate course materials free-of-charge to anyone in the world and thereby foster the growth of vibrant communities around the subject.<br/><br/>This project will achieve two complementary goals: first, extend the foundations of RandNLA by tailoring randomization directly towards downstream end goals provided by the underlying problem, rather than intermediate matrix approximations goals; and second, use the statistical and optimization insights obtained from these downstream applications to transform and extend the foundations of RandNLA. The investigators will propose and extend several fundamental ideas, including probabilistic hashing, sketching, streaming, sampling, leverage scores, and random projections, to make SP significantly resource-frugal. Precise mathematical quantification of these tradeoffs will be provided.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123486
Title: Collaborative Research: HDR DSC:  The Metropolitan Chicago Data Science Corps (MCDC): Learning from Data to Support Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 20, 2021
Latest Amendment Date: August 20, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $78,090
ARRA Amount: $
Investigator(s): Paschalis Paschos ppaschos@csu.edu (Principal Investigator) 
Organization: Chicago State University
9501 S KING DR, CHICAGO, IL 60628-, (773)995-2400
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Diverse experts from five universities in, or with a presence in, the Chicago area are collaborating as the Metropolitan Chicago Data-science Corps to 1) help local non-profit organizations take advantage of increasing data volume and data complexity, 2) train data science students in how to effectively apply their academic knowledge to real data challenges in the non-profit sector, 3) exchange data science curriculum and expertise among these universities and with local community colleges. An organization can submit a Request for Data Services (RDS) and receive help to develop it. MCDC particularly welcomes RDS in areas related to environment, health, and our social well-being. Each RDS is assigned to a team of students. Teams of students with a foundation in data science are formed within a practicum course or as part of a summer internship. MCDC will develop the practicum course, where each team has one or more expert mentors and forms a partnership with the requesting organization. At the end of the term, each team will deliver a solution to each of the requesting organizations.<br/><br/>MCDC is an interdisciplinary partnership between universities, myriad community organizations, and two expansion colleges and aims to strengthen the national data science workforce by integrating community needs with academic learning. By supporting infrastructure to unite diverse students and faculty across institutions and disciplines, by prioritizing the engagement of community, and embedding real-world team-based data science projects into the curriculum, the MCDC will be a uniquely powerful educational experience which will support societal progress. To realize this goal, existing curricula are grouped into multiple pathways to prepare a diverse range of students for participation in MCDC. MCDC students acquire both data acumen and societal knowledge that is intended to lead to a well-prepared and engaged workforce. The MCDC project directors combine extensive, proven, funded, and diverse expertise in curriculum development, inclusive learning practices, integrating real-world data into courses, learning systems, data science, as well as in health, social, and environmental sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939916
Title: Collaborative Research: Machine Learning methods for multi-disciplinary multi-scales problems
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 18, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: January 01, 2020
End Date: December 31, 2022
Awarded Amount to Date: $295,964
ARRA Amount: $
Investigator(s): Singdhansu Chatterjee chatt019@umn.edu (Principal Investigator) 
Organization: University of Minnesota-Twin Cities
200 OAK ST SE # 224, MINNEAPOLIS, MN 55455-2009, (612)624-5599
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y
Abstract: This project addresses two of the most pressing challenges in modern scientific research: (a) modeling natural phenomena across a broad range of space and time scales, and (b) the application of data science to discover physically meaningful relationships from large datasets. It will leverage knowledge from related and disparate disciplines, connecting them through data science. Four specific problems will be studied: cloud formation and evolution, movement of particles through random media, frustrated magnetic systems, and the reconstruction of urban topography. These benchmark problems have been selected as they capture different disciplinary aspects of multi-scale challenges. State-of-the-art methods in machine learning (including Artificial Neural Networks) will be used to develop new mathematical representation for small-scale processes. If successful, this project will substantially increase the capability of scientific computing to address a wide variety of important problems from the natural and social sciences, and will be disseminated widely through a pair of workshops, multiple campus visits across the 5-institution consortium, high impact peer-reviewed publications and presentations and the training of a cadre of more than a dozen post-docs and students.<br/><br/>This project will develop, implement and evaluate a new constrained optimization framework to discover and test physical phenomena at different resolutions and scales, including new machine learning algorithms aimed at discovering the stochastic differential equations underlying noisy data. This will be used to train physical parameterizations that account for the effects of small-scale processes in coarse resolution models. Core to this will be the design of a new framework to constrain artificial neural networks to deliver solutions that are interpretable and meaningful in the domain sciences and that can be directly associated with differential operators.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by HDR and the Division of Mathematical Sciences within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940272
Title: Collaborative Research: Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $325,000
ARRA Amount: $
Investigator(s): Qiang Zhu qiang.zhu@unlv.edu (Principal Investigator) 
Organization: University of Nevada Las Vegas
4505 S MARYLAND PKWY, LAS VEGAS, NV 89154-9900, (702)895-1357
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934790
Title: Collaborative Research: Near Term Forecasts of Global Plant Distribution, Community Structure, and Ecosystem Function
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $966,186
ARRA Amount: $
Investigator(s): Brian Enquist benquist@u.arizona.edu (Principal Investigator) Nirav Merchant (Co-Principal Investigator) 
Organization: University of Arizona
888 N EUCLID AVE RM 510, TUCSON, AZ 85719-4824, (520)626-6000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 062Z 7231
Program Element Code(s): 099Y, 7231
Abstract: This project is the first to explore how plant species distributions across the entire globe may respond to global change. The project brings together ecologists, environmental engineers, data scientists, and conservation stakeholders to determine optimal ways to integrate these data sources to make near term forecasts for all plants globally by addressing changes in (1) species' abundance and geographic distribution, (2) community structure, and (3) ecosystem function. This three-pronged approach is designed to span a range of approaches to understand the spectrum of possible futures consistent with current knowledge while integrating knowledge across scales of biological organization. These forecasts will be used along with input from conservation stakeholders to assess how differing conservation decisions can minimize the impacts of global change responses. An ultimate goal of the project is to automate a pipeline to ingest new incoming data, update forecasts, and serve these to end-users to enable a near-real time forecasting workflow to provide best-available predictions at any given time to inform conservation decisions. <br/><br/>A key aspect of these forecasts is their reliance on novel environmental information that better characterize the conditions that influence plant performance, including soil moisture and extreme weather events based on NASA satellite observations. These species-level predictions will be linked to community demography models that integrate a variety of relatively untapped data sources for understanding global change, including plant trait data, community plot data across the globe, highly detailed plot data from National Ecological Observatory Network (NEON) and Long Term Ecological Research (LTER) sites, and global biomass data from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. By integrating this wide variety of data sources, the mechanistic understanding needed to make robust near term forecasts can be made, to understand ecosystem properties like Net Primary productivity, Carbon stock, and resilience. Based on workshops with conservation stakeholders, researchers will determine how best to use this unique suite of forecasts to best inform different conservation questions in different regions of the world. The project will also result in an open, cleaned and curated database on global plant distributions. This will aid others in exploring data and predictions by delivering and visualizing complex future scenarios in an easy to use portal. All results of the project can be found at the website for the Biodiversity Informatics and Forecasting Institute or BIFI, at https://enquistlab.github.io/BIFI .<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940335
Title: Collaborative Research: I-AIM: Interpretable Augmented Intelligence for Multiscale Material Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 14, 2019
Latest Amendment Date: September 14, 2019
Award Instrument: Standard Grant
Program Manager: Giovanna Biscontin
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $417,999
ARRA Amount: $
Investigator(s): Hendrik Heinz hendrik.heinz@colorado.edu (Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The ability to model, predict, and improve the mechanical performance of engineering materials such as polymers, composites, and alloys can have a significant impact on manufacturing, with important economic and societal benefits. As advanced computational algorithms and data science approaches become available, they can be harnessed to disrupt the current approaches to materials modeling, and allow for the design and discovery of new high-strength, high-performance materials for manufacturing. Bringing together multidisciplinary teams of researchers can maximize the impact of these new tools and techniques. This Harnessing the Data Revolution Institutes for Data-Intensive Research in Science and Engineering (HDR-I-DIRSE) award supports the conceptualization of an Institute to develop novel data science methods, address fundamental scientific questions of Materials Engineering and Manufacturing, and build such multidisciplinary teams. The project will apply novel data science methods to advance the analysis of large sets of structural data of composite materials and alloys from the atomic scale to correlate with and predict mechanical properties. The methods are based on machine learning techniques and uncertainty quantification, and will help uncover underlying structural features in the materials that determine the properties and performance. The methods and results will help accelerate the development of ultra-high strength and lightweight carbon-based composites for aerospace applications, and multi-element superalloys for more durable engine parts, by navigating in the large possible design space and providing faster predictions than experiments and traditional simulation methods. The project will also lead to new methods and computational algorithms that will become publicly available. The investigators will train graduate and undergraduate students from various disciplines with a focus on engaging women and minorities in STEM fields, develop short courses that integrate novel Materials Science and Engineering applications and Data Science methods, and foster vertical integration of interdisciplinary research from undergraduate students to senior scientists.<br/><br/>This project aims at building an effective and interpretable learning framework for materials data across scales to solve a major challenge in current data-driven materials design. The combined Materials Science and Data Science approaches will synergistically contribute to the development and use of interpretable and physics-informed data science methodologies to gain new understanding of mechanical properties of polymer composites and alloys, with the potential to be expanded into different property sets and different systems. The PIs will utilize available data efficiently through combination with physical rules and prior knowledge, to develop an interpretable augmented intelligent system to learn principles behind the association of input structures with material properties with uncertainty quantification. The interconnected tasks involve the (1) collection and curation of large amounts of computational and experimental data for polymer/carbon nanotube composites and alloys from open data sources and targeted calculations and experiments, (2) the development of geometric and topological methods incorporating physical principles to generate a better, more sensitive low-dimensional representation of the multidimensional data and characterize the parameter space related to mechanical properties, (3) the development of a Bayesian deep reinforcement learning framework to generate interpretable knowledge graphs that depict the relational knowledge among physical quantities with uncertainty quantification, and (4) the prediction of mechanical properties to reveal design principles to improve materials performance, evaluate and validate the methods, and develop software for dissemination. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity and is co-funded by the Division of Civil, Mechanical and Manufacturing Innovation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837999
Title: BIGDATA: IA: Collaborative Research: Asynchronous Distributed Machine Learning Framework for Multi-Site Collaborative Brain Big Data Mining
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: September 10, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $119,982
ARRA Amount: $
Investigator(s): Todd Parrish toddp@northwestern.edu (Principal Investigator) 
Organization: Northwestern University at Chicago
633 CLARK ST, EVANSTON, IL 60208-0001, (312)503-7955
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Recent advances in multimodal brain imaging and high throughput genotyping and sequencing techniques provide exciting new opportunities to ultimately improve our understanding of brain structure and neural dynamics, their genetic architecture, and their influences on cognition and behavior. However, data privacy and security issues have inhibited data sharing across institutes. Emerging multi-site collaborative data analysis can address these issues and facilitate data and computing resource sharing. In collaborative data analysis, the participating institutes keep their own data, which are analyzed and computed locally, and only share the computed results by communicating with a server. The server communicates with all institutes and updates the local models such that the trained machine learning models indirectly use all data and are shared with all institutes. Although some distributed/parallel computation techniques were recently proposed to address big data mining problems, most of them are synchronous models. Asynchronous distributed learning methods are much more efficient, because they allow the server to update the model with information from only one worker node without waiting for slow worker nodes in each round. However, the convergence analysis for the asynchronous distributed algorithms is much more difficult due to the inconsistent variables update across nodes. Thus, it is challenging to design efficient distributed machine learning algorithms for collaborative big data analysis. The research objective of this project is to address the computational challenges in the emerging multi-site collaborative data mining for brain big data.<br/> <br/>This project seeks to harness the opportunities of designing new efficient asynchronous distributed machine learning algorithms with rigorous theoretical foundations for multi-site collaborative brain big data mining, creating large-scale computational strategies and effective software tools to reveal sophisticated relationships among heterogeneous brain data. This project designs the asynchronous distributed machine learning and principled big data mining models to conduct the comprehensive study of brain imaging genomics and connectomics. Specifically, the principal investigators investigate: 1) collaborative genotype and phenotype association study using new asynchronous doubly stochastic proximal gradient algorithms; 2) communication-efficient multi-site collaborative data integration models to integrate imaging genomics data for predicting outcomes of interest; 3) collaborative deep learning algorithm speedup by the asynchronous distributed algorithms with applications in temporal cognitive change prediction; and 4) new graph convolutional deep learning models for brain network mining. It is innovative to integrate new distributed machine learning and data-intensive computing with brain imaging genomics and connectomics that hold great promise for a systems biology of the brain. The developed methods and tools impact other neuroimaging, genomics, and neuroscience research, and enable investigators working on brain science to effectively test their scientific hypotheses. This project will also facilitate the development of novel educational tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1938729
Title: Collaborative Research: SSMCDAT2020: Solid-State and Materials Chemistry Data Science Hackathon
NSF Org: DMR Division Of Materials Research
Initial Amendment Date: August 23, 2019
Latest Amendment Date: August 23, 2019
Award Instrument: Standard Grant
Program Manager: Birgit Schwenzer
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $37,426
ARRA Amount: $
Investigator(s): Frank Curtis fec309@lehigh.edu (Principal Investigator) 
Organization: Lehigh University
526 BRODHEAD AVE, BETHLEHEM, PA 18015-3008, (610)758-3021
NSF Directorate: MPS
Program(s): OFFICE OF MULTIDISCIPLINARY AC SOLID STATE & MATERIALS CHEMIS CONDENSED MATTER & MAT THEORY Big Data Science &Engineering 
Program Reference Code(s): 054Z 7556 8083 8084
Program Element Code(s): 1253, 1762, 1765, 8083
Abstract: This award, with support from the Division of Materials Research, the Division of Mathematical Sciences and the Office of Multidisciplinary Activities, sponsors the organization of a "data science hackathon" for researchers in the fields of solid-state materials chemistry and data science. This event, SSMCDAT2020, bring together members from these fields to further science through data-intensive research in order to make advances toward solving challenging problems relevant to solid-state materials chemistry. Teams work together for a three-day event, working both as teams and as a large cohort on a set of research projects. The hackathon lays a foundation for long-lasting collaborations between materials and data scientists.<br/><br/>The Materials Genome Initiative (MGI) was introduced in 2011 with the goal of developing and deploying new materials at twice the speed and a fraction of the cost. Key tenets of the initiative are the ideas that (a) materials "genes" exist and skilled manipulation of the materials "genome" will lead to rapid discovery and deployment of advanced materials, and (b) experimental materials research has been far too costly and slow to be the primary vehicle for exploration and discovery. For these reasons, the MGI proposes that investigations should be minimized by judicious use of computational materials science. The development of such computational techniques has transformed the field, but unlocking the materials genome still faces major challenges. To address these challenges, this solid-state materials chemistry-focused "hackathon" is designed to broaden the approach laid out in the MGI to encompass the rapidly evolving field of data science. Indeed, early adopters of this approach have amassed numerous impressive proofs of concept. With strong partnerships between solid-state materials chemistry and data science researchers, significant advances toward accomplishing the goals of the MGI can be achieved.<br/><br/>This "data science hackathon" is a fundamentally interdisciplinary endeavor. Solid-state materials chemistry researchers are trained in the application of data science tools, becoming informed of the advantages and limitations of various approaches.  Data scientists are exposed to the breadth of materials data available, as well as the most pressing solid-state materials research challenges. Special attention is paid to have participation from promising graduate students and postdocs, as well as under-represented groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837964
Title: BIGDATA: IA: Collaborative Research: Asynchronous Distributed Machine Learning Framework for Multi-Site Collaborative Brain Big Data Mining
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 10, 2018
Latest Amendment Date: May 27, 2020
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $316,000
ARRA Amount: $
Investigator(s): Li Shen li.shen@pennmedicine.upenn.edu (Principal Investigator) 
Organization: University of Pennsylvania
3451 WALNUT ST STE 440A, PHILADELPHIA, PA 19104-6205, (215)898-7293
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7364 8083 9251
Program Element Code(s): 8083
Abstract: Recent advances in multimodal brain imaging and high throughput genotyping and sequencing techniques provide exciting new opportunities to ultimately improve our understanding of brain structure and neural dynamics, their genetic architecture, and their influences on cognition and behavior. However, data privacy and security issues have inhibited data sharing across institutes. Emerging multi-site collaborative data analysis can address these issues and facilitate data and computing resource sharing. In collaborative data analysis, the participating institutes keep their own data, which are analyzed and computed locally, and only share the computed results by communicating with a server. The server communicates with all institutes and updates the local models such that the trained machine learning models indirectly use all data and are shared with all institutes. Although some distributed/parallel computation techniques were recently proposed to address big data mining problems, most of them are synchronous models. Asynchronous distributed learning methods are much more efficient, because they allow the server to update the model with information from only one worker node without waiting for slow worker nodes in each round. However, the convergence analysis for the asynchronous distributed algorithms is much more difficult due to the inconsistent variables update across nodes. Thus, it is challenging to design efficient distributed machine learning algorithms for collaborative big data analysis. The research objective of this project is to address the computational challenges in the emerging multi-site collaborative data mining for brain big data.<br/> <br/>This project seeks to harness the opportunities of designing new efficient asynchronous distributed machine learning algorithms with rigorous theoretical foundations for multi-site collaborative brain big data mining, creating large-scale computational strategies and effective software tools to reveal sophisticated relationships among heterogeneous brain data. This project designs the asynchronous distributed machine learning and principled big data mining models to conduct the comprehensive study of brain imaging genomics and connectomics. Specifically, the principal investigators investigate: 1) collaborative genotype and phenotype association study using new asynchronous doubly stochastic proximal gradient algorithms; 2) communication-efficient multi-site collaborative data integration models to integrate imaging genomics data for predicting outcomes of interest; 3) collaborative deep learning algorithm speedup by the asynchronous distributed algorithms with applications in temporal cognitive change prediction; and 4) new graph convolutional deep learning models for brain network mining. It is innovative to integrate new distributed machine learning and data-intensive computing with brain imaging genomics and connectomics that hold great promise for a systems biology of the brain. The developed methods and tools impact other neuroimaging, genomics, and neuroscience research, and enable investigators working on brain science to effectively test their scientific hypotheses. This project will also facilitate the development of novel educational tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838017
Title: BIGDATA: F: Optimization in Federated Networks of Devices
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: September 07, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $999,391
ARRA Amount: $
Investigator(s): Ameet Talwalkar talwalkar@cmu.edu (Principal Investigator) Virginia Smith (Co-Principal Investigator) 
Organization: Carnegie-Mellon University
5000 FORBES AVE, PITTSBURGH, PA 15213-3815, (412)268-8746
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Modern networks of remote devices, such as mobile phones, wearable devices, and autonomous vehicles, generate massive amounts of data each day. This rich data has the potential to power a wide range of statistical machine learning-based applications, such as learning the activities of mobile phone users, adapting to pedestrian behavior in autonomous vehicles, predicting health events like low blood sugar from wearable devices, or detecting burglaries within smart homes. Due to the growing storage and computational power of remote devices, as well as privacy concerns associated with personal data, it is increasingly attractive to store and process data directly on each device. In the burgeoning field of "federated learning," the aim is to use a central server to learn statistical models from data stored across these remote devices, while relying on substantial computation from each device. Federated learning can be naturally cast through the lens of mathematical optimization, a key component in formulating and training most machine learning models. This project focuses on tackling several of the unique statistical and systems challenges associated with federated optimization. As part of this project, a novel open-source benchmarking framework is also being developed to concretely define the research challenges in federated learning and promote reproducibility in empirical evaluations. This project involves participation from students from underrepresented populations.<br/>    <br/>The focus of this project is to develop a novel suite of optimization methods to tackle the unique challenges of learning on remote devices, including (a) expensive communication between remote devices and a central server; (b) high variability in data, computational resources, and communication bandwidth across devices; and (c) a very small fraction of remote devices participating in the training process at any one time. While numerous optimization methods in the data center setting have been proposed to tackle (a), none allow significant flexibility in terms of (b) and (c). Further, the limited number of recently introduced federated methods either lack theoretical convergence guarantees or do not adequately address these three challenges. This project aims to develop a suite of federated optimization methods to tackle these issues, specifically developing and understanding techniques for: convex optimization, non-convex optimization, and network-aware optimization. These methods will unleash the computational power of federated networks to train highly-accurate predictive models while adhering to strict systems, network, and privacy constraints. This project leverages ideas from optimization, statistics, machine learning, distributed computing, and sensor networks.  In addition to developing foundational federated optimization methods, the broader impact of this project includes the creation of a novel open-source benchmarking framework.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1837959
Title: BIGDATA: IA: A Multi-phase Survey Strategy for Generalizing Inferences from Big Data
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $991,127
ARRA Amount: $
Investigator(s): Michael Robbins mrobbins@rand.org (Principal Investigator) 
Organization: Rand Corporation
1776 MAIN ST, Santa Monica, CA 90401-3297, (310)393-0411
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7434 8083
Program Element Code(s): 8083
Abstract: Many researchers argue that commercial services that yield a high volume of data have little scientific utility because their users are not representative of the general population. This project develops methods for generalizing inferences drawn from non-representative big data sources. The researchers are implementing a multi-phase survey to compare survey results with online social networking data. They will collect a nationwide probability sample and a separate sample of online users, and use novel statistical procedures to combine them in a manner will enable statistically valid estimators to be produced from the universe of online users.  The results of this project will be broadly applicable by enabling more accurate statistical models of to be created for applications in medicine, economics, and many other fields. <br/> <br/>Statistical weighting will be used to match the online media sample with the probability survey sample across a set of auxiliary variables observed for both samples. The researchers will then match the data in the universe of online users to the weighted sample across a second set of variables that is measured for all users. Doing so will enable extracting results from media users that are more representative of the general population. To produce real-time forecasts, Bayesian models for mixed frequency time series will be used to combine the weighted online-based analyses with traditional polls.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939885
Title: Collaborative Research: Accelerating Synthetic Biology Discovery & Exploration through Knowledge Integration
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $271,519
ARRA Amount: $
Investigator(s): Mai Nguyen mhnguyen@ucsd.edu (Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: The scientific challenge for this project is to accelerate discovery and exploration of the synthetic biology design space.  In particular, many parts used in synthetic biology come from or are initially tested in a simple bacteria, E. coli, but many potential applications in energy, agriculture, materials, and health require either different bacteria or higher level organisms (yeast for example). Currently, researchers use a trial-and-error approach because they cannot find reliable information about prior experiments with a given part of interest. This process simply cannot scale. Therefore, to achieve scale, a wide range of data must be harnessed to allow confidence to be determined about the likelihood of success. The quantity of data and the exponential increase in the publications generated by this field is creating a tipping point, but this data is not readily accessible to practitioners. To address this challenge, our multidisciplinary team of biological engineers, machine learning experts, data scientists, library scientists, and social scientists will build a knowledge system integrating disparate data and publication repositories in order to deliver effective and efficient access to collectively available information; doing so will enable expedited, knowledge-based synthetic biology design research.<br/><br/>This project will develop an open and integrated synthetic biology knowledge system (SBKS) that leverages existing data repositories and publications to create a single interface that transforms the way researchers access this information. Access to up-to-date information in multiple, heterogeneous sources will be provided via a federated approach. New methods based on machine learning will be developed to automatically generate ontology annotations in order to create connections between data in various repositories and information extracted from publications.  Provenance for each entity in SBKS will be tracked, and it will be utilized by new methods that are developed to assess bias and assign confidence scores to knowledge returned for each entity. An intuitive, natural-language-based interface and visualization functionality will be implemented for users to easily access and explore SBKS contents.  Additionally, as ethics is necessarily a part of synthetic biology research, data from text sources related to ethical concerns in synthetic biology will also be incorporated to inform researchers about ethical debates relevant to their search queries.  Finally, to test the SBKS API, a new genetic design tool, Kimera, will be developed that leverages the knowledge in SBKS to produce better designs.  The proposed SBKS will accelerate discovery and innovation by enabling researchers to learn from others' past experiences and to maximize the productivity of valuable experimental time on testing designs that have a higher likelihood of working when transformed to a new organism.  This research thus provides the potential for transformative research outcomes in the field of synthetic biology by leveraging data science to improve the field's epistemic culture. For more information please see https://synbioks.github.io.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1818650
Title: Enabling Computer and Information Science and Engineering Research and Education in the Cloud Workshop
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: January 11, 2018
Latest Amendment Date: January 10, 2022
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 15, 2018
End Date: December 31, 2022
Awarded Amount to Date: $49,999
ARRA Amount: $
Investigator(s): Jennifer Rexford jrex@cs.princeton.edu (Principal Investigator) 
Organization: Princeton University
1 NASSAU HALL, PRINCETON, NJ 08544-2001, (609)258-3090
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7556 8083
Program Element Code(s): 8083
Abstract: -Part 1:<br/><br/>Cloud computing can transform computer science research and education through on-demand, elastic, and self-serve access to computation and storage resources at scale, coupled with contemporary hardware (e.g., graphical and tensor processing units), advanced software stacks (e.g., machine-learning libraries), and shared data sets. Researchers and educators can avoid the substantial time, energy, and expense of building and maintaining local infrastructure, students can be better prepared for the cloud-centered world they will enter upon graduation, and research projects across institutional boundaries can more easily share and maintain data and the results of their analysis. <br/><br/>Although academic adoption of the cloud is increasing, significant challenges remain. Researchers worry about the relative costs compared to local infrastructure, especially when some local costs are hidden (e.g., "free" rack space, cooling, and power, as well as lower overhead charges on grants for equipment purchases). Graduate students worry about causing run-away costs if their experiments in the cloud run amok, and the risk of escalating costs near major paper submission deadlines. Some projects may not be able to use the public cloud, due to privacy issues (or the perception of increased privacy risk) concerning the underlying data. Plus, for both researchers and educators, making the transition to the cloud requires overcoming a "learning curve" to select a particular cloud offering---and learn how to use it effectively. <br/><br/>This workshop will identify opportunities and challenges for Computer and Information Science and Engineering (CISE) researchers and educators to use the cloud, and recommend steps the major stakeholders can take to lower the barriers to cloud adoption. By convening a diverse community of stakeholders who can contribute to the strategic development of a cloud-computing roadmap, this workshop will lower the barriers for cloud adoption for academic research and education in CISE. The perspectives and insights shared from industry, government, and academia, coupled with discussions focused on actionable challenges and measurable outcomes, will serve to advance CISE research and education. The workshop will identify high-priority topics and high-impact opportunities for future research, training, and collaboration in conjunction with cloud computing.<br/><br/>-Part 2<br/><br/>The workshop will engage about 35-45 participants from academic, industry, and government, including principal investigators, educators, cloud-computing researchers, campus CIOs, public cloud providers, and government funding agencies.  The workshop will focus on several key issues including, (1) CISE research and the cloud: What types of CISE research are (or are not) best enabled by cloud platforms? (2) CISE education and the cloud: What types of CISE education are best enabled by cloud platforms? What novel concepts can be taught? (3) Key challenges with cloud usage: What are the barriers to cloud adoption and how should the stakeholders address these issues? (4) Relationship among various types of resources: What roles should on-campus resources, national resources, and cloud-provided resources each play in supporting research and teaching? (5) Cloud costs: How can researchers and educators best manage the costs of cloud usage, including the risks of runaway costs or costs that continue after a grant funding a project has ended? (6) Education for prospective cloud users: What are good ways to educate and train researchers, students, and campus IT staff on using the cloud effectively? (7) Ongoing user support: What ongoing support is needed for academic users, whether locally or at the national level? <br/><br/>The workshop will host a series of presentations and working sessions with live note-takers, resulting in a post-meeting white paper describing key themes, insights, and recommendations from the discussions. Lowering the barriers to academic use of the cloud has the potential to significantly improve how CISE researchers and educators conduct their work. Using the cloud can reduce IT costs, foster cross-institution and interdisciplinary research collaborators, and better train students for a cloud-centric world. Innovations in cloud computing services can help cloud providers recognize new opportunities ahead of future commercial demands, while better supporting academic research and education.

Award Number: 1633370
Title: BIGDATA: Collaborative Research: F: Efficient and Exact Methods for Big Data Reduction
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2016
Latest Amendment Date: September 22, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $499,653
ARRA Amount: $
Investigator(s): Qiaozhu Mei qmei@umich.edu (Principal Investigator) Jie Wang (Former Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: Research in big data involves analyzing growing data sets with huge numbers of samples, very high-dimensional feature vectors, and complex and diverse structures. The ever-growing volume and complexity of these data sets make many traditional techniques inadequate to extract knowledge from them. An emerging area, known as sparse learning, has achieved great success in learning from big data by identifying a small set of explanatory features and/or samples. Typical examples include selecting features that are most indicative of users? preferences for recommendation systems, identifying brain regions that are predictive of neurological disorders based on imaging data, and extracting semantic information from raw images for object recognition. However, training sparse learning models can be computationally prohibitive due to the sparsity-inducing regularization, which is non-smooth and can be highly complex when incorporating complex structures. This project aims at developing algorithms and tools to significantly accelerate the training process of sparse learning models for big data applications. The key idea is to efficiently identify redundant features and/or samples, which can be removed from the training phase without losing useful information of interests. Success in these unique techniques is expected to dramatically scaling up sparse learning for big data by orders of magnitude in terms of both time and space. The PIs plan to integrate the big data reduction tools developed in this project into their education and outreach activities, including development of new courses and integration of project components into existing courses. The PIs will make special efforts to recruit female and underrepresented students to this project.<br/><br/>The major technical innovations of this project include the following components: (1) the PIs will develop efficient feature reduction methods for the generic scenario where the structures of both input and output can be represented by directed acyclic graphs; the proposed formulations include many existing approaches as special cases; (2) the PIs will develop efficient methods to reduce the numbers of features and samples simultaneously under a unified formulation, which can also incorporate various structures; (3) the PIs will develop efficient methods to discard irrelevant data subspaces to accelerate the process of uncovering low-rank structures commonly seen in big data. All the proposed data reduction methods are exact, i.e., the models learned on the reduced data sets are identical to the ones learned on the full data sets. This project heavily relies on optimization theory, especially on sensitivity analysis and convex geometry. The outcome of this project includes a unified approach to accelerate sparse learning and provide a systematic framework for developing efficient and exact data reduction methods. The systematic study and in-depth exploration of redundant data identification is expected to deepen the understanding of sparse learning techniques and dramatically enhance their applications in big data analytics.

Award Number: 1940202
Title: Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $435,478
ARRA Amount: $
Investigator(s): Takaki Komiyama tkomiyama@ucsd.edu (Principal Investigator) 
Organization: University of California-San Diego
9500 GILMAN DR, LA JOLLA, CA 92093-5004, (858)534-4896
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1640
Abstract: The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.<br/><br/>The project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940162
Title: Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $387,256
ARRA Amount: $
Investigator(s): Rudiyanto Gunawan rgunawan@buffalo.edu (Principal Investigator) 
Organization: SUNY at Buffalo
520 LEE ENTRANCE STE 211, AMHERST, NY 14228-2577, (716)645-2634
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc Info Integration & Informatics 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y, 1640, 7364
Abstract: The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.<br/><br/>The project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939999
Title: Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: November 08, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $375,224
ARRA Amount: $
Investigator(s): Tim Mewes tmewes@ua.edu (Principal Investigator) Claudia Mewes (Former Principal Investigator) 
Organization: University of Alabama Tuscaloosa
301 ROSE ADMIN BLDG, TUSCALOOSA, AL 35487-0001, (205)348-5152
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc 
Program Reference Code(s): 062Z 9102 9150
Program Element Code(s): 099Y, 1640
Abstract: The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.<br/><br/>The project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940124
Title: Collaborative Research: Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $331,001
ARRA Amount: $
Investigator(s): David Matteson dm484@cornell.edu (Principal Investigator) 
Organization: Cornell University
341 PINE TREE RD, ITHACA, NY 14850-2820, (607)255-5014
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934389
Title: Collaborative Research: Near Term Forecasts of Global Plant Distribution, Community Structure, and Ecosystem Function
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Peter McCartney
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $296,104
ARRA Amount: $
Investigator(s): Laura Duncanson lduncans@umd.edu (Principal Investigator) 
Organization: University of Maryland, College Park
3112 LEE BLDG 7809 REGENTS DR, COLLEGE PARK, MD 20742-0001, (301)405-6269
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: This project is the first to explore how plant species distributions across the entire globe may respond to global change. The project brings together ecologists, environmental engineers, data scientists, and conservation stakeholders to determine optimal ways to integrate these data sources to make near term forecasts for all plants globally by addressing changes in (1) species' abundance and geographic distribution, (2) community structure, and (3) ecosystem function. This three-pronged approach is designed to span a range of approaches to understand the spectrum of possible futures consistent with current knowledge while integrating knowledge across scales of biological organization. These forecasts will be used along with input from conservation stakeholders to assess how differing conservation decisions can minimize the impacts of global change responses. An ultimate goal of the project is to automate a pipeline to ingest new incoming data, update forecasts, and serve these to end-users to enable a near-real time forecasting workflow to provide best-available predictions at any given time to inform conservation decisions. <br/><br/>A key aspect of these forecasts is their reliance on novel environmental information that better characterize the conditions that influence plant performance, including soil moisture and extreme weather events based on NASA satellite observations. These species-level predictions will be linked to community demography models that integrate a variety of relatively untapped data sources for understanding global change, including plant trait data, community plot data across the globe, highly detailed plot data from National Ecological Observatory Network (NEON) and Long Term Ecological Research (LTER) sites, and global biomass data from NASA's Global Ecosystem Dynamics Investigation (GEDI) mission. By integrating this wide variety of data sources, the mechanistic understanding needed to make robust near term forecasts can be made, to understand ecosystem properties like Net Primary productivity, Carbon stock, and resilience. Based on workshops with conservation stakeholders, researchers will determine how best to use this unique suite of forecasts to best inform different conservation questions in different regions of the world. The project will also result in an open, cleaned and curated database on global plant distributions. This will aid others in exploring data and predictions by delivering and visualizing complex future scenarios in an easy to use portal. All results of the project can be found at the website for the Biodiversity Informatics and Forecasting Institute or BIFI, at https://enquistlab.github.io/BIFI .<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838145
Title: BIGDATA: F: Collaborative Research: Collective Mining of Vertical Social Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 06, 2018
Latest Amendment Date: September 06, 2018
Award Instrument: Standard Grant
Program Manager: Sara Kiesler
Start Date: September 15, 2018
End Date: August 31, 2022
Awarded Amount to Date: $427,912
ARRA Amount: $
Investigator(s): Eduard Dragut edragut@temple.edu (Principal Investigator) 
Organization: Temple University
1801 N BROAD ST, PHILADELPHIA, PA 19122-6003, (215)707-7547
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 7433 8083
Program Element Code(s): 8083
Abstract: A large fraction of internet social media content is found in thousands of specialized communities that are hosted by news outlets, typically in the form of reader forums or comments on news articles. The users of the such a site are said to form a vertical social community (VSC), because they deeply engage with a single media source.  While each VSC is tiny compared to broad communities such as Facebook, they are important because they expose how different segments of society feel about various world events. This can be a very useful resource for downstream intelligence and predictive analytics.  However, current web crawlers cannot effectively access VSCs. Thus their data is invisible to search engines, and remains hidden from analytics tools.  The goals of this project are to enable effective access to vertical social communities coalesced at news reports online, and to mine their comments and debates. This project will provide researchers with tools to collect data from these communities and analyze them.  The educational component of the project includes the involvement of graduate and undergraduate student training and research and the incorporation of research projects and results in courses.<br/><br/>The researchers will develop algorithms to unearth the content generated at thousands of vertical social communities and make their content transparently accessible to data management and analytics tools. The researchers will develop novel deep learning techniques for content detection, and build a novel scalable end-to-end system for real-time access and collective mining of these communities, capable of handling large parallel data streams based on shifting ideas. The specific algorithms will include user population estimation, bootstrap communication patterns for automatic crawling of content, and fine-grained sentiment analysis for intelligence and predictive analytics. Software tools will be made available to researchers in academe and industry. Distribution of free, open-source software for implementing the techniques developed will enhance existing research infrastructure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741370
Title: BIGDATA: IA: Collaborative Research: Domain Adaptation Approaches for Classifying Crisis Related Data on Social Media
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 14, 2017
Latest Amendment Date: September 18, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2018
End Date: December 31, 2022
Awarded Amount to Date: $400,000
ARRA Amount: $
Investigator(s): Andrea Tapia atapia@ist.psu.edu (Principal Investigator) Jessica Kropczynski (Co-Principal Investigator) 
Organization: Pennsylvania State Univ University Park
201 Old Main, University Park, PA 16802-1503, (814)865-1372
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 8083
Abstract: The project investigates the use of big-data analysis techniques for classifying crisis-related data in social media with respect to situational awareness categories, such as caution, advice, fatality, injury, and support, with the goal of helping emergency response teams identify useful information. A major challenge is the scale of the data, where millions of short messages are continuously posted during a disaster, and need to be analyzed. The use of current technologies based on automated machine learning is limited due to the lack of labeled data for an emergent target disaster, and the fact that every event is unique in terms of geography, culture, infrastructure, technology, and the people involved. To tackle the above challenges, domain adaptation techniques that make use of existing labeled data from prior disasters and unlabeled data from a current disaster are designed. The resulting models are continuously updated and improved based on feedback from crowdsourcing volunteers. The research will provide real, usable solutions to emergency response organizations and will enable these organizations to improve the speed, quality and efficiency of their response. <br/><br/>The research provides novel solutions based on domain adaptation and deep neural networks to tackle the unique challenges in applying machine learning for crisis-related data analysis, specifically the volume and velocity challenges of big crisis data. Domain adaptation approaches enable the transfer of information from prior source disasters to an emergenet target disaster. Deep learning approaches make it possible to employ large amounts of labeled source data and unlabeled target data, and to incrementally update the models as more labeled target data becomes available. Large-scale analysis across combinations of source and target crises will help identify patterns of transferable situational awareness knowledge. The resulting technical and social solutions will be blended together for use in data management and emergency response.

Award Number: 1939795
Title: HDR: DIRSE-IL: COLLABORATIVE RESEARCH: Harnessing data advances in systems biology to design a biological 3D printer: The synthetic coral
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $340,584
ARRA Amount: $
Investigator(s): Hollie Putnam hputnam@uri.edu (Principal Investigator) 
Organization: University of Rhode Island
75 LOWER COLLEGE, KINGSTON, RI 02881-1974, (401)874-2635
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102 9150
Program Element Code(s): 099Y
Abstract: Corals are important natural resources that are key to the ocean's vast biodiversity and provide economic, cultural, and scientific benefits. As a result of human activities, locally and globally, coral reefs are declining rapidly. The complexity of corals makes conserving and restoring reefs very challenging. Corals are made up of thousands of different organisms, including the animal host and the algae, bacteria, viruses, and fungi that coexist as a so-called holobiont. Thus, corals are more like cities than individual animals, as they provide factories, housing, restaurants, nurseries, and more for an entire ecosystem. This project brings together experts in computer science, materials science, and biology to harness the data revolution in biology with machine learning to study how corals grow and function, when viewed as if they were manufacturing sites in the ocean. The study will focus on three key coral capabilities: (1) they create calcium carbonate skeletons that provide 3D structures for diverse sea life to live in, (2) they can heal damage to their tissues, and, (3) they live with the other organisms in a process referred to as symbiosis. Through these remarkable abilities, corals can 'print' resources for themselves and hundreds of thousands of other species, just like a 3D printer. The goal of this project is to understand these processes well enough to control them in the lab. This project may allow finding new ways to help coral survival, by deciphering the reasons why certain conditions damage them and find ways of repairing them. Furthermore, by synthetically growing corals, new types of materials may be identified for manufacturing. This project offers an opportunity to educate a diverse scientific workforce and the public by creating and disseminating the outcomes of a convergent research environment and will train postdoctoral researchers, graduate, and undergraduate students. Results of this research will be made available to the broader scientific community through web interfaces, peer-reviewed publications and workshops/conferences and shared with the public through outreach activities online, at schools, and public aquariums.<br/>    <br/>Through convergence of three disciplines, computer science, material science and biology, this project will provide a data-driven framework and toolset to learn from, control, engineer, and manufacture a combined form of living material, the 'synthetic coral', thereby opening new avenues for material synthesis and manufacturing. The research methodology will offer new analytical approaches to identify and quantify the parameters that govern coral growth and foster innovative new tools for controlling their growth. To understand the key functions of coral biology of biomineralization, wound healing, and symbiosis, this research will : (1) harness and analyze large amounts of coral '-omics' data to decipher critical molecules and their interactions for the aforementioned key functions, (2) experimentally validate the resulting predictions in coral individuals and cell lines, (3) manipulate the material properties of the calcium carbonate structures of the coral individuals and cell lines, and (4) test the biological and physical interactions in a network model of the 'synthetic coral'. This project develops and integrates fundamental building blocks that are essential for  an integrated computational and experimental validation system. Specifically, using machine learning, diverse data will be harnessed to identify physical conditions (e.g., surface characteristics), environmental conditions (e.g., temperature, pH), and key biological constituents (e.g., small molecule ligands and proteins encoded in the DNA) that are correlated to key structural and functional properties of the coral holobiont. These predicted conditions and molecules will be verified experimentally by perturbing individual coral nodes in a network of a 3D printed array of intact corals or their constituent cells and measuring their effects on the network of interactions and resulting structures. The results from this prediction-validation cycle will then be transferred back as input to manufacture novel adaptive materials fully embracing the organic/inorganic interface. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939249
Title: HDR: DIRSE-IL:  Collaborative Research: Harnessing data advances in systems biology to design a biological 3D printer: the synthetic coral
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $358,816
ARRA Amount: $
Investigator(s): Jinkyu (JK) Yang jkyang@aa.washington.edu (Principal Investigator) 
Organization: University of Washington
4333 Brooklyn Ave NE, Seattle, WA 98195-0001, (206)543-4043
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: Corals are important natural resources that are key to the ocean's vast biodiversity and provide economic, cultural, and scientific benefits. As a result of human activities, locally and globally, coral reefs are declining rapidly. The complexity of corals makes conserving and restoring reefs very challenging. Corals are made up of thousands of different organisms, including the animal host and the algae, bacteria, viruses, and fungi that coexist as a so-called holobiont. Thus, corals are more like cities than individual animals, as they provide factories, housing, restaurants, nurseries, and more for an entire ecosystem. This project brings together experts in computer science, materials science, and biology to harness the data revolution in biology with machine learning to study how corals grow and function, when viewed as if they were manufacturing sites in the ocean. The study will focus on three key coral capabilities: (1) they create calcium carbonate skeletons that provide 3D structures for diverse sea life to live in, (2) they can heal damage to their tissues, and, (3) they live with the other organisms in a process referred to as symbiosis. Through these remarkable abilities, corals can 'print' resources for themselves and hundreds of thousands of other species, just like a 3D printer. The goal of this project is to understand these processes well enough to control them in the lab. This project may allow finding new ways to help coral survival, by deciphering the reasons why certain conditions damage them and find ways of repairing them. Furthermore, by synthetically growing corals, new types of materials may be identified for manufacturing. This project offers an opportunity to educate a diverse scientific workforce and the public by creating and disseminating the outcomes of a convergent research environment and will train postdoctoral researchers, graduate, and undergraduate students. Results of this research will be made available to the broader scientific community through web interfaces, peer-reviewed publications and workshops/conferences and shared with the public through outreach activities online, at schools, and public aquariums.<br/>    <br/>Through convergence of three disciplines, computer science, material science and biology, this project will provide a data-driven framework and toolset to learn from, control, engineer, and manufacture a combined form of living material, the 'synthetic coral', thereby opening new avenues for material synthesis and manufacturing. The research methodology will offer new analytical approaches to identify and quantify the parameters that govern coral growth and foster innovative new tools for controlling their growth. To understand the key functions of coral biology of biomineralization, wound healing, and symbiosis, this research will : (1) harness and analyze large amounts of coral '-omics' data to decipher critical molecules and their interactions for the aforementioned key functions, (2) experimentally validate the resulting predictions in coral individuals and cell lines, (3) manipulate the material properties of the calcium carbonate structures of the coral individuals and cell lines, and (4) test the biological and physical interactions in a network model of the 'synthetic coral'. This project develops and integrates fundamental building blocks that are essential for  an integrated computational and experimental validation system. Specifically, using machine learning, diverse data will be harnessed to identify physical conditions (e.g., surface characteristics), environmental conditions (e.g., temperature, pH), and key biological constituents (e.g., small molecule ligands and proteins encoded in the DNA) that are correlated to key structural and functional properties of the coral holobiont. These predicted conditions and molecules will be verified experimentally by perturbing individual coral nodes in a network of a 3D printed array of intact corals or their constituent cells and measuring their effects on the network of interactions and resulting structures. The results from this prediction-validation cycle will then be transferred back as input to manufacture novel adaptive materials fully embracing the organic/inorganic interface. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1924245
Title: HDR DSC: Collaborative Research: Connecting the Dots
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 17, 2019
Latest Amendment Date: April 12, 2021
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $402,053
ARRA Amount: $
Investigator(s): Ardie Walser walser@ccny.cuny.edu (Principal Investigator) Gilda Barabino (Former Principal Investigator) Akira Kawaguchi (Co-Principal Investigator) Michael Grossberg (Co-Principal Investigator) Ardie Walser (Former Co-Principal Investigator) 
Organization: CUNY City College
160 CONVENT AVE, NEW YORK, NY 10031-9101, (212)650-5418
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: There is significant demand for a workforce that is proficient in data science and analytics. Employers seek graduates with an ability to (1) understand, interpret, and analyze data, (2) effectively communicate results that stem from the analysis of data, (3) practice the ethical use of data, and (4) apply data science concepts to solve practical problems with real-world relevance. Data from job search sites indicate that the demand in New York State is particularly acute. A 2018 report from the National Academies of Sciences, Engineering, and Medicine entitled "Data Science for Undergraduates: Opportunities and Options" calls for institutions to advance the so-called "data acumen" of graduates. While the dissemination of data science competencies has been emphasized in some disciplines (e.g., computer science), the broad delivery of these skills to college graduates has been slow to evolve. The aim of this project is to develop and implement a scalable, innovative program, termed "Connecting the Dots", for delivery of data science competencies to students pursuing an undergraduate engineering degree.<br/><br/>Connecting the Dots (CTD) is a highly collaborative project between the flagships schools in the State University of New York (SUNY) system, the largest higher education system in the nation, and the City University of New York (CUNY) system. CTD teams the University at Buffalo (UB) with the City College of New York (CCNY) with the goals to (a) strengthen the ability to understand and use data effectively to inform decisions among diverse undergraduate students from across the engineering disciplines, while (b) simultaneously increasing the capacity of regional community partners to incorporate data analytical methods into their business or strategic planning objectives. The signature academic data science track to be created by the CTD project team is an undergraduate certificate program, the New York Data Science Scholars program, that is readily integrated with any engineering major and that complements existing computer science majors at both the undergraduate and graduate level. A broad range of community partners are served via novel Data Science Community Labs, which act as "pop-up" summer facilities on the UB and CCNY campuses wherein students perform internship projects for community partners who have challenging data science problems for students to work on, but are not well-positioned to host a conventional intern. The team's ultimate scaling objective is to develop a program that is easily adopted by other SUNY and CCNY campuses that host 4-year engineering programs and by campuses outside of New York State with similar degree program structures. <br/><br/>NSF's Harnessing the Data Revolution Data Science Corps program focuses on building capacity for harnessing the data revolution at the local, state, national, and international levels to help unleash the power of data in the service of science and society. Projects in this program are being jointly funded by the NSF's Harnessing the Data Revolution Big Idea; the Directorate for Computer and Information Science and Engineering, Division of Information and Intelligent Systems; the Directorate for Education and Human Resources, Division of Undergraduate Education; the Directorate for Mathematical and Physical Sciences, Division of Mathematical Sciences; and the Directorate for Social, Behavioral and Economic Sciences, Office of Multidisciplinary Activities and Division of Behavioral and Cognitive Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934548
Title: Collaborative Research: Knowledge Guided Machine Learning: A Framework for Accelerating Scientific Discovery
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 15, 2019
Latest Amendment Date: August 12, 2020
Award Instrument: Continuing Grant
Program Manager: Eva Zanzerkia
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $152,000
ARRA Amount: $
Investigator(s): Christopher Duffy cxd11@psu.edu (Principal Investigator) 
Organization: Pennsylvania State Univ University Park
201 Old Main, University Park, PA 16802-1503, (814)865-1372
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z
Program Element Code(s): 099Y
Abstract: The success of machine learning (ML) in many applications where large-scale data is available has led to a growing anticipation of similar accomplishments in scientific disciplines. The use of data science is particularly promising in scientific problems involving processes that are not completely understood. However, a purely data-driven approach to modeling a physical process can be problematic. For example, it can create a complex model that is neither generalizable beyond the data on which it was trained nor physically interpretable. This problem becomes worse when there is not enough training data, which is quite common in science and engineering domains.  A machine learning model that is grounded by explainable theories stands a better chance at safeguarding against learning spurious patterns from the data that lead to non-generalizable performance. This is especially important when dealing with problems that are critical and associated with high risks (e.g., extreme weather or collapse of an ecosystem).  Hence, neither an ML-only nor a scientific knowledge-only approach can be considered sufficient for knowledge discovery in complex scientific and engineering applications. This project is developing novel techniques to explore the continuum between knowledge-based and ML models, where both scientific knowledge and data are integrated synergistically. Such integrated methods have the potential for accelerating discovery in a range of scientific and engineering disciplines. This project will train interdisciplinary scientists who are well versed in such methods and will disseminate results of the project via peer-reviewed publications, open-source software, and a series of workshops to engage the broader scientific community.<br/><br/>This project aims to develop a framework that uses the unique capability of data science models to automatically learn patterns and models from data, without ignoring the treasure of accumulated scientific knowledge. Specifically, the project builds the foundations of knowledge-guided machine learning (KGML) by exploring several ways of bringing scientific knowledge and machine learning models together using pilot applications from four domains: aquatic ecodynamics, climate and weather, hydrology, and translational biology. These pilot applications were selected because they are at tipping points where knowledge-guided machine learning can have a transformative effect.  KGML has the potential for providing scientists and engineers with new insights into their domains of interest and will require the development of innovative new machine learning approaches and architectures that can incorporate scientific principles. Scientific knowledge, KGML methods, and software developed in this project could potentially be extended to a wide range of scientific applications where mechanistic (also known as process-based) models are used.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741166
Title: BIGDATA: IA: Collaborative Research: From Bytes to Watts - A Data Science Solution to Improve Wind Energy Reliability and Operation
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 15, 2017
Latest Amendment Date: October 19, 2017
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $274,999
ARRA Amount: $
Investigator(s): Eunshin Byon ebyon@umich.edu (Principal Investigator) 
Organization: Regents of the University of Michigan - Ann Arbor
503 THOMPSON ST, ANN ARBOR, MI 48109-1340, (734)763-6438
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 7433 8083 9102
Program Element Code(s): 8083
Abstract: The collective efforts in aerospace, civil, electrical, and mechanical engineering areas have led to remarkable progresses in wind energy. Larger turbines are designed and installed, and wind farms are nowadays built at locations where wind is even more intermittent and maintenance equipment is less accessible. This adds new challenges to ensuring operational reliability. To cope with these challenges, along with the rapid advancement in microelectronics, modern wind farms are equipped with a large number and variety of sensors, including, at the turbine level, anemometers, tachometers, accelerometers, thermometers, strain sensors, and power meters, and at the farm level, anemometers, vanes, sonars, thermometers, humidity meters, pressure meters, among others. It is worth noting that all these data are currently analyzed/utilized only in their respective domains. The big data challenges in this project include how to best use spatio-temporal data for wind forecast, how to use data of different nature (wind, power, load etc.) and data of different sources (physical data versus computer simulation data) for power production assessment in a computationally efficient manner, and finally how to integrate these three sets of solutions into a reliable and efficient computational platform. The proposed research and education activities will make a paradigm shift in the wind industry by demonstrating how dramatically data science innovations can benefit the industry. The PIs will disseminate the research findings through classroom teaching, journal/conference publications, industry workshops, and data/software sharing. The summer internship opportunities and undergraduate research help train the next generation workforce to be better versed with data science methodologies.<br/><br/>The critical barrier to cost effective wind power and its general adoption is partly rooted in wind stochasticity, severely complicating wind power production optimization and cost reduction. The long-term viability of wind energy hinges upon a good understanding of its production reliability, which is affected in turn by the predictability of wind and power productivity of wind turbines. Furthermore, the productivity of a wind turbine comprises two aspects: its ability of converting wind into power during its operation and the availability of wind turbines. Three inter-related research efforts will enhance wind energy reliability and productivity): (1) spatio-temporal analysis (for wind forecast) (2) conditional density estimation (for wind-to-power conversion assessment); and (3) importance sampling (for turbine reliability assessment and improvement). Significant data resourced provided by industry partners in the research, coupled with models and computational resources, will enable better prediction of wind profiles and utilization.  In addition, the team will develop dedicated reconfigurable field programmable gate array (FPGA) processors that will be 50 to 500 times faster than general-purpose CPUs for both on-site and central control processing and have small form-factor, low cost and energy efficient to enable agile development under severe outdoor conditions at wind farms.

Award Number: 1633271
Title: BIGDATA: Collaborative Research: F: Association Analysis of Big Graphs: Models, Algorithms and Applications
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 26, 2016
Latest Amendment Date: June 02, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2016
End Date: August 31, 2022
Awarded Amount to Date: $257,430
ARRA Amount: $
Investigator(s): Tingjian Ge ge@cs.uml.edu (Principal Investigator) 
Organization: University of Massachusetts Lowell
600 SUFFOLK ST STE 415, LOWELL, MA 01854-3643, (978)934-4170
NSF Directorate: CSE
Program(s): Robust Intelligence Big Data Science &Engineering 
Program Reference Code(s): 7433 8083
Program Element Code(s): 7495, 8083
Abstract: Association analysis is a fundamental problem in Big Data analytics. Emerging applications require computationally efficient association models and scalable association mining techniques to find regularities of graph data.  Conventional association analysis for transactional data is hard or infeasible to be adapted to effectively support the next generation of graph data analytics, especially under limited computing resources.  In this project, the PIs develop models, algorithms and tools to support association analysis over large-scale graph data under resource constraints.  The project formulates new variants of the conventional association model that are enhanced by advanced capability of graph queries. Both exact and approximate querying and mining paradigms are explored to support effective association analysis over multi-source, large-scale, and fast-changing graph data. The PIs instantiate the generic framework to two practical association analysis scenarios, notably, a) multi-graph association analysis, and b) association detection over graph streams. The project develops a package of distributed and stream association mining techniques supported by the proposed generic model and algorithms.<br/><br/>The enhanced model and algorithms enable scalable association analysis in a wide range of massive data applications. The principles learned from this project can be applied to big data analytics and system design in general. The study of new association analysis framework has immediate applications in emerging areas, including data quality, affinity marketing, and network security. Application collaborators of the project include Pacific Northwest National Laboratory, LogicMonitor, and Facebook. Broader impacts of the project also include research training and education of students including women and minorities, and design of new curricula and education tools that target both CS and non-CS students.

Award Number: 2140378
Title: Collaborative Research: Accelerating Synthetic Biology Discovery & Exploration through Knowledge Integration
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: August 31, 2021
Latest Amendment Date: August 31, 2021
Award Instrument: Standard Grant
Program Manager: Peter McCartney
Start Date: September 01, 2021
End Date: November 30, 2022
Awarded Amount to Date: $111,471
ARRA Amount: $
Investigator(s): Chris Myers chris.myers@colorado.edu (Principal Investigator) 
Organization: University of Colorado at Boulder
3100 MARINE ST STE 481 572 UCB, BOULDER, CO 80309-0001, (303)492-6221
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: The scientific challenge for this project is to accelerate discovery and exploration of the synthetic biology design space.  In particular, many parts used in synthetic biology come from or are initially tested in a simple bacteria, E. coli, but many potential applications in energy, agriculture, materials, and health require either different bacteria or higher level organisms (yeast for example). Currently, researchers use a trial-and-error approach because they cannot find reliable information about prior experiments with a given part of interest. This process simply cannot scale. Therefore, to achieve scale, a wide range of data must be harnessed to allow confidence to be determined about the likelihood of success. The quantity of data and the exponential increase in the publications generated by this field is creating a tipping point, but this data is not readily accessible to practitioners. To address this challenge, our multidisciplinary team of biological engineers, machine learning experts, data scientists, library scientists, and social scientists will build a knowledge system integrating disparate data and publication repositories in order to deliver effective and efficient access to collectively available information; doing so will enable expedited, knowledge-based synthetic biology design research.<br/><br/>This project will develop an open and integrated synthetic biology knowledge system (SBKS) that leverages existing data repositories and publications to create a single interface that transforms the way researchers access this information. Access to up-to-date information in multiple, heterogeneous sources will be provided via a federated approach. New methods based on machine learning will be developed to automatically generate ontology annotations in order to create connections between data in various repositories and information extracted from publications.  Provenance for each entity in SBKS will be tracked, and it will be utilized by new methods that are developed to assess bias and assign confidence scores to knowledge returned for each entity. An intuitive, natural-language-based interface and visualization functionality will be implemented for users to easily access and explore SBKS contents.  Additionally, as ethics is necessarily a part of synthetic biology research, data from text sources related to ethical concerns in synthetic biology will also be incorporated to inform researchers about ethical debates relevant to their search queries.  Finally, to test the SBKS API, a new genetic design tool, Kimera, will be developed that leverages the knowledge in SBKS to produce better designs.  The proposed SBKS will accelerate discovery and innovation by enabling researchers to learn from others' past experiences and to maximize the productivity of valuable experimental time on testing designs that have a higher likelihood of working when transformed to a new organism.  This research thus provides the potential for transformative research outcomes in the field of synthetic biology by leveraging data science to improve the field's epistemic culture. For more information please see https://synbioks.github.io.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939860
Title: Collaborative Research: Accelerating Synthetic Biology Discovery & Exploration through Knowledge Integration
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: September 17, 2019
Award Instrument: Standard Grant
Program Manager: Peter McCartney
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $204,148
ARRA Amount: $
Investigator(s): Eric Young emyoung@wpi.edu (Principal Investigator) 
Organization: Worcester Polytechnic Institute
100 INSTITUTE RD, WORCESTER, MA 01609-2247, (508)831-5000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu CYBERINFRASTRUCTURE 
Program Reference Code(s): 1165 7231
Program Element Code(s): 099Y, 7231
Abstract: The scientific challenge for this project is to accelerate discovery and exploration of the synthetic biology design space.  In particular, many parts used in synthetic biology come from or are initially tested in a simple bacteria, E. coli, but many potential applications in energy, agriculture, materials, and health require either different bacteria or higher level organisms (yeast for example). Currently, researchers use a trial-and-error approach because they cannot find reliable information about prior experiments with a given part of interest. This process simply cannot scale. Therefore, to achieve scale, a wide range of data must be harnessed to allow confidence to be determined about the likelihood of success. The quantity of data and the exponential increase in the publications generated by this field is creating a tipping point, but this data is not readily accessible to practitioners. To address this challenge, our multidisciplinary team of biological engineers, machine learning experts, data scientists, library scientists, and social scientists will build a knowledge system integrating disparate data and publication repositories in order to deliver effective and efficient access to collectively available information; doing so will enable expedited, knowledge-based synthetic biology design research.<br/><br/>This project will develop an open and integrated synthetic biology knowledge system (SBKS) that leverages existing data repositories and publications to create a single interface that transforms the way researchers access this information. Access to up-to-date information in multiple, heterogeneous sources will be provided via a federated approach. New methods based on machine learning will be developed to automatically generate ontology annotations in order to create connections between data in various repositories and information extracted from publications.  Provenance for each entity in SBKS will be tracked, and it will be utilized by new methods that are developed to assess bias and assign confidence scores to knowledge returned for each entity. An intuitive, natural-language-based interface and visualization functionality will be implemented for users to easily access and explore SBKS contents.  Additionally, as ethics is necessarily a part of synthetic biology research, data from text sources related to ethical concerns in synthetic biology will also be incorporated to inform researchers about ethical debates relevant to their search queries.  Finally, to test the SBKS API, a new genetic design tool, Kimera, will be developed that leverages the knowledge in SBKS to produce better designs.  The proposed SBKS will accelerate discovery and innovation by enabling researchers to learn from others' past experiences and to maximize the productivity of valuable experimental time on testing designs that have a higher likelihood of working when transformed to a new organism.  This research thus provides the potential for transformative research outcomes in the field of synthetic biology by leveraging data science to improve the field's epistemic culture. For more information please see https://synbioks.github.io.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Biological Infrastructure within the NSF Directorate of Directorate for Biological Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 2123329
Title: Collaborative Research: HDR DSC: The Metropolitan Chicago Data Science Corps (MCDC): Learning from Data to Support Communities
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 20, 2021
Latest Amendment Date: August 20, 2021
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: September 01, 2021
End Date: August 31, 2024
Awarded Amount to Date: $157,403
ARRA Amount: $
Investigator(s): Nadja Insel n-insel@neiu.edu (Principal Investigator) 
Organization: Northeastern Illinois University
5500 N ST LOUIS AVE, CHICAGO, IL 60625-4625, (773)442-4671
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu 
Program Reference Code(s): 062Z 9102
Program Element Code(s): 099Y
Abstract: Diverse experts from five universities in, or with a presence in, the Chicago area are collaborating as the Metropolitan Chicago Data-science Corps to 1) help local non-profit organizations take advantage of increasing data volume and data complexity, 2) train data science students in how to effectively apply their academic knowledge to real data challenges in the non-profit sector, 3) exchange data science curriculum and expertise among these universities and with local community colleges. An organization can submit a Request for Data Services (RDS) and receive help to develop it. MCDC particularly welcomes RDS in areas related to environment, health, and our social well-being. Each RDS is assigned to a team of students. Teams of students with a foundation in data science are formed within a practicum course or as part of a summer internship. MCDC will develop the practicum course, where each team has one or more expert mentors and forms a partnership with the requesting organization. At the end of the term, each team will deliver a solution to each of the requesting organizations.<br/><br/>MCDC is an interdisciplinary partnership between universities, myriad community organizations, and two expansion colleges and aims to strengthen the national data science workforce by integrating community needs with academic learning. By supporting infrastructure to unite diverse students and faculty across institutions and disciplines, by prioritizing the engagement of community, and embedding real-world team-based data science projects into the curriculum, the MCDC will be a uniquely powerful educational experience which will support societal progress. To realize this goal, existing curricula are grouped into multiple pathways to prepare a diverse range of students for participation in MCDC. MCDC students acquire both data acumen and societal knowledge that is intended to lead to a well-prepared and engaged workforce. The MCDC project directors combine extensive, proven, funded, and diverse expertise in curriculum development, inclusive learning practices, integrating real-world data into courses, learning systems, data science, as well as in health, social, and environmental sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1939992
Title: Collaborative Research: MEMONET: Understanding memory in neuronal networks through a brain-inspired spin-based artificial intelligence
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $399,550
ARRA Amount: $
Investigator(s): Ying Zhang yingzhang@uri.edu (Principal Investigator) 
Organization: University of Rhode Island
75 LOWER COLLEGE, KINGSTON, RI 02881-1974, (401)874-2635
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Information Technology Researc Info Integration & Informatics 
Program Reference Code(s): 062Z 9102 9150
Program Element Code(s): 099Y, 1640, 7364
Abstract: The brain is arguably the most sophisticated and the most efficient computational machine in the universe. The human brain, for example, comprises about 100 billion neurons that form an interconnected circuit with well over 100 trillion connections. Understanding how a multitude of brain functions emerge from the underlying neuronal circuit will give insights into the operating principles of the brain. In this award, a multidisciplinary team of systems biologist, computational biologist, material scientist, neuroscientist, and machine learning expert will work synergistically to leverage the data revolution in neuroscience to answer a fundamental question: How does the brain learn, store, and process information?  The team will develop and apply advanced data analysis algorithms to harness the great volume of neuronal data generated by the latest imaging and molecular profiling technologies, for elucidating the neuronal circuits driving brain functions. Computer simulations of a spin-electronic (spintronic) device will further serve as a platform to validate and emulate important operational characteristics of such neuronal circuits. The award sets the groundwork for an interdisciplinary data science research and educational program that will bring a new and powerful paradigm for studying brain functions as well as for designing transformative brain-inspired devices for information processing, data storage, computing, and decision making.<br/><br/>The project has a specific focus on an essential function of the brain: motor-skill learning. This function emerges from the underlying circuitry of neurons that governs the activities of molecular signal transmission and neuronal firing. Importantly, the neuronal circuit in a mammalian brain is highly plastic and dynamic, features that endow animals with the ability to respond to myriad external stimulations through learning. By harnessing the latest data revolution in neuronal imaging, single neuron molecular profiling, spintronic device simulation, network inference, and machine learning, a team of multidisciplinary investigators will be supported by this award to investigate the fundamental principle of neuronal circuit rewiring that drives brain?s learning function. More specifically, the team sets out to achieve the following specific tasks: (A) Infer learning-induced rewiring of large-scale neuronal networks from two-photon calcium imaging data through the development of novel and powerful network inference algorithms; (B) Build biochemical-based models of neuronal circuits by integrating molecular profiling with neuron firing and connectome dynamics; and (C) Develop a spintronic material network model that emulates learning and memory formation by exploiting the spin dynamics in spintronic materials. The project seeks to lay the foundation for the creation of an interdisciplinary data-intensive brain-to-materials initiative that will be applied to understand and emulate the operational principles of brain neuronal circuits underlying learning, cognition, memory formation, and other behaviors. The outcomes of the initiative will have a paramount impact on the society, not only in our understanding of the brain and its functions, but also in overcoming current bottlenecks of existing computing architectures.  This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940169
Title: HDR: DIRSE-IL: Collaborative Research: Harnessing data advances in systems biology to design a biological 3D printer: the synthetic coral
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Sylvia Spengler
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $494,014
ARRA Amount: $
Investigator(s): Judith Klein jkleinse@asu.edu (Principal Investigator) 
Organization: Colorado School of Mines
1500 ILLINOIS ST, GOLDEN, CO 80401-1887, (303)273-3000
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu Info Integration & Informatics 
Program Reference Code(s): 062Z 9102 9251
Program Element Code(s): 099Y, 7364
Abstract: Corals are important natural resources that are key to the ocean's vast biodiversity and provide economic, cultural, and scientific benefits. As a result of human activities, locally and globally, coral reefs are declining rapidly. The complexity of corals makes conserving and restoring reefs very challenging. Corals are made up of thousands of different organisms, including the animal host and the algae, bacteria, viruses, and fungi that coexist as a so-called holobiont. Thus, corals are more like cities than individual animals, as they provide factories, housing, restaurants, nurseries, and more for an entire ecosystem. This project brings together experts in computer science, materials science, and biology to harness the data revolution in biology with machine learning to study how corals grow and function, when viewed as if they were manufacturing sites in the ocean. The study will focus on three key coral capabilities: (1) they create calcium carbonate skeletons that provide 3D structures for diverse sea life to live in, (2) they can heal damage to their tissues, and, (3) they live with the other organisms in a process referred to as symbiosis. Through these remarkable abilities, corals can 'print' resources for themselves and hundreds of thousands of other species, just like a 3D printer. The goal of this project is to understand these processes well enough to control them in the lab. This project may allow finding new ways to help coral survival, by deciphering the reasons why certain conditions damage them and find ways of repairing them. Furthermore, by synthetically growing corals, new types of materials may be identified for manufacturing. This project offers an opportunity to educate a diverse scientific workforce and the public by creating and disseminating the outcomes of a convergent research environment and will train postdoctoral researchers, graduate, and undergraduate students. Results of this research will be made available to the broader scientific community through web interfaces, peer-reviewed publications and workshops/conferences and shared with the public through outreach activities online, at schools, and public aquariums.<br/>    <br/>Through convergence of three disciplines, computer science, material science and biology, this project will provide a data-driven framework and toolset to learn from, control, engineer, and manufacture a combined form of living material, the 'synthetic coral', thereby opening new avenues for material synthesis and manufacturing. The research methodology will offer new analytical approaches to identify and quantify the parameters that govern coral growth and foster innovative new tools for controlling their growth. To understand the key functions of coral biology of biomineralization, wound healing, and symbiosis, this research will : (1) harness and analyze large amounts of coral '-omics' data to decipher critical molecules and their interactions for the aforementioned key functions, (2) experimentally validate the resulting predictions in coral individuals and cell lines, (3) manipulate the material properties of the calcium carbonate structures of the coral individuals and cell lines, and (4) test the biological and physical interactions in a network model of the 'synthetic coral'. This project develops and integrates fundamental building blocks that are essential for  an integrated computational and experimental validation system. Specifically, using machine learning, diverse data will be harnessed to identify physical conditions (e.g., surface characteristics), environmental conditions (e.g., temperature, pH), and key biological constituents (e.g., small molecule ligands and proteins encoded in the DNA) that are correlated to key structural and functional properties of the coral holobiont. These predicted conditions and molecules will be verified experimentally by perturbing individual coral nodes in a network of a 3D printed array of intact corals or their constituent cells and measuring their effects on the network of interactions and resulting structures. The results from this prediction-validation cycle will then be transferred back as input to manufacture novel adaptive materials fully embracing the organic/inorganic interface. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1940188
Title: Collaborative Research: Atomic Level Structural Dynamics in Catalysts
NSF Org: OAC Office of Advanced Cyberinfrastructure (OAC)
Initial Amendment Date: September 17, 2019
Latest Amendment Date: October 15, 2020
Award Instrument: Continuing Grant
Program Manager: Pui Ho
Start Date: October 01, 2019
End Date: September 30, 2022
Awarded Amount to Date: $324,793
ARRA Amount: $
Investigator(s): Mahmoud Moradi moradi@uark.edu (Principal Investigator) 
Organization: University of Arkansas
1125 WEST MAPLE STE 210, FAYETTEVILLE, AR 72701-3124, (479)575-3845
NSF Directorate: CSE
Program(s): HDR-Harnessing the Data Revolu PROJECTS 
Program Reference Code(s): 062Z 9263
Program Element Code(s): 099Y, 1978
Abstract: Catalysts help make chemical reactions go faster and their development impact areas such as energy, the environment, biotechnology, and drug design. The vision of this project is to harness computational tools from modern statistics and machine learning to perform data-driven discovery of new catalysts. To this end, a collaborative team is assembled with the complementary expertise in catalysts, materials science, biophysics, computational modelling, statistics, signal processing, and data science. How a reaction is accelerated depends on the dynamic changes in the structure and shape of a catalyst and its associated chemical reactants (a catalytic system). The goal of this project is to explore, describe, and quantify the dynamic structures of enzyme and nanoparticle catalysts at the atomic level. Recent advances in microscopy and spectroscopy now make it possible to measure with great detail dynamic changes in time and in dimensional space. This project combines recent advances in data science with these new experimental tools to extract features that describe the dynamic behaviour of catalytic systems. In addition, the project will enhance the development of educational infrastructure for data-intensive and interdisciplinary science, contribute to workforce development, promote gender equality in the sciences, and disseminate scientific knowledge. <br/><br/>The guiding hypothesis of this research is that catalytic functionality cannot be fully understood without describing the atomic-level structural changes triggered by the molecular interactions of reactants with the catalyst. This hypothesis is tested by utilizing experimental datasets obtained from electron microscopy and single-molecule fluorescence resonance energy-transfer spectroscopy to explore structural dynamics in nanoparticles and enzymes. A data-analysis workflow, which integrates denoising, dimensionality reduction, clustering, and dynamic Markovian modelling, enables descriptions and classifications of the complex dynamical evolutions in spatiotemporally resolved measurements. The research develops and applies advanced methodologies to process noisy, high-dimensional data - a crucial bottleneck for the analysis of dynamic systems. The information extracted from experimental data guides the computational sampling of the conformational space of proteins and nanoparticles within a statistical physics framework, using supercomputer technology. This information facilitates the development of physical models that probe phenomena that are currently experimentally inaccessible, such as picosecond nuclear motions, as well as protein conformational changes and their coupling with chemical events. The transformative impact is to better understand catalysis by establishing a link between dynamic system response and catalytic functionality. The computational approaches developed through this project have the potential to be generally applied to many fundamental problems in materials science and structural biology where dynamic behaviours are important.<br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity, and is jointly supported by the HDR and the Division of Chemistry within the NSF Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1934960
Title: HDR TRIPODS: FINPenn: Center for the Foundations of Information Processing at the University of Pennsylvania
NSF Org: CCF Division of Computing and Communication Foundations
Initial Amendment Date: September 11, 2019
Latest Amendment Date: August 11, 2021
Award Instrument: Continuing Grant
Program Manager: Christopher Stark
Start Date: September 01, 2019
End Date: August 31, 2022
Awarded Amount to Date: $1,500,000
ARRA Amount: $
Investigator(s): Alejandro Ribeiro aribeiro@seas.upenn.edu (Principal Investigator) Saswati Sarkar (Co-Principal Investigator) EDGAR DOBRIBAN (Co-Principal Investigator) Robert Ghrist (Co-Principal Investigator) Kostas Daniilidis (Co-Principal Investigator) 
Organization: University of Pennsylvania
3451 WALNUT ST STE 440A, PHILADELPHIA, PA 19104-6205, (215)898-7293
NSF Directorate: CSE
Program(s): TRIPODS Transdisciplinary Rese HDR-Harnessing the Data Revolu 
Program Reference Code(s): 047Z 062Z
Program Element Code(s): 041Y, 099Y
Abstract: Recent advances in artificial intelligence have led to significant progress in our ability to extract information from images and time sequences. Maintaining this rate of progress hinges upon attaining equally significant results in the processing of more complex signals such as those that are acquired by autonomous systems and networks of connected devices, or those that arise in the study of complex biological and social systems. This award establishes FINPenn, the Center for the Foundations of Information Processing at the University of Pennsylvania. The focus of the center is to establish fundamental theory to enable the study of data beyond time and images. The center's premise is that humans' rich intuitive understanding of space and time may not necessarily be applicable to the processing of complex signals. Therefore, matching the success in time and space necessitates the discovery and development of foundational principles to guide the design of generic artificial intelligence algorithms.  FINPenn will support a class of scholar trainees along with a class of visiting postdocs and students to advance this agenda. The center will engage the community through the organization of workshops and lectures and will disseminate knowledge with onsite and online educational activities at the undergraduate and graduate level.<br/><br/>FINPenn builds on two observations: (i) To understand the foundations of data science it is necessary to succeed beyond Euclidean signals in time and space. This is true even to understand the foundations for Euclidean signal processing. (ii) Humans live in Euclidean time and space. To succeed in information processing beyond signals with Euclidean structure, operation from foundational principles is necessary because human intuition is of limited help. For instance, convolutional neural networks have found success in the processing of images and signals in time but they rely heavily on spatial and temporal intuition. To generalize their success to unconventional signal domains it is necessary to postulate fundamental principles and generalize from those principles. If the generalizations are successful they not only illuminate the new application domains but they also help establish the validity of the postulated principles for Euclidean spaces in the tradition of predictive science.  The proposers further contend that the foundational principles of data sciences are to be found in the exploitation of structure and the associated invariances and symmetries that structure generates. The initial focus of the center is in advancing the theory of information processing in signals whose structure is defined by a group, a graph, or a topology. These three types of signals generate three foundational research directions which build on the particular strengths of the University of Pennsylvania on network sciences, robotics, and autonomous systems which are areas in which these types of signals appear often. <br/><br/>This project is part of the National Science Foundation's Harnessing the Data Revolution (HDR) Big Idea activity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838248
Title: BIGDATA: F: Collaborative Research: Optimizing Log-Structured-Merge-Based Big Data Management Systems
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 08, 2018
Latest Amendment Date: September 08, 2018
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $604,836
ARRA Amount: $
Investigator(s): Michael Carey mjcarey@ics.uci.edu (Principal Investigator) 
Organization: University of California-Irvine
141 INNOVATION DR STE 250, IRVINE, CA 92617-3213, (949)824-7295
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: Modern big data management systems support fast read and write operations based on the unique identifier (key) of a record. That is, they are fast when inserting key-value pairs, and given a key they quickly return the value associated with that key. To do so, most such systems rely on a Log-Structured-Merge Tree (LSM) structure that batches writes together before writing them to persistent storage. This project will study how to efficiently support more sophisticated operations on LSM-based storage systems, that is, operations that do not simply specify the key of a record. Examples of such operations include searching for records based instead on their location or time. By optimizing the storage and management of big data, this project has the potential to cut the storage costs and energy consumption in data centers. Further, the successful completion of this work will allow users to manage more data with the existing hardware infrastructure, which is critical given the new wave of big data being generated by sensors and the Internet-of-Things.  The project will capitalize on the student diversity at two Hispanic Serving Institutions, and thus broaden the participation of under-represented groups in the research process.<br/><br/>To support richer data modeling and querying capabilities on top of LSM key-value stores, this project will develop novel LSM indexing and access algorithms to support query plans that utilize both primary and secondary LSM components. In addition, it will design and evaluate flow control policies to dampen or eliminate the notoriously bursty data ingestion behavior that LSM-based storage structures exhibit. It will also study how to automatically and dynamically change LSM compaction policies and parameters based on the query workload. Data-semantics-aware compaction techniques will also be studied. The project will additionally develop novel LSM-aware query optimization techniques; the LSM storage layer is currently treated as a black box by most query optimizers. The planned methods will be deployed and evaluated on the open source Apache AsterixDB system.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1838022
Title: BIGDATA: IA: Collaborative Research: Protecting Yourself from Wildfire Smoke: Big Data-Driven Adaptive Air Quality Prediction Methodologies
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: September 07, 2018
Latest Amendment Date: August 27, 2019
Award Instrument: Standard Grant
Program Manager: Sylvia Spengler
Start Date: January 01, 2019
End Date: December 31, 2022
Awarded Amount to Date: $357,987
ARRA Amount: $
Investigator(s): Evgenia Smirni esmirni@cs.wm.edu (Principal Investigator) 
Organization: College of William and Mary
261 RICHMOND RD, WILLIAMSBURG, VA 23185-4042, (757)221-3965
NSF Directorate: CSE
Program(s): Big Data Science &Engineering 
Program Reference Code(s): 062Z 8083
Program Element Code(s): 8083
Abstract: The objective of this project is to develop a framework to achieve real-time smoke transport prediction and air quality forecasting.  Wildfire smoke can transport very fast and pose significant health hazards to communities.  State-of-the-art smoke forecasting models typically have infrequent updates and provide predictions with a coarse spatial resolution due to spatiotemporal resolution limitations of input data and the tremendous computational power required to simulate atmospheric conditions.  This project will develop real-time smoke transport and air quality prediction methodologies with better spatial resolution for improving the scalability and efficiency of the underlying data processing system to enable timely air quality alerts.  While this project is applied towards smoke transport and air quality prediction, this work can be generalized to solve many other big data problems that require such design. The principal investigators will use the materials and topics from this project to enhance education by creating new big data analytics related courses and developing a Big Data Minor program at the University of Nevada, Reno.  The project will also provide opportunities to engage more students from underrepresented groups and impact the education of several students, via K-12 outreach and mentoring undergraduate and graduate students.<br/><br/>The intellectual merit of this research is in establishing a novel big data driven air quality prediction for wildfire smoke to provide timely and effective health alerts. The planned new prediction methodology will integrate the novel Gaussian Markov Random Field based real-time spatiotemporal prediction with statistical-based long-term spatiotemporal prediction. To tackle the challenge of missing high-resolution data, a data fusion methodology is planned to integrate fine-grained image data collected from camera networks with air pollution monitoring data to increase data resolution. A Deep Neural Network based smoke density detection process will extract air quality information from camera image data. The planned novel signature time-series based prediction methodology will open opportunities to process larger amounts of spatiotemporal data using limited resources. By identifying critical data based on spatiotemporal properties, the project will develop a communication framework that enables efficient camera data transfer. Efficient parallel and distributed data processing is utterly important to support processing large scale data in real time. The planned decomposition-based parallelization methodology and a performance model driven scheduling framework will enable efficient dynamic computing resource management, which is key to the success of this project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.

Award Number: 1741040
Title: BIGDATA: IA: Collaborative Research: In Situ Data Analytics for Next Generation Molecular Dynamics Workflows
NSF Org: IIS Div Of Information & Intelligent Systems
Initial Amendment Date: August 30, 2017
Latest Amendment Date: August 26, 2021
Award Instrument: Standard Grant
Program Manager: Almadena Chtchelkanova
Start Date: October 01, 2017
End Date: September 30, 2022
Awarded Amount to Date: $616,000
ARRA Amount: $
Investigator(s): Ewa Deelman deelman@isi.edu (Principal Investigator) Rafael Ferreira da Silva (Former Principal Investigator) Ewa Deelman (Former Co-Principal Investigator) 
Organization: University of Southern California
3720 S FLOWER ST FL 3, LOS ANGELES, CA 90007-4304, (213)740-7762
NSF Directorate: CSE
Program(s): Software & Hardware Foundation Big Data Science &Engineering 
Program Reference Code(s): 7433 7924 7942 8083
Program Element Code(s): 7798, 8083
Abstract: Molecular dynamics simulations studying the classical time evolution of a molecular system at atomic resolution are widely recognized in the fields of chemistry, material sciences, molecular biology and drug design; these simulations are one of the most common simulations on supercomputers.  Next-generation supercomputers will have dramatically higher performance than do current systems, generating more data that needs to be analyzed (i.e., in terms of number and length of molecular dynamics trajectories). The coordination of data generation and analysis cannot rely on manual, centralized approaches as it does now.  This interdisciplinary project integrates research from various areas across programs such as computer science, structural molecular biosciences, and high performance computing to transform the centralized nature of the molecular dynamics analysis into a distributed approach that is predominantly performed in situ. Specifically, this effort combines machine learning and data analytics approaches, workflow management methods, and high performance computing techniques to analyze molecular dynamics data as it is generated, save to disk only what is really needed for future analysis, and annotate molecular dynamics trajectories to drive the next steps in increasingly complex simulations' workflows. <br/><br/>The investigators tackle the data challenge of data analysis of molecular dynamics simulations on the next-generation supercomputers by (1) creating new in situ methods to trace molecular events such as conformational changes, phase transitions, or binding events in molecular dynamics simulations at runtime by locally reducing knowledge on high-dimensional molecular organization into a set of relevant structural molecular properties; (2) designing new data representations and extend unsupervised machine learning techniques to accurately and efficiently build an explicit global organization of structural and temporal molecular properties; (3) integrating simulation and analytics into complex workflows for runtime detection of changes in structural and temporal molecular properties; and (4) developing new curriculum material, online courses, and online training material targeting data analytics. The project's harnessed knowledge of molecular structures' transformations at runtime can be used to steer simulations to more promising areas of the simulation space, identify the data that should be written to congested parallel file systems, and index generated data for retrieval and post-simulation analysis. Supported by this knowledge, molecular dynamics workflows such as replica exchange simulations, Markov state models, and the string method with swarms of trajectories can be executed ?from the outside? (i.e., without reengineering the molecular dynamics code).

