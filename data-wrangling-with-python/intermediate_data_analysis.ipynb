{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis with Python & pandas"
      ],
      "metadata": {
        "id": "UyitAvaNS6XE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "\n",
        "- Explore real-world data with Python\n",
        "- Practice using the popular pandas library to work with a tabular dataset\n",
        "- Perform basic data cleanup and manipulation\n",
        "- Perform basic analysis & visualization of a dataset"
      ],
      "metadata": {
        "id": "mWkdExmdS_Hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The dataset\n",
        "\n",
        "- We'll be using a dataset from the US Bureau of Labor Statistics: the Consumer Price Index (CPI). The [CPI](https://www.bls.gov/cpi/) is  used to measure inflation across a wide spectrum of goods and services. \n",
        "\n",
        "- We'll be interacting with CPI data through a series of [text tables](https://download.bls.gov/pub/time.series/cu/), which are suitable for use with tools like Python.\n",
        "\n",
        "- There are several files in this directory. Today we'll work with the file called `cu.data.0.Current`."
      ],
      "metadata": {
        "id": "71vsu0u6U_x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### exercise\n",
        "-----\n",
        "Open the [Current file](https://download.bls.gov/pub/time.series/cu/cu.data.0.Current) in your browser and take a few moments to inspect the format. \n",
        "\n",
        "\n",
        "\n",
        "1.   How is it structured/organized?\n",
        "2.   What additional information do you need to interpret this dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "rTTnUrqYYHum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing the pandas library\n",
        "\n",
        "- The pandas library is a third-party, open-source Python library. It's modeled on functionality from the R language, particularly on R's DataFrame object. The pandas library gives us a way to use R-type DataFrames in Python.\n",
        "\n",
        "- Pandas is also highly optimized, so working with large datasets, so it's performance is generally much better than Python code you or I could write on our own. \n",
        "\n",
        "- The pandas library is already installed in a Google Colab environment. But because it's an external library, we have to import pandas into our Python session before we can use it. "
      ],
      "metadata": {
        "id": "Ck2kgFIDT1mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "q5BicPI5kCyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the CPI data file\n",
        "\n",
        "- When loading a data file, it's important to understand the format.\n",
        "\n",
        "- The CPI `Current` file is plain text, but it's separated into columns. \n",
        "\n",
        "- The generic term for this kind of file is **CSV** (comma-separated values).\n",
        "\n",
        "- Pandas has a `read_csv` [method](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) we can use to load files of this type."
      ],
      "metadata": {
        "id": "BG8F_UIydq51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQF0MlzShbOo"
      },
      "outputs": [],
      "source": [
        "# All Urban Consumers (Current Series)\n",
        "all_items_url = 'https://download.bls.gov/pub/time.series/cu/cu.data.0.Current'\n",
        "all_items = pd.read_csv(all_items_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_items = pd.read_csv(all_items_url, sep='\\s+')"
      ],
      "metadata": {
        "id": "4XVLDvBfhzmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame Basics: Rows & Columns\n",
        "\n",
        "- Just as in a spreadsheet, a DataFrame allows us to work with rows and/or columns of data.\n",
        "\n",
        "- In pandas, this is called **slicing**.\n",
        "\n",
        "#### exercise\n",
        "-------\n",
        "\n",
        "Run the following cells and see if you can determine what each command is doing.\n"
      ],
      "metadata": {
        "id": "oRKFuqXjh22I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_items['series_id']"
      ],
      "metadata": {
        "id": "Vw9m22zVitPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_items[['series_id', 'period', 'value']]"
      ],
      "metadata": {
        "id": "5TiRAXejixlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_items.loc[0:10]"
      ],
      "metadata": {
        "id": "B1z8cEg9i5bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_items.loc[99:500, ['series_id', 'year']]"
      ],
      "metadata": {
        "id": "6COgN-R_i8vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_items.year.max(), all_items.year.min()"
      ],
      "metadata": {
        "id": "5kwmN8B-yYvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering DataFrames\n",
        "\n",
        "- In a spreadsheet, we often filter the rows by values in particular columns.\n",
        "\n",
        "- We can do the same in pandas, but the syntax is actually much more flexible (as we'll see)."
      ],
      "metadata": {
        "id": "z6ANIoQejgRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To find rows for a particular year\n",
        "all_items.loc[all_items.year == 2020]"
      ],
      "metadata": {
        "id": "zjgT2PJOkJhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To find rows where the year is greater than a certain value\n",
        "all_items.loc[all_items.year > 2000]"
      ],
      "metadata": {
        "id": "1QcKYO5qkg86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To find rows where the series_id contains a certain item code\n",
        "all_items.loc[all_items.series_id.str.contains('SEEB')]"
      ],
      "metadata": {
        "id": "ZxUzzw0Bkqal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Columns\n",
        "\n",
        "- Before we get into our analysis, let's make the data easier to work with.\n",
        "\n",
        "- The `series_id` column actually contains multiple pieces of information.\n",
        "\n",
        "#### exercise\n",
        "-----\n",
        "Using the [documentation](https://download.bls.gov/pub/time.series/cu/cu.txt), can you figure out how to parse the `series_id` values into their components? "
      ],
      "metadata": {
        "id": "s7MZgno5lGT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all_items['survey_code'] = all_items.series_id.str[:]\n",
        "#all_items['seasonal_code'] = all_items.series_id.str[:]\n",
        "#all_items['periodicity_code'] = all_items.series_id.str[:]\n",
        "#all_items['area_code'] = all_items.series_id.str[:]\n",
        "#all_items['item_code'] = all_items.series_id.str[:]"
      ],
      "metadata": {
        "id": "SWHF7P8dm4e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Summarizing DataFrames\n",
        "\n",
        "- The CPI is time-series data, consisting of values for various kinds of goods & services (items), across various geographic regions, at discrete moments in time.\n",
        "\n",
        "- An initial question we might pose: are these data points distributed uniformly? In other words, are all items and regions represented across the entire time span? \n",
        "\n",
        "- To answer this question, we can use a powerful feature of pandas called `groupby`. \n",
        "\n",
        "- The `groupby` method allows you to perform the same operation across subsets of your data.\n",
        "\n",
        "- A prime use for it is summarizing data by subset."
      ],
      "metadata": {
        "id": "_O59iseUnfBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the range of years?\n",
        "all_items.year.unique()"
      ],
      "metadata": {
        "id": "pLEauRWtraI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many different item groups are represented?\n",
        "all_items.item_code.unique().size"
      ],
      "metadata": {
        "id": "0PI5JZ6ukJj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many observations are there per item code?\n",
        "all_items.groupby('item_code').size()"
      ],
      "metadata": {
        "id": "JcuvHQkjrye0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many different items have data each year?\n",
        "all_items.groupby('year').item_code.apply(lambda x: x.unique().size)"
      ],
      "metadata": {
        "id": "THDA1iI8umxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### exercise\n",
        "----\n",
        "See if you can write some code to determine whether all the regions (area codes) are covered for all years (regardless of item)."
      ],
      "metadata": {
        "id": "4UlF0IKmxSFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering by Groups\n",
        "\n",
        "\n",
        "- The `groupby` method can be used in conjunction with the `filter` method to filter our dataset by groups.\n",
        "\n",
        "- The `filter` method applies a condition to each group and returns data only from groups where the condition evaluates to `True`.\n",
        "\n",
        "- We can supply a condition to `filter` using the `lambda` syntax we saw above.\n",
        "\n",
        "- We've seen that CPI data is not consistent for all item types across all years and regions/areas. How can we analyze data for only those items that have a CPI calculated for all years, 1997-2022?\n"
      ],
      "metadata": {
        "id": "Ee9J7PSSyliF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine how many unique years are in the dataset\n",
        "num_years = all_items.year.unique().size"
      ],
      "metadata": {
        "id": "wA3YurziCVrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's isolate a single area to make sure our data is consistent\n",
        "# 0000 is the code for U.S. city average, so let's use that one\n",
        "us_items = all_items.loc[all_items.area_code == '0000'].copy()"
      ],
      "metadata": {
        "id": "oaAAMLQMDrVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to make sure our data is consistent, let's also limit by periodicity and seasonality\n",
        "us_items = us_items.loc[(us_items.periodicity_code == 'R') & (us_items.seasonal_code == 'U')].copy()"
      ],
      "metadata": {
        "id": "81eVsM03J7RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# within each item group, determine if the number of unique years matches the number across the whole dataset\n",
        "complete_items = us_items.groupby('item_code').filter(lambda x: x.year.unique().size == num_years)"
      ],
      "metadata": {
        "id": "KR5gKBfIdilH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have a slightly smaller set of items than we started with\n",
        "complete_items.item_code.unique().size"
      ],
      "metadata": {
        "id": "GbC_Hz9mDmK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering one DataFrame by another\n",
        "\n",
        "Often we'll want to work with data that are spread across multiple tables. The pandas library includes functionality to make that easier.\n",
        "\n",
        "- The CPI file we've been using has codes to represent items. \n",
        "\n",
        "- To understand which items are included, we can download an additional file provided by the Bureau of Labor Statistics, which maps each item code to its descriptions. \n",
        "\n",
        "- Since we've filtered our dataset to exclude certain items, we can filter this secondary dataset using elements from our `complete_items` DataFrame."
      ],
      "metadata": {
        "id": "b4Nm8y1dFzAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can load the item description table same as we did with the CPI table above\n",
        "items_desc_url = 'https://download.bls.gov/pub/time.series/cu/cu.item'\n",
        "items_desc = pd.read_csv(items_desc_url, sep='\\t')"
      ],
      "metadata": {
        "id": "-ulEV-suXVUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We've seen how to access the unique item codes in our complete_items DataFrame\n",
        "item_codes = complete_items.item_code.unique()"
      ],
      "metadata": {
        "id": "ewXduFRmY8ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can use .loc together with the .isin method to filter the item descriptions to just those item codes\n",
        "item_desc_keep = items_desc.loc[items_desc.item_code.isin(item_codes)]"
      ],
      "metadata": {
        "id": "g-HE9zTFZNXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can export this new, filtered table of item descriptions and review it in a spreadsheet\n",
        "item_desc_keep.to_csv('filtered-item-table.csv', index=False)"
      ],
      "metadata": {
        "id": "9wzi71e6aRAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### exercise\n",
        "-----\n",
        "\n",
        "Pick a handful of items from the CSV file (spreadsheet) you downloaded to include in your analysis. This file represents only those items with CPI values for the complete time span (1997-2022) of this dataset. \n",
        "\n",
        "Create a Python list of your chosen item codes below."
      ],
      "metadata": {
        "id": "a7f285JCanoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#my_codes = []"
      ],
      "metadata": {
        "id": "ylWaSglb10T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can filter our complete_items DataFrame by our selected codes\n",
        "my_items = complete_items.loc[complete_items.item_code.isin(my_codes)].copy()"
      ],
      "metadata": {
        "id": "iKpg0N7ncOmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with time series data\n",
        "\n",
        "- CPI data is calculated monthly. \n",
        "\n",
        "- Our dataset (`my_items`) indicates the date by the combination of two columns: the `year` and the `period`, which can be either a month code or a seasonal code. \n",
        "\n",
        "- Multiple time scales are present in this dataset.\n",
        "\n",
        "- In order to do consistent analyes, we should pick a particular time scale and discard the other data points.\n",
        "\n",
        "- In what follows, we'll isolate the month-level data and combine the month code and year columns to create a proper date element."
      ],
      "metadata": {
        "id": "TYqr7Y4wch9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### exercise\n",
        "----\n",
        "Can you describe -- logically, not in terms of Python syntax -- how we can combine the values in the `period` and `year` columns to create a date value?"
      ],
      "metadata": {
        "id": "_ROALrzreY6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove annual average and semiannual values\n",
        "my_items = my_items.loc[~my_items.period.isin(['M13', 'S01', 'S02', 'S03'])].copy()"
      ],
      "metadata": {
        "id": "-C24zkHi11MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a datetime column in four steps\n",
        "# 1.\n",
        "# 2.\n",
        "# 3.\n",
        "# 4.\n"
      ],
      "metadata": {
        "id": "pz8yO-ZD2rXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping DataFrames\n",
        "\n",
        "- Now that we've cleaned up our data sample and created a Python datetime column, we can analyze it as a timeseries.\n",
        "\n",
        "- The CPI values in the `value` column don't reflect actual prices; rather, they index change from one period to the next.\n",
        "\n",
        "- Generally, it's easier to compare the CPI between different kinds of items by looking at the _percentage change_ over time. \n",
        "\n",
        "- Pandas has a built-in method for calculating this metric. Let's use it to plot the percentage change for the items in in our sample.\n",
        "\n",
        "- We'll also change the shape of our DataFrame to make it easier to plot."
      ],
      "metadata": {
        "id": "lfFDz9omFzJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We're interested in the percentage change in CPI for each item, so we need to use groupby again\n",
        "# We'll reassign the result to a new column\n",
        "my_items['pct_change'] = my_items.groupby('item_code').value.pct_change()"
      ],
      "metadata": {
        "id": "FU9pbX73HC3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a DataFrame with the item values side by side, we can use the .pivot method\n",
        "my_items_pivot = my_items.pivot(index='month', columns='item_code', values='pct_change')"
      ],
      "metadata": {
        "id": "s-HaU3JlItv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing DataFrames\n",
        "\n",
        "- There are lots of options when it comes to data visualization with Python.\n",
        "\n",
        "- A very commonly used library is called [matplotlib](https://matplotlib.org/). \n",
        "\n",
        "- pandas has some matplotlib functionality embedded into its DataFrame API."
      ],
      "metadata": {
        "id": "9LXcTvLm6vSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can make a basic line graph comparing the rate of change in the CPI over time for our sample of items \n",
        "# just by calling the plot() method\n",
        "my_items_pivot.plot()"
      ],
      "metadata": {
        "id": "DRSborb6LKLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customizing matplotlib plots\n",
        "\n",
        "- Matplotlib plots are highly customizable.\n",
        "\n",
        "- Let's look at a few of the settings that can make our plot more legible.\n",
        "\n",
        "  - We can make our plot bigger with the `figsize` argument.\n",
        "  - We can give our plot a title and change the units on the Y axes to show percentages out of 100 (rather than 1)\n",
        "  - We can improve our legend by supplying the actual names of the items measured, rather than their codes."
      ],
      "metadata": {
        "id": "njFXYejChwrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after pivoting our DataFrame, the item codes are now the names of the columns\n",
        "my_items_pivot.columns"
      ],
      "metadata": {
        "id": "42s3eHhzRVHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the column names to select the rows from our table of item descriptions that contain the names of these items\n",
        "# To do that, we first need to make the item_code column the INDEX of the item_desc_keep DataFrame\n",
        "item_desc_keep = item_desc_keep.set_index('item_code')"
      ],
      "metadata": {
        "id": "2ymKA328Vnp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can filter the index of that DataFrame by the column names in our pivot DataFrame\n",
        "# We're filtering by the names of the columns, not their values\n",
        "my_item_desc = item_desc_keep.loc[my_items_pivot.columns]"
      ],
      "metadata": {
        "id": "R-tH2-lEWA9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we can rename the columns on our pivot DataFrame, using the item_name column on the filtered\n",
        "# DataFrame of item descriptions\n",
        "my_items_pivot.columns = my_items_desc.item_name"
      ],
      "metadata": {
        "id": "JHvTekj7T0Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To change the units on the axis, we need access to something called a tick formatter\n",
        "# This functionality lives in a separate matplotlib module, which we need to import\n",
        "import matplotlib.ticker as mtick"
      ],
      "metadata": {
        "id": "Ecb0EhqGW_Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set the figure size and assign the return value of plot to a new variable\n",
        "ax = my_items_pivot.plot(figsize=(20, 6))\n",
        "# Our ax variable now gives us access to special matplotlib formatting methods\n",
        "# We can use set_title to set the plot title\n",
        "ax.set_title('CPI percent change, 1997-2022')\n",
        "# mtick.PercentFormatter(1.0) instructs matplotib to format values as percentages, using the argument (1.0) as the denominator\n",
        "# in calculating the percentage\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
      ],
      "metadata": {
        "id": "PP6PrGy7iea8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}