{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Python\n",
    "Fall 2021\n",
    "\n",
    "In this workshop, we'll dive deep into some techniques for cleaning and re-shaping data in Python using the [pandas](https://pandas.pydata.org/docs/) library. \n",
    "\n",
    "Here's what you can expect to practice:\n",
    " - working with CSV data from various sources\n",
    " - reshaping data for analysis\n",
    " - joining datasets on common elements\n",
    " - handling text and time series data\n",
    " - dealing with nulls and duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research question\n",
    "\n",
    "Calculate change in US home prices over a five-year period, using the Zillow Home Value Index, and compare with change in median household income. Identify regions where the two measures diverge.\n",
    "\n",
    "## Data sources\n",
    "\n",
    " - [Zillow Home Value Index](https://www.zillow.com/research/data/): \"A smoothed, seasonally adjusted measure of the typical home value and market changes across a given region and housing type. It reflects the typical value for homes in the 35th to 65th percentile range.\"\n",
    " - [US Census, American Community Survey](https://www.census.gov/programs-surveys/acs) data for median household income over the previous 12 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "\n",
    "### Library imports\n",
    "\n",
    "Let's import any libraries we'll need. \n",
    "\n",
    "We'll do most of our work in `pandas`, which should be available automatically in a Google Colab environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use a library that simplifies the process of retrieving Census data. We may need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census import Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links & API registration\n",
    "\n",
    "At this time, you should also [register for an API key](https://api.census.gov/data/key_signup.html) so as to be able to retrieve datasets from census.gov. Once you have completed the form, you should receive your API key at the email address you provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following link will allows us to download Zillow Home Value Index (ZVHI) data. The data covers the time period between January 2000 and August 2021. Values are aggregated at the level of the zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi_all_homes = 'https://files.zillowstatic.com/research/public_csvs/zhvi/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv?t=1631541070'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & exploring data\n",
    "\n",
    "### Loading data from CSV\n",
    "\n",
    "The pandas `read_csv` method can load data from a URL as well as a file, provided the data is in the proper format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi_df = pd.read_csv(zhvi_all_homes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data\n",
    "\n",
    "If we look at the DataFrame's columns, we can see that each month is represented by a discrete column heading, leading to a very wide table. This is done to compress the data to save storage space. (The names of the months appear only once, in the column headings.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName',\n",
       "       'State', 'City', 'Metro', 'CountyName', '2000-01-31',\n",
       "       ...\n",
       "       '2020-11-30', '2020-12-31', '2021-01-31', '2021-02-28', '2021-03-31',\n",
       "       '2021-04-30', '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31'],\n",
       "      dtype='object', length=269)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhvi_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table has 30K+ rows, one row per zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zhvi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analysis, it's often easier to work with data in so-called \"long\" format. Meaning that each row corresponds to a single observation. \n",
    "\n",
    "An observation is a specific measure of one or more variables. In this dataset, we have basically two variables: time and location (zip code). So how can we re-shape this data so that each row contains a single value for ZHVI? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has a handy method called `melt`, which is useful when you have several columns that all contain the same **kind** of measure. Here, each of the month columns contains the same measure, i.e., the ZHVI values for that month. So we can \"melt\" this table so that all the ZHVI values are in one column, and all the months in another. \n",
    "\n",
    "And what about the geographical columns? We will retain those, making them what pandas calls \"ID variables\" -- the idea being that the combination of those columns creates a set of unique identifiers. In this case, that's the geographical location identified by zip code. \n",
    "\n",
    "In the following method call, I'm referring to the geographical columns by position, which I can do since they precede all of the month columns, by slicing the DataFrame's `columns` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df = zhvi_df.melt(id_vars=zhvi_df.columns[0:9], var_name='month', value_name='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset is much bigger, though it has exactly the same data! But the new shape will make it easier to group our data and filter it in different way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7935980"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting data types\n",
    "\n",
    "It's useful to make sure the datatypes in your DataFrame make sense for what they represent. In this case, our zip codes should be strings, our values floats, and our months datetime objects.\n",
    "\n",
    "The `dtypes` property displays the type of each column. In pandas, a type of `object` is either for a column of strings or of mixed data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID        int64\n",
       "SizeRank        int64\n",
       "RegionName      int64\n",
       "RegionType     object\n",
       "StateName      object\n",
       "State          object\n",
       "City           object\n",
       "Metro          object\n",
       "CountyName     object\n",
       "month          object\n",
       "value         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding strings \n",
    "\n",
    "Let's convert the zip code fields to strings. One thing you might notice is that by treating the zip code (`RegionName`) as an integer, pandas has truncated zip codes that begin with zero. That could pose problems later, if we want to match this data against other data using the zip code. \n",
    "\n",
    "We can fix that by converting the `RegionName` column to a string and using the Python string method `zfill`, which adds zeroes to the beginning of a string to make it the required length. The argument to `zfill` is the **total number** of characters in the string. If the string to which you apple `zfill` contains fewer characters than the number you provide, the string will be padded with zeroes to fill it out to the required length. For example, `'7'.zfill(3)` returns `'007'`.\n",
    "\n",
    "To use `zfill` on the `RegionName` column of our DataFrame, we first have to convert the data to strings, using the `astype` method. Then we can `apply` the `zfill` method to the data in that column. The pandas `apply` method, which takes as its argument another function, executes that function once for each value in the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df['RegionName'] = z_df['RegionName'].astype(str).apply(lambda x: x.zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting dates and times\n",
    "\n",
    "Now let's convert the `month` column to a `datetime` type. This makes it much easier to aggregate on time series. In this case, pandas can interpret the string correctly without our supplying a pattern. In other cases, it may be necessary to provide a second argument to `pd.to_datetime`, indicating the pattern of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df['month'] = pd.to_datetime(z_df['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter by parts of the date, for instance, by year. To do this, we use the special `dt` attribute, which has attributes corresponding to day, month, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7691796</th>\n",
       "      <td>61639</td>\n",
       "      <td>0</td>\n",
       "      <td>10025</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>1121064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691797</th>\n",
       "      <td>84654</td>\n",
       "      <td>1</td>\n",
       "      <td>60657</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>503891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691798</th>\n",
       "      <td>61637</td>\n",
       "      <td>2</td>\n",
       "      <td>10023</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>1466975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691799</th>\n",
       "      <td>91982</td>\n",
       "      <td>3</td>\n",
       "      <td>77494</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>358995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691800</th>\n",
       "      <td>84616</td>\n",
       "      <td>4</td>\n",
       "      <td>60614</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>643988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935975</th>\n",
       "      <td>66169</td>\n",
       "      <td>34430</td>\n",
       "      <td>20052</td>\n",
       "      <td>Zip</td>\n",
       "      <td>DC</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1443140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935976</th>\n",
       "      <td>89666</td>\n",
       "      <td>34430</td>\n",
       "      <td>72630</td>\n",
       "      <td>Zip</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>Diamond City</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>Boone County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>118818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935977</th>\n",
       "      <td>62532</td>\n",
       "      <td>34430</td>\n",
       "      <td>12345</td>\n",
       "      <td>Zip</td>\n",
       "      <td>OR</td>\n",
       "      <td>OR</td>\n",
       "      <td>Central Point</td>\n",
       "      <td>Medford</td>\n",
       "      <td>Jackson County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>169411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935978</th>\n",
       "      <td>87060</td>\n",
       "      <td>34430</td>\n",
       "      <td>66045</td>\n",
       "      <td>Zip</td>\n",
       "      <td>KS</td>\n",
       "      <td>KS</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>256756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935979</th>\n",
       "      <td>58379</td>\n",
       "      <td>34430</td>\n",
       "      <td>01470</td>\n",
       "      <td>Zip</td>\n",
       "      <td>MA</td>\n",
       "      <td>MA</td>\n",
       "      <td>Groton</td>\n",
       "      <td>Boston-Cambridge-Newton</td>\n",
       "      <td>Middlesex County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>427623.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244184 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionID  SizeRank RegionName RegionType StateName State  \\\n",
       "7691796     61639         0      10025        Zip        NY    NY   \n",
       "7691797     84654         1      60657        Zip        IL    IL   \n",
       "7691798     61637         2      10023        Zip        NY    NY   \n",
       "7691799     91982         3      77494        Zip        TX    TX   \n",
       "7691800     84616         4      60614        Zip        IL    IL   \n",
       "...           ...       ...        ...        ...       ...   ...   \n",
       "7935975     66169     34430      20052        Zip        DC    DC   \n",
       "7935976     89666     34430      72630        Zip        AR    AR   \n",
       "7935977     62532     34430      12345        Zip        OR    OR   \n",
       "7935978     87060     34430      66045        Zip        KS    KS   \n",
       "7935979     58379     34430      01470        Zip        MA    MA   \n",
       "\n",
       "                  City                             Metro  \\\n",
       "7691796       New York       New York-Newark-Jersey City   \n",
       "7691797        Chicago          Chicago-Naperville-Elgin   \n",
       "7691798       New York       New York-Newark-Jersey City   \n",
       "7691799           Katy  Houston-The Woodlands-Sugar Land   \n",
       "7691800        Chicago          Chicago-Naperville-Elgin   \n",
       "...                ...                               ...   \n",
       "7935975     Washington   Washington-Arlington-Alexandria   \n",
       "7935976   Diamond City                          Harrison   \n",
       "7935977  Central Point                           Medford   \n",
       "7935978       Lawrence                          Lawrence   \n",
       "7935979         Groton           Boston-Cambridge-Newton   \n",
       "\n",
       "                   CountyName      month      value  \n",
       "7691796       New York County 2021-01-31  1121064.0  \n",
       "7691797           Cook County 2021-01-31   503891.0  \n",
       "7691798       New York County 2021-01-31  1466975.0  \n",
       "7691799         Harris County 2021-01-31   358995.0  \n",
       "7691800           Cook County 2021-01-31   643988.0  \n",
       "...                       ...        ...        ...  \n",
       "7935975  District of Columbia 2021-08-31  1443140.0  \n",
       "7935976          Boone County 2021-08-31   118818.0  \n",
       "7935977        Jackson County 2021-08-31   169411.0  \n",
       "7935978        Douglas County 2021-08-31   256756.0  \n",
       "7935979      Middlesex County 2021-08-31   427623.0  \n",
       "\n",
       "[244184 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df.loc[z_df.month.dt.year == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customizing the numerical format\n",
    "\n",
    "When dealing with dollar values in the millions, it is useful to limit the number of decimal places to 2 and to add commas separating the thousands, etc. We can set this option globally as follows.\n",
    "\n",
    "Note that it does not affect the underlying representation of the data (which is still floating-point decimal), just the way it displays on screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format','{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61639</td>\n",
       "      <td>0</td>\n",
       "      <td>10025</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>329,121.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84654</td>\n",
       "      <td>1</td>\n",
       "      <td>60657</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>311,929.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61637</td>\n",
       "      <td>2</td>\n",
       "      <td>10023</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>500,887.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91982</td>\n",
       "      <td>3</td>\n",
       "      <td>77494</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>225,325.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84616</td>\n",
       "      <td>4</td>\n",
       "      <td>60614</td>\n",
       "      <td>Zip</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago-Naperville-Elgin</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>405,926.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935975</th>\n",
       "      <td>66169</td>\n",
       "      <td>34430</td>\n",
       "      <td>20052</td>\n",
       "      <td>Zip</td>\n",
       "      <td>DC</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1,443,140.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935976</th>\n",
       "      <td>89666</td>\n",
       "      <td>34430</td>\n",
       "      <td>72630</td>\n",
       "      <td>Zip</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>Diamond City</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>Boone County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>118,818.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935977</th>\n",
       "      <td>62532</td>\n",
       "      <td>34430</td>\n",
       "      <td>12345</td>\n",
       "      <td>Zip</td>\n",
       "      <td>OR</td>\n",
       "      <td>OR</td>\n",
       "      <td>Central Point</td>\n",
       "      <td>Medford</td>\n",
       "      <td>Jackson County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>169,411.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935978</th>\n",
       "      <td>87060</td>\n",
       "      <td>34430</td>\n",
       "      <td>66045</td>\n",
       "      <td>Zip</td>\n",
       "      <td>KS</td>\n",
       "      <td>KS</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>256,756.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935979</th>\n",
       "      <td>58379</td>\n",
       "      <td>34430</td>\n",
       "      <td>01470</td>\n",
       "      <td>Zip</td>\n",
       "      <td>MA</td>\n",
       "      <td>MA</td>\n",
       "      <td>Groton</td>\n",
       "      <td>Boston-Cambridge-Newton</td>\n",
       "      <td>Middlesex County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>427,623.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7935980 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionID  SizeRank RegionName RegionType StateName State  \\\n",
       "0           61639         0      10025        Zip        NY    NY   \n",
       "1           84654         1      60657        Zip        IL    IL   \n",
       "2           61637         2      10023        Zip        NY    NY   \n",
       "3           91982         3      77494        Zip        TX    TX   \n",
       "4           84616         4      60614        Zip        IL    IL   \n",
       "...           ...       ...        ...        ...       ...   ...   \n",
       "7935975     66169     34430      20052        Zip        DC    DC   \n",
       "7935976     89666     34430      72630        Zip        AR    AR   \n",
       "7935977     62532     34430      12345        Zip        OR    OR   \n",
       "7935978     87060     34430      66045        Zip        KS    KS   \n",
       "7935979     58379     34430      01470        Zip        MA    MA   \n",
       "\n",
       "                  City                             Metro  \\\n",
       "0             New York       New York-Newark-Jersey City   \n",
       "1              Chicago          Chicago-Naperville-Elgin   \n",
       "2             New York       New York-Newark-Jersey City   \n",
       "3                 Katy  Houston-The Woodlands-Sugar Land   \n",
       "4              Chicago          Chicago-Naperville-Elgin   \n",
       "...                ...                               ...   \n",
       "7935975     Washington   Washington-Arlington-Alexandria   \n",
       "7935976   Diamond City                          Harrison   \n",
       "7935977  Central Point                           Medford   \n",
       "7935978       Lawrence                          Lawrence   \n",
       "7935979         Groton           Boston-Cambridge-Newton   \n",
       "\n",
       "                   CountyName      month        value  \n",
       "0             New York County 2000-01-31   329,121.00  \n",
       "1                 Cook County 2000-01-31   311,929.00  \n",
       "2             New York County 2000-01-31   500,887.00  \n",
       "3               Harris County 2000-01-31   225,325.00  \n",
       "4                 Cook County 2000-01-31   405,926.00  \n",
       "...                       ...        ...          ...  \n",
       "7935975  District of Columbia 2021-08-31 1,443,140.00  \n",
       "7935976          Boone County 2021-08-31   118,818.00  \n",
       "7935977        Jackson County 2021-08-31   169,411.00  \n",
       "7935978        Douglas County 2021-08-31   256,756.00  \n",
       "7935979      Middlesex County 2021-08-31   427,623.00  \n",
       "\n",
       "[7935980 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "#### Null values\n",
    "\n",
    "One thing we may want to know about dataset is how many rows have null values. There are other ways to accomplish this, but a straightforward way to get a total by column is to call `sum` on the result of the `DataFrame.isna` method. `isna` returns a new DataFrame where each cell is either `True` or `False`, depending on whether it's null or not. And the `sum` method simply \"adds up\" these Boolean values, treating `True` as 1 and `False` as 0. The result shows us how many null values are in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID            0\n",
       "SizeRank            0\n",
       "RegionName          0\n",
       "RegionType          0\n",
       "StateName           0\n",
       "State               0\n",
       "City                0\n",
       "Metro         2248468\n",
       "CountyName          0\n",
       "month               0\n",
       "value         1817353\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only columns with nulls are the `Metro` column and the `value` column. The `Metro` column refers to the zip code's metro area; rural zip codes would not have a metro area, so that makes sense. The nulls in the `value` column might be more problematic, depending on our analysis; these are instances where we don't have a valid observation. (Maybe no data were available.)\n",
    "\n",
    "Here we also have an example of the principle that an aggregate operation on a DataFrame (`sum`) returns a pandas Series.\n",
    "\n",
    "If we want to examine the null values, we can use the `isna` method to find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>92271</td>\n",
       "      <td>23</td>\n",
       "      <td>78130</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>New Braunfels</td>\n",
       "      <td>San Antonio-New Braunfels</td>\n",
       "      <td>Comal County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>61643</td>\n",
       "      <td>25</td>\n",
       "      <td>10029</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>New York County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>92036</td>\n",
       "      <td>27</td>\n",
       "      <td>77573</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>League City</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land</td>\n",
       "      <td>Galveston County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>92515</td>\n",
       "      <td>36</td>\n",
       "      <td>78572</td>\n",
       "      <td>Zip</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>Mission</td>\n",
       "      <td>McAllen-Edinburg-Mission</td>\n",
       "      <td>Hidalgo County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>86026</td>\n",
       "      <td>54</td>\n",
       "      <td>63376</td>\n",
       "      <td>Zip</td>\n",
       "      <td>MO</td>\n",
       "      <td>MO</td>\n",
       "      <td>Saint Peters</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>Saint Charles County</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7927728</th>\n",
       "      <td>81919</td>\n",
       "      <td>23362</td>\n",
       "      <td>54836</td>\n",
       "      <td>Zip</td>\n",
       "      <td>WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>Foxboro</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928350</th>\n",
       "      <td>61885</td>\n",
       "      <td>24090</td>\n",
       "      <td>10597</td>\n",
       "      <td>Zip</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Town Of Lewisboro</td>\n",
       "      <td>New York-Newark-Jersey City</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928562</th>\n",
       "      <td>81907</td>\n",
       "      <td>24347</td>\n",
       "      <td>54820</td>\n",
       "      <td>Zip</td>\n",
       "      <td>WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>Brule</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928676</th>\n",
       "      <td>81935</td>\n",
       "      <td>24479</td>\n",
       "      <td>54854</td>\n",
       "      <td>Zip</td>\n",
       "      <td>WI</td>\n",
       "      <td>WI</td>\n",
       "      <td>Maple</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Douglas County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933804</th>\n",
       "      <td>65858</td>\n",
       "      <td>30705</td>\n",
       "      <td>19319</td>\n",
       "      <td>Zip</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Glen Mills</td>\n",
       "      <td>Philadelphia-Camden-Wilmington</td>\n",
       "      <td>Delaware County</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1732458 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionID  SizeRank RegionName RegionType StateName State  \\\n",
       "22          92271        23      78130        Zip        TX    TX   \n",
       "24          61643        25      10029        Zip        NY    NY   \n",
       "26          92036        27      77573        Zip        TX    TX   \n",
       "35          92515        36      78572        Zip        TX    TX   \n",
       "53          86026        54      63376        Zip        MO    MO   \n",
       "...           ...       ...        ...        ...       ...   ...   \n",
       "7927728     81919     23362      54836        Zip        WI    WI   \n",
       "7928350     61885     24090      10597        Zip        NY    NY   \n",
       "7928562     81907     24347      54820        Zip        WI    WI   \n",
       "7928676     81935     24479      54854        Zip        WI    WI   \n",
       "7933804     65858     30705      19319        Zip        PA    PA   \n",
       "\n",
       "                      City                             Metro  \\\n",
       "22           New Braunfels         San Antonio-New Braunfels   \n",
       "24                New York       New York-Newark-Jersey City   \n",
       "26             League City  Houston-The Woodlands-Sugar Land   \n",
       "35                 Mission          McAllen-Edinburg-Mission   \n",
       "53            Saint Peters                         St. Louis   \n",
       "...                    ...                               ...   \n",
       "7927728            Foxboro                            Duluth   \n",
       "7928350  Town Of Lewisboro       New York-Newark-Jersey City   \n",
       "7928562              Brule                            Duluth   \n",
       "7928676              Maple                            Duluth   \n",
       "7933804         Glen Mills    Philadelphia-Camden-Wilmington   \n",
       "\n",
       "                   CountyName      month  value  \n",
       "22               Comal County 2000-01-31    nan  \n",
       "24            New York County 2000-01-31    nan  \n",
       "26           Galveston County 2000-01-31    nan  \n",
       "35             Hidalgo County 2000-01-31    nan  \n",
       "53       Saint Charles County 2000-01-31    nan  \n",
       "...                       ...        ...    ...  \n",
       "7927728        Douglas County 2021-08-31    nan  \n",
       "7928350    Westchester County 2021-08-31    nan  \n",
       "7928562        Douglas County 2021-08-31    nan  \n",
       "7928676        Douglas County 2021-08-31    nan  \n",
       "7933804       Delaware County 2021-08-31    nan  \n",
       "\n",
       "[1732458 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df.loc[z_df.value.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for duplicates\n",
    "\n",
    "Another problem frequently encountered is duplicated data. We can check for that using the `duplicated` method, which works like `isna` except that it returns `True` if a value is duplicated within a column. By default, it doesn't mark the first duplicate as a duplicate, but I usually find it helpful to see all the duplicates, so I pass the parameter `keep=False`, which means, \"Count the first instance of a duplicated datum as a duplicate.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>2000-01-31</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-11-30</th>\n",
       "      <th>2020-12-31</th>\n",
       "      <th>2021-01-31</th>\n",
       "      <th>2021-02-28</th>\n",
       "      <th>2021-03-31</th>\n",
       "      <th>2021-04-30</th>\n",
       "      <th>2021-05-31</th>\n",
       "      <th>2021-06-30</th>\n",
       "      <th>2021-07-31</th>\n",
       "      <th>2021-08-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RegionID, SizeRank, RegionName, RegionType, StateName, State, City, Metro, CountyName, 2000-01-31, 2000-02-29, 2000-03-31, 2000-04-30, 2000-05-31, 2000-06-30, 2000-07-31, 2000-08-31, 2000-09-30, 2000-10-31, 2000-11-30, 2000-12-31, 2001-01-31, 2001-02-28, 2001-03-31, 2001-04-30, 2001-05-31, 2001-06-30, 2001-07-31, 2001-08-31, 2001-09-30, 2001-10-31, 2001-11-30, 2001-12-31, 2002-01-31, 2002-02-28, 2002-03-31, 2002-04-30, 2002-05-31, 2002-06-30, 2002-07-31, 2002-08-31, 2002-09-30, 2002-10-31, 2002-11-30, 2002-12-31, 2003-01-31, 2003-02-28, 2003-03-31, 2003-04-30, 2003-05-31, 2003-06-30, 2003-07-31, 2003-08-31, 2003-09-30, 2003-10-31, 2003-11-30, 2003-12-31, 2004-01-31, 2004-02-29, 2004-03-31, 2004-04-30, 2004-05-31, 2004-06-30, 2004-07-31, 2004-08-31, 2004-09-30, 2004-10-31, 2004-11-30, 2004-12-31, 2005-01-31, 2005-02-28, 2005-03-31, 2005-04-30, 2005-05-31, 2005-06-30, 2005-07-31, 2005-08-31, 2005-09-30, 2005-10-31, 2005-11-30, 2005-12-31, 2006-01-31, 2006-02-28, 2006-03-31, 2006-04-30, 2006-05-31, 2006-06-30, 2006-07-31, 2006-08-31, 2006-09-30, 2006-10-31, 2006-11-30, 2006-12-31, 2007-01-31, 2007-02-28, 2007-03-31, 2007-04-30, 2007-05-31, 2007-06-30, 2007-07-31, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 269 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhvi_df.loc[zhvi_df.RegionName.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No zip codes in our original dataset are duplicated, so that's good! Note that I didn't call that method on our \"melted\" dataset, since converting the original table to a \"long\" version created many duplicates. \n",
    "\n",
    "In our \"melted\" dataset, the combination of zip code and month should be unique. We can check for this using the `subset` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RegionID, SizeRank, RegionName, RegionType, StateName, State, City, Metro, CountyName, month, value]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df.loc[z_df.duplicated(subset=['RegionName', 'month'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ACS data\n",
    "\n",
    "To make things more interesting, we're going to combine our Zillow data with a dataset from the US Census. The American Community Survey provides five-year estimates of many important economic indicators, including median household income by zip code. \n",
    "\n",
    "We can use the Census API to fetch the tables we need. The Python [census](https://pypi.org/project/census/) package provides a convenient wrapper around the API's. \n",
    "\n",
    "If you submitted the form at the start of our workshop, you should have received an API key via the email address you provided. If you didn't, I'll provide a link to the datasets we're going to use. \n",
    "\n",
    "#### Retrieving Census data \n",
    "\n",
    "First we need to initialize the module with our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = '0009292cbc84afabcef7b434345abb0df20349c7'\n",
    "census = Census(apikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access Census tables by API, we need to know the specific variable names. You can find these in the [ACS documentation](https://api.census.gov/data/2019/acs/acs5/variables.html). Using the `census` module, we can specify the ACS 5-year tables and zip code as the geographical level. In addition, you can specify a year as a method parameter, if we want data other than that from the most recent survey. \n",
    "\n",
    "In order to have some timeseries data, we'll retrieve the data for 2014 and 2019. (It's recommended to use [non-overlapping datasets](https://www.census.gov/data/developers/data-sets/acs-5year.html) for the ACS 5-year surveys because of how the estimates are calculated.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income = \"B19013_001E\"\n",
    "census = Census(apikey)\n",
    "acs2019 = census.acs5.zipcode(median_income, '*')\n",
    "acs2014 = census.acs5.zipcode(median_income, '*', year=2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a DataFrame\n",
    "\n",
    "The Census API returns the table as a list of dictionaries. You can see that the value for our variable -- median household income -- is provided for each row, as well as a code for the state and the zip code (both strings). \n",
    "\n",
    "Our first step is to convert these two lists to DataFrames so that we can efficiently merge them with our Zillow data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has a handy method call `DataFrame.from_records`, which creates a DataFrame from exactly this structure. (The elements of the list are the rows, the keys of the dictionaries are the columns.)\n",
    "\n",
    "We can also rename our columns for clarity and concision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df = pd.DataFrame.from_records(acs2019)\n",
    "acs_df = acs_df.rename(columns={'B19013_001E': '2019_median_hhi',\n",
    "                               'zip code tabulation area': 'zip_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33120"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames\n",
    "\n",
    "But we have two separate datasets, one from 2019 and one from 2014. Ideally, we want a single table containing all of our ACS data. We'll accomplish that by using pandas' `concat` method, which takes a list of DataFrames and stacks them one on top of the other.\n",
    "\n",
    "We'll add a column to record the year. And we'll put this code into a Python function, which is good practice for encapsulating our code for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acs_df(datasets, years):\n",
    "    '''\n",
    "    Accepts a list of pandas DataFrames to concat and a list of years, which will be added as a column to the resulting DataFrame\n",
    "    '''\n",
    "    # Step 1: Create an empty DataFrame -- for the first dataset, we need something to concat it with\n",
    "    df_all = pd.DataFrame()\n",
    "    # Step 2: Create a for loop: we can use the zip method to loop over the datasets and years at the same time\n",
    "    for dataset, year in zip(datasets, years):\n",
    "        # Create a DataFrame from the current dataset\n",
    "        df = pd.DataFrame.from_records(dataset)\n",
    "        # Create a year column and populate it with the corresponding year\n",
    "        df['year'] = year\n",
    "        # Rename the columns\n",
    "        df = df.rename(columns={'B19013_001E': 'median_hhi',\n",
    "                               'zip code tabulation area': 'zip_code'})\n",
    "        # Concat with the previous DataFrame\n",
    "        df_all = pd.concat([df_all, df])\n",
    "    # Don't forget to return something!\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df = create_acs_df([acs2019, acs2014], [2019, 2014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13,092.00</td>\n",
       "      <td>72</td>\n",
       "      <td>00601</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16,358.00</td>\n",
       "      <td>72</td>\n",
       "      <td>00602</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16,603.00</td>\n",
       "      <td>72</td>\n",
       "      <td>00603</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12,832.00</td>\n",
       "      <td>72</td>\n",
       "      <td>00606</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19,309.00</td>\n",
       "      <td>72</td>\n",
       "      <td>00610</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33115</th>\n",
       "      <td>-666,666,666.00</td>\n",
       "      <td>02</td>\n",
       "      <td>99923</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33116</th>\n",
       "      <td>39,167.00</td>\n",
       "      <td>02</td>\n",
       "      <td>99925</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>51,071.00</td>\n",
       "      <td>02</td>\n",
       "      <td>99926</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33118</th>\n",
       "      <td>17,946.00</td>\n",
       "      <td>02</td>\n",
       "      <td>99927</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33119</th>\n",
       "      <td>48,153.00</td>\n",
       "      <td>02</td>\n",
       "      <td>99929</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           median_hhi state zip_code  year\n",
       "0           13,092.00    72    00601  2019\n",
       "1           16,358.00    72    00602  2019\n",
       "2           16,603.00    72    00603  2019\n",
       "3           12,832.00    72    00606  2019\n",
       "4           19,309.00    72    00610  2019\n",
       "...               ...   ...      ...   ...\n",
       "33115 -666,666,666.00    02    99923  2014\n",
       "33116       39,167.00    02    99925  2014\n",
       "33117       51,071.00    02    99926  2014\n",
       "33118       17,946.00    02    99927  2014\n",
       "33119       48,153.00    02    99929  2014\n",
       "\n",
       "[66240 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with \"bad\" data\n",
    "\n",
    "It looks like we have some outliers here, which may be an artifact of how the data has been reported/coded. We can use the `describe` method to try to spot these. (Ignore the year column; we're only interested in outliers in the `median_hhi` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66205.00</td>\n",
       "      <td>66240.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-33237571.79</td>\n",
       "      <td>2016.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145221476.17</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-666666666.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38750.00</td>\n",
       "      <td>2014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50056.00</td>\n",
       "      <td>2016.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63826.00</td>\n",
       "      <td>2019.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>250001.00</td>\n",
       "      <td>2019.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         median_hhi     year\n",
       "count      66205.00 66240.00\n",
       "mean   -33237571.79  2016.50\n",
       "std    145221476.17     2.50\n",
       "min   -666666666.00  2014.00\n",
       "25%        38750.00  2014.00\n",
       "50%        50056.00  2016.50\n",
       "75%        63826.00  2019.00\n",
       "max       250001.00  2019.00"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't really make sense to have negative median income; and indeed, by looking at the unique values in the column that fall **below** zero, we can see that there's only one value, which may mean any number of things, but for the purposes of this example, we can just discard those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.66666666e+08])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_df.loc[acs_df.median_hhi < 0].median_hhi.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `DataFrame.loc` to limit to the rows with a non-negative value for `median_hhi`. We'll make a copy of the filtered DataFrame, which helps avoid issues as we manipulate this data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_df = acs_df.loc[acs_df.median_hhi >= 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62,899.00</td>\n",
       "      <td>62,899.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55,749.01</td>\n",
       "      <td>2,016.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24,176.37</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2,499.00</td>\n",
       "      <td>2,014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40,623.00</td>\n",
       "      <td>2,014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51,125.00</td>\n",
       "      <td>2,014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64,821.00</td>\n",
       "      <td>2,019.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>250,001.00</td>\n",
       "      <td>2,019.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       median_hhi      year\n",
       "count   62,899.00 62,899.00\n",
       "mean    55,749.01  2,016.46\n",
       "std     24,176.37      2.50\n",
       "min      2,499.00  2,014.00\n",
       "25%     40,623.00  2,014.00\n",
       "50%     51,125.00  2,014.00\n",
       "75%     64,821.00  2,019.00\n",
       "max    250,001.00  2,019.00"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our joint dataset\n",
    "\n",
    "In order to compare Zillow home values and median household income by geographical area, it will be useful to have a single table that contains both variables. We'll create this table in a few steps.\n",
    "\n",
    "#### Creating aligned data\n",
    "\n",
    "Most important is to make sure that our two variables are aligned, meaning that they represent observations at the same scale. \n",
    "\n",
    "How well are our datasets aligned?\n",
    "\n",
    "| Dataset | Measure | Geographic Dimension | Temporal Dimension |\n",
    "| --- | --- | --- | --- |\n",
    "| Zillow | Estimated median home value (dollars) | Zipcode | Month |\n",
    "| ACS | Median household income (dollars) | Zipcode | Year |\n",
    "\n",
    "Zillow and ACS are measuring different things, but they're both using the median as their statistic, and they're both measuring value in dollars. Geographically, both datasets are aligned at the level of zipcode. \n",
    "\n",
    "However, the Zillow data are presented on a monthly basis, while the ACS data are available only at the annual level. Moreover, because of the 5-year overlap, we have only two \"years\" of ACS data to work with. We'll need to adjust our Zillow dataset to bring it into alignment with our ACS data.\n",
    "\n",
    "\n",
    "(Technically, the ACS data represent five-year aggregates, which are not the same as annual measures. In what follows we are going to take a statistically naive approach to comparing and summarizing these data. Tis approach is not intended to be empirically rigorous; rather, it is meant to illustrate operations with pandas. For more on the appropriate methodology for handling ACS median values, [this guide](http://www.dof.ca.gov/Forecasting/Demographics/Census_Data_Center_Network/documents/How_to_Recalculate_a_Median.pdf) is a good starting point.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering a dataset and checking for missing data\n",
    "\n",
    "First we limit the Zillow data to the years for which we have ACS data: 2014 and 2019. We can use the `dt` datetime attribute on the `month` column to select particular years with `DataFrame.loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df = z_df.loc[(z_df.month.dt.year == 2019) | (z_df.month.dt.year == 2014)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if there are zipcodes represented in each dataset not present in the other, we can use the `asin` method to compare the values in one DataFrame with the values in another. This code counts how many unique zip codes are in our Zillow dataset that are not present in the ACS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_df.loc[~z_df.RegionName.isin(acs_df.zip_code)].RegionName.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same to count how many zip codes in the ACS dataset are missing from the Zillow data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acs_df.loc[~acs_df.zip_code.isin(z_df.RegionName)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'll simply omit these non-overlapping data points from our merged dataset. But in other cases, it might be important to account for them in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating by time scale\n",
    "\n",
    "We'll aggregate the Zillow data by year in order to compare with them the ACS data at the same time scale. \n",
    "\n",
    "We'll use the `DataFrame.groupby` method to group our dataset at the desired level. We're grouping by year, so we can use the `dt.year` attribute on the `month` column as the group key. We can group by multiple columns, so we might want to include other columns, too (except for the `value` column, which contains the data that we're trying to summarize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can provide them as a list to the `groupby` method, which use the unique combinations of the values in these columns as the keys for grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grp = z_df.groupby([z_df.StateName, z_df.City, z_df.Metro, z_df.RegionName, z_df.month.dt.year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the `mean` of the `value` column from our grouped DataFrame. Such operations by default return a Series (in this case, with a so-called hierarchical index). But to turn that back to a DataFrame, we can use the `reset_index` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_means = z_grp.value.mean()\n",
    "z_means = z_means.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99501</td>\n",
       "      <td>2014</td>\n",
       "      <td>265,894.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99501</td>\n",
       "      <td>2019</td>\n",
       "      <td>277,092.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99502</td>\n",
       "      <td>2014</td>\n",
       "      <td>295,827.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99502</td>\n",
       "      <td>2019</td>\n",
       "      <td>325,150.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99503</td>\n",
       "      <td>2014</td>\n",
       "      <td>241,454.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46811</th>\n",
       "      <td>WY</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>82731</td>\n",
       "      <td>2019</td>\n",
       "      <td>370,148.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46812</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>83014</td>\n",
       "      <td>2014</td>\n",
       "      <td>1,191,844.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46813</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>83014</td>\n",
       "      <td>2019</td>\n",
       "      <td>1,576,990.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46814</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wright</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>82732</td>\n",
       "      <td>2014</td>\n",
       "      <td>215,183.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46815</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wright</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>82732</td>\n",
       "      <td>2019</td>\n",
       "      <td>233,214.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46816 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName       City      Metro RegionName  month        value\n",
       "0            AK  Anchorage  Anchorage      99501   2014   265,894.50\n",
       "1            AK  Anchorage  Anchorage      99501   2019   277,092.83\n",
       "2            AK  Anchorage  Anchorage      99502   2014   295,827.08\n",
       "3            AK  Anchorage  Anchorage      99502   2019   325,150.25\n",
       "4            AK  Anchorage  Anchorage      99503   2014   241,454.50\n",
       "...         ...        ...        ...        ...    ...          ...\n",
       "46811        WY     Weston   Gillette      82731   2019   370,148.83\n",
       "46812        WY     Wilson    Jackson      83014   2014 1,191,844.42\n",
       "46813        WY     Wilson    Jackson      83014   2019 1,576,990.58\n",
       "46814        WY     Wright   Gillette      82732   2014   215,183.17\n",
       "46815        WY     Wright   Gillette      82732   2019   233,214.58\n",
       "\n",
       "[46816 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When grouping by multiple columns, it's important to be careful when including columns with null values. Recall from our analysis above that sometimes the `Metro` column is blank in this dataset. \n",
    "\n",
    "What happens to those rows in our final group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StateName, City, Metro, RegionName, month, value]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_means.loc[z_means.Metro.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By grouping by a column with nulls, we've actually lost a fair amount of data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7115"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_df.loc[~z_df.RegionName.isin(z_means.RegionName)].RegionName.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this problem, we could omit the `Metro` column from our `groupby` statement. In more recent versions of pandas, we can also add a `dropna=False` parameter to our `groupby` statement, which will keep the null values in the group keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99556</td>\n",
       "      <td>2014</td>\n",
       "      <td>153,405.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99556</td>\n",
       "      <td>2019</td>\n",
       "      <td>169,179.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AK</td>\n",
       "      <td>Clam Gulch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99568</td>\n",
       "      <td>2014</td>\n",
       "      <td>164,201.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AK</td>\n",
       "      <td>Clam Gulch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99568</td>\n",
       "      <td>2019</td>\n",
       "      <td>181,696.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AK</td>\n",
       "      <td>Cooper Landing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99572</td>\n",
       "      <td>2014</td>\n",
       "      <td>292,707.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61037</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wheatland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82201</td>\n",
       "      <td>2019</td>\n",
       "      <td>210,679.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61040</th>\n",
       "      <td>WY</td>\n",
       "      <td>Worland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82401</td>\n",
       "      <td>2014</td>\n",
       "      <td>147,281.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61041</th>\n",
       "      <td>WY</td>\n",
       "      <td>Worland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82401</td>\n",
       "      <td>2019</td>\n",
       "      <td>164,424.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61044</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2014</td>\n",
       "      <td>177,986.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61045</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2019</td>\n",
       "      <td>228,844.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14230 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName            City Metro RegionName  month      value\n",
       "0            AK    Anchor Point   NaN      99556   2014 153,405.92\n",
       "1            AK    Anchor Point   NaN      99556   2019 169,179.08\n",
       "32           AK      Clam Gulch   NaN      99568   2014 164,201.92\n",
       "33           AK      Clam Gulch   NaN      99568   2019 181,696.50\n",
       "34           AK  Cooper Landing   NaN      99572   2014 292,707.75\n",
       "...         ...             ...   ...        ...    ...        ...\n",
       "61037        WY       Wheatland   NaN      82201   2019 210,679.25\n",
       "61040        WY         Worland   NaN      82401   2014 147,281.58\n",
       "61041        WY         Worland   NaN      82401   2019 164,424.08\n",
       "61044        WY           Yoder   NaN      82244   2014 177,986.25\n",
       "61045        WY           Yoder   NaN      82244   2019 228,844.33\n",
       "\n",
       "[14230 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_grp = z_df.groupby([z_df.StateName, z_df.City, z_df.Metro, z_df.RegionName, z_df.month.dt.year],\n",
    "                    dropna=False)\n",
    "z_means = z_grp.value.mean()\n",
    "z_means = z_means.reset_index()\n",
    "z_means.loc[z_means.Metro.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>month</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99556</td>\n",
       "      <td>2014</td>\n",
       "      <td>153,405.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99556</td>\n",
       "      <td>2019</td>\n",
       "      <td>169,179.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99501</td>\n",
       "      <td>2014</td>\n",
       "      <td>265,894.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99501</td>\n",
       "      <td>2019</td>\n",
       "      <td>277,092.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>99502</td>\n",
       "      <td>2014</td>\n",
       "      <td>295,827.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61041</th>\n",
       "      <td>WY</td>\n",
       "      <td>Worland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82401</td>\n",
       "      <td>2019</td>\n",
       "      <td>164,424.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61042</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wright</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>82732</td>\n",
       "      <td>2014</td>\n",
       "      <td>215,183.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61043</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wright</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>82732</td>\n",
       "      <td>2019</td>\n",
       "      <td>233,214.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61044</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2014</td>\n",
       "      <td>177,986.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61045</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2019</td>\n",
       "      <td>228,844.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName          City      Metro RegionName  month      value\n",
       "0            AK  Anchor Point        NaN      99556   2014 153,405.92\n",
       "1            AK  Anchor Point        NaN      99556   2019 169,179.08\n",
       "2            AK     Anchorage  Anchorage      99501   2014 265,894.50\n",
       "3            AK     Anchorage  Anchorage      99501   2019 277,092.83\n",
       "4            AK     Anchorage  Anchorage      99502   2014 295,827.08\n",
       "...         ...           ...        ...        ...    ...        ...\n",
       "61041        WY       Worland        NaN      82401   2019 164,424.08\n",
       "61042        WY        Wright   Gillette      82732   2014 215,183.17\n",
       "61043        WY        Wright   Gillette      82732   2019 233,214.58\n",
       "61044        WY         Yoder        NaN      82244   2014 177,986.25\n",
       "61045        WY         Yoder        NaN      82244   2019 228,844.33\n",
       "\n",
       "[61046 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging data\n",
    "\n",
    "Now we're ready to merge our Zillow data with our ACS data. The `merge` method performs the equivalent of a SQL join on two DataFrames that share at least one common key. The keys are the columns with values that are the same in both datasets. The following chart shows the keys between our two datasets.\n",
    "\n",
    "| Measure or Dimension | `z_means` | `acs` |\n",
    "| --- | --- | --- | \n",
    "| State | `StateName` |  | \n",
    "| City | `City` |  |\n",
    "| Metro | `Metro` |  |\n",
    "| Zip code | `RegionName` | `zip_code`  |\n",
    "| Year | `month` | `year` |\n",
    "| State code |  | `state` |\n",
    "| Median income | | `median_hhi` |\n",
    "| Home value | `value` |  |\n",
    "\n",
    "The keys don't have to have the same column **names**, but they must share at least some of the same **values** in those columns. In our case, the shared values are the zip codes and the years. (Note that both our Zillow and ACS datasets have columns for U.S. state, but the values in those columns do not overlap: the Zillow dataset uses the name of the state, while the ACS data uses a numerical identifier.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging our datasets, we'll rename the Zillow columns `month` and `value` to more accurately represent their contents. This isn't necessary for merging, but it will make the merged table more legible for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_means = z_means.rename(columns={'month': 'year',\n",
    "                                 'value': 'zhvi'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the merge, which creates a new DataFrame. The arguments to the `merge` method are as follows:\n",
    "\n",
    "- `acs_df`: the second DataFrame we want to merge with the first.\n",
    "- `left_on`: this parameter takes a list of columns in the first DataFrame to use as keys.\n",
    "- `right_on`: this parameter takes a list of columns in the second DataFrame to use as keys.\n",
    "\n",
    "You can also specify a `how` parameter, which indicates the kind of join. The default is an **inner** join, meaning that the merged DataFrame will only contains rows where the keys are present in both of the source DataFrames. In this case, an inner join will drop those rows for zip codes that are missing from either the Zillow or the ACS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_merged = z_means.merge(acs_df, left_on=['RegionName', 'year'], \n",
    "                         right_on=['zip_code', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the `state` column from our ACS dataset. Nor do we need two columns of zip codes, so we can drop these from our merged dataset. The `axis` parameter is important in the `drop` method: `axis=1` means \"drop columns\" (as opposed to rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_merged = z_merged.drop(['state', 'zip_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating change over time\n",
    "\n",
    "As an illustration of further uses for `groupby`, we'll calculate the percentage change between 2014 and 2019 for both the ZHVI and median household income for each zip code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll sort the merged dataset by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_merged = z_merged.sort_values(by='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create new columns to hold the percentage change for each of our measures (home value and income). To calculate the percentage change, we will use the built-in `pct_change` method, applying it to the result of a `groupby` operation (since we still want to observe the changes at the zip-code level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StateName', 'City', 'Metro', 'RegionName', 'year', 'zhvi',\n",
       "       'median_hhi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['StateName', 'City', 'Metro', 'RegionName']\n",
    "z_merged['zhvi_pc'] = z_merged.groupby(columns, dropna=False).zhvi.pct_change()\n",
    "z_merged['hhi_pc'] = z_merged.groupby(columns, dropna=False).median_hhi.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `pc` columns have null values for all the rows where the `year` is 2014. That is expected: the first value in each sequence represents no change (since it's the first value). For each subsequent value, the percentage change is calculated with respect to the preceding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>year</th>\n",
       "      <th>zhvi</th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>zhvi_pc</th>\n",
       "      <th>hhi_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99556</td>\n",
       "      <td>2014</td>\n",
       "      <td>153,405.92</td>\n",
       "      <td>43,906.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24222</th>\n",
       "      <td>MI</td>\n",
       "      <td>Hancock</td>\n",
       "      <td>Houghton</td>\n",
       "      <td>49958</td>\n",
       "      <td>2014</td>\n",
       "      <td>74,156.25</td>\n",
       "      <td>36,731.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46303</th>\n",
       "      <td>SC</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>29440</td>\n",
       "      <td>2014</td>\n",
       "      <td>124,045.83</td>\n",
       "      <td>34,117.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24220</th>\n",
       "      <td>MI</td>\n",
       "      <td>Hancock</td>\n",
       "      <td>Houghton</td>\n",
       "      <td>49952</td>\n",
       "      <td>2014</td>\n",
       "      <td>nan</td>\n",
       "      <td>42,917.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24218</th>\n",
       "      <td>MI</td>\n",
       "      <td>Hancock</td>\n",
       "      <td>Houghton</td>\n",
       "      <td>49930</td>\n",
       "      <td>2014</td>\n",
       "      <td>104,142.17</td>\n",
       "      <td>36,880.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25985</th>\n",
       "      <td>MN</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington</td>\n",
       "      <td>55357</td>\n",
       "      <td>2019</td>\n",
       "      <td>427,492.25</td>\n",
       "      <td>104,821.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25987</th>\n",
       "      <td>MN</td>\n",
       "      <td>Greenwald</td>\n",
       "      <td>St. Cloud</td>\n",
       "      <td>56335</td>\n",
       "      <td>2019</td>\n",
       "      <td>129,383.67</td>\n",
       "      <td>57,708.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25989</th>\n",
       "      <td>MN</td>\n",
       "      <td>Grey Eagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56336</td>\n",
       "      <td>2019</td>\n",
       "      <td>214,723.42</td>\n",
       "      <td>58,688.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25993</th>\n",
       "      <td>MN</td>\n",
       "      <td>Grygla</td>\n",
       "      <td>Bemidji</td>\n",
       "      <td>56727</td>\n",
       "      <td>2019</td>\n",
       "      <td>113,225.83</td>\n",
       "      <td>52,656.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58258</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2019</td>\n",
       "      <td>228,844.33</td>\n",
       "      <td>75,357.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58259 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName          City                             Metro RegionName  \\\n",
       "0            AK  Anchor Point                               NaN      99556   \n",
       "24222        MI       Hancock                          Houghton      49958   \n",
       "46303        SC    Georgetown                        Georgetown      29440   \n",
       "24220        MI       Hancock                          Houghton      49952   \n",
       "24218        MI       Hancock                          Houghton      49930   \n",
       "...         ...           ...                               ...        ...   \n",
       "25985        MN    Greenfield  Minneapolis-St. Paul-Bloomington      55357   \n",
       "25987        MN     Greenwald                         St. Cloud      56335   \n",
       "25989        MN    Grey Eagle                               NaN      56336   \n",
       "25993        MN        Grygla                           Bemidji      56727   \n",
       "58258        WY         Yoder                               NaN      82244   \n",
       "\n",
       "       year       zhvi  median_hhi  zhvi_pc  hhi_pc  \n",
       "0      2014 153,405.92   43,906.00      nan     nan  \n",
       "24222  2014  74,156.25   36,731.00      nan     nan  \n",
       "46303  2014 124,045.83   34,117.00      nan     nan  \n",
       "24220  2014        nan   42,917.00      nan     nan  \n",
       "24218  2014 104,142.17   36,880.00      nan     nan  \n",
       "...     ...        ...         ...      ...     ...  \n",
       "25985  2019 427,492.25  104,821.00     0.23    0.19  \n",
       "25987  2019 129,383.67   57,708.00     0.23    0.18  \n",
       "25989  2019 214,723.42   58,688.00     0.24    0.05  \n",
       "25993  2019 113,225.83   52,656.00     0.38    0.02  \n",
       "58258  2019 228,844.33   75,357.00     0.29    0.43  \n",
       "\n",
       "[58259 rows x 9 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're just interested in the percentage change, we could drop the 2014 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_merged = z_merged.loc[z_merged.year == 2019].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>zhvi</th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>zhvi_pc</th>\n",
       "      <th>hhi_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28,708.00</td>\n",
       "      <td>28,397.00</td>\n",
       "      <td>28,708.00</td>\n",
       "      <td>26,765.00</td>\n",
       "      <td>28,643.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>229,401.67</td>\n",
       "      <td>59,869.23</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>235,203.14</td>\n",
       "      <td>25,221.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>14,309.33</td>\n",
       "      <td>2,499.00</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>108,478.50</td>\n",
       "      <td>43,720.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>166,515.58</td>\n",
       "      <td>54,514.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>266,548.00</td>\n",
       "      <td>69,135.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2,019.00</td>\n",
       "      <td>6,300,275.67</td>\n",
       "      <td>250,001.00</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year         zhvi  median_hhi   zhvi_pc    hhi_pc\n",
       "count 28,708.00    28,397.00   28,708.00 26,765.00 28,643.00\n",
       "mean   2,019.00   229,401.67   59,869.23      0.26      0.14\n",
       "std        0.00   235,203.14   25,221.57      0.17      0.26\n",
       "min    2,019.00    14,309.33    2,499.00     -0.49     -0.89\n",
       "25%    2,019.00   108,478.50   43,720.25      0.16      0.03\n",
       "50%    2,019.00   166,515.58   54,514.50      0.25      0.11\n",
       "75%    2,019.00   266,548.00   69,135.00      0.34      0.21\n",
       "max    2,019.00 6,300,275.67  250,001.00      2.68      9.32"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's a demonstration of how we could use a custom function to calculate percentage change. There's no need to do so -- the built-in method will be more efficient. But sometimes you want to compute an aggregation that's not available as a built-in method.\n",
    "\n",
    "For relatively simple calculations, we can use a `lambda` function, which is basically a one-line Python function. We define it with `lambda` instead of `def`. \n",
    "\n",
    "The `x` in the lambda expression is a function parameter. When used with `apply` on the `zhvi` column, `x` will represent a pandas Series containing the ZHVI values for each group created by our `groupby` expression. \n",
    "\n",
    "Since `x` is a Series, it has all the usual Series methods and properties, including `iloc`, which lets us take the first and second values for the purposes of calculating the percentage change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionName  StateName  City      \n",
       "00501       NY         Holtsville   0.25\n",
       "00602       AL         Auburn       0.29\n",
       "00693       PA         Greensburg    nan\n",
       "00705       UT         Aibonito     0.13\n",
       "00734       TX         Ponce        0.98\n",
       "                                    ... \n",
       "99714       AK         Salcha       0.11\n",
       "99801       AK         Juneau       0.15\n",
       "99824       AK         Juneau       0.11\n",
       "99833       AK         Petersburg    nan\n",
       "99901       AK         Ketchikan    0.13\n",
       "Name: zhvi, Length: 30523, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_means.groupby(['RegionName', 'StateName', 'City']).zhvi.apply(lambda x: (x.iloc[1] - x.iloc[0]) / x.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our merged, aggregated dataset to investigate certain questions.\n",
    "\n",
    "For example, where have home values risen *faster* than household income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>year</th>\n",
       "      <th>zhvi</th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>zhvi_pc</th>\n",
       "      <th>hhi_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56985</th>\n",
       "      <td>WV</td>\n",
       "      <td>Benwood</td>\n",
       "      <td>Wheeling</td>\n",
       "      <td>26031</td>\n",
       "      <td>2019</td>\n",
       "      <td>47,816.25</td>\n",
       "      <td>35,714.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40722</th>\n",
       "      <td>OK</td>\n",
       "      <td>Atwood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74827</td>\n",
       "      <td>2019</td>\n",
       "      <td>125,130.42</td>\n",
       "      <td>45,000.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57192</th>\n",
       "      <td>WV</td>\n",
       "      <td>Dunmore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24934</td>\n",
       "      <td>2019</td>\n",
       "      <td>78,474.17</td>\n",
       "      <td>28,403.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50587</th>\n",
       "      <td>TX</td>\n",
       "      <td>Murphy</td>\n",
       "      <td>Dallas-Fort Worth-Arlington</td>\n",
       "      <td>75094</td>\n",
       "      <td>2019</td>\n",
       "      <td>390,048.58</td>\n",
       "      <td>133,125.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57184</th>\n",
       "      <td>WV</td>\n",
       "      <td>Dry Creek</td>\n",
       "      <td>Beckley</td>\n",
       "      <td>25062</td>\n",
       "      <td>2019</td>\n",
       "      <td>59,717.83</td>\n",
       "      <td>28,250.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25983</th>\n",
       "      <td>MN</td>\n",
       "      <td>Greenbush</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56726</td>\n",
       "      <td>2019</td>\n",
       "      <td>76,219.67</td>\n",
       "      <td>59,167.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25985</th>\n",
       "      <td>MN</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington</td>\n",
       "      <td>55357</td>\n",
       "      <td>2019</td>\n",
       "      <td>427,492.25</td>\n",
       "      <td>104,821.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25987</th>\n",
       "      <td>MN</td>\n",
       "      <td>Greenwald</td>\n",
       "      <td>St. Cloud</td>\n",
       "      <td>56335</td>\n",
       "      <td>2019</td>\n",
       "      <td>129,383.67</td>\n",
       "      <td>57,708.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25989</th>\n",
       "      <td>MN</td>\n",
       "      <td>Grey Eagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56336</td>\n",
       "      <td>2019</td>\n",
       "      <td>214,723.42</td>\n",
       "      <td>58,688.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25993</th>\n",
       "      <td>MN</td>\n",
       "      <td>Grygla</td>\n",
       "      <td>Bemidji</td>\n",
       "      <td>56727</td>\n",
       "      <td>2019</td>\n",
       "      <td>113,225.83</td>\n",
       "      <td>52,656.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20450 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName        City                             Metro RegionName  \\\n",
       "56985        WV     Benwood                          Wheeling      26031   \n",
       "40722        OK      Atwood                               NaN      74827   \n",
       "57192        WV     Dunmore                               NaN      24934   \n",
       "50587        TX      Murphy       Dallas-Fort Worth-Arlington      75094   \n",
       "57184        WV   Dry Creek                           Beckley      25062   \n",
       "...         ...         ...                               ...        ...   \n",
       "25983        MN   Greenbush                               NaN      56726   \n",
       "25985        MN  Greenfield  Minneapolis-St. Paul-Bloomington      55357   \n",
       "25987        MN   Greenwald                         St. Cloud      56335   \n",
       "25989        MN  Grey Eagle                               NaN      56336   \n",
       "25993        MN      Grygla                           Bemidji      56727   \n",
       "\n",
       "       year       zhvi  median_hhi  zhvi_pc  hhi_pc  \n",
       "56985  2019  47,816.25   35,714.00     0.19    0.11  \n",
       "40722  2019 125,130.42   45,000.00     0.18   -0.19  \n",
       "57192  2019  78,474.17   28,403.00     0.36   -0.15  \n",
       "50587  2019 390,048.58  133,125.00     0.29    0.10  \n",
       "57184  2019  59,717.83   28,250.00     0.20   -0.16  \n",
       "...     ...        ...         ...      ...     ...  \n",
       "25983  2019  76,219.67   59,167.00     0.35    0.11  \n",
       "25985  2019 427,492.25  104,821.00     0.23    0.19  \n",
       "25987  2019 129,383.67   57,708.00     0.23    0.18  \n",
       "25989  2019 214,723.42   58,688.00     0.24    0.05  \n",
       "25993  2019 113,225.83   52,656.00     0.38    0.02  \n",
       "\n",
       "[20450 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_merged.loc[z_merged.zhvi_pc > z_merged.hhi_pc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where have they kept pace or lagged behind income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>Metro</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>year</th>\n",
       "      <th>zhvi</th>\n",
       "      <th>median_hhi</th>\n",
       "      <th>zhvi_pc</th>\n",
       "      <th>hhi_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45477</th>\n",
       "      <td>PA</td>\n",
       "      <td>Tunkhannock Township</td>\n",
       "      <td>East Stroudsburg</td>\n",
       "      <td>18610</td>\n",
       "      <td>2019</td>\n",
       "      <td>164,201.83</td>\n",
       "      <td>65,810.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56916</th>\n",
       "      <td>WV</td>\n",
       "      <td>Alum Creek</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>25169</td>\n",
       "      <td>2019</td>\n",
       "      <td>46,390.50</td>\n",
       "      <td>44,115.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40806</th>\n",
       "      <td>OK</td>\n",
       "      <td>Byars</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>74831</td>\n",
       "      <td>2019</td>\n",
       "      <td>81,355.42</td>\n",
       "      <td>39,063.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56909</th>\n",
       "      <td>WV</td>\n",
       "      <td>Alum Creek</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>25003</td>\n",
       "      <td>2019</td>\n",
       "      <td>102,873.75</td>\n",
       "      <td>37,224.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57226</th>\n",
       "      <td>WV</td>\n",
       "      <td>Evans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25241</td>\n",
       "      <td>2019</td>\n",
       "      <td>134,118.08</td>\n",
       "      <td>85,451.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26001</th>\n",
       "      <td>MN</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington</td>\n",
       "      <td>55339</td>\n",
       "      <td>2019</td>\n",
       "      <td>217,925.25</td>\n",
       "      <td>88,333.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26015</th>\n",
       "      <td>MN</td>\n",
       "      <td>Harmony</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>55939</td>\n",
       "      <td>2019</td>\n",
       "      <td>153,561.42</td>\n",
       "      <td>54,271.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26023</th>\n",
       "      <td>MN</td>\n",
       "      <td>Hawley</td>\n",
       "      <td>Fargo</td>\n",
       "      <td>56549</td>\n",
       "      <td>2019</td>\n",
       "      <td>228,107.25</td>\n",
       "      <td>79,191.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25997</th>\n",
       "      <td>MN</td>\n",
       "      <td>Hackensack</td>\n",
       "      <td>Brainerd</td>\n",
       "      <td>56452</td>\n",
       "      <td>2019</td>\n",
       "      <td>218,475.33</td>\n",
       "      <td>54,700.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58258</th>\n",
       "      <td>WY</td>\n",
       "      <td>Yoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82244</td>\n",
       "      <td>2019</td>\n",
       "      <td>228,844.33</td>\n",
       "      <td>75,357.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6315 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StateName                  City                             Metro  \\\n",
       "45477        PA  Tunkhannock Township                  East Stroudsburg   \n",
       "56916        WV            Alum Creek                        Charleston   \n",
       "40806        OK                 Byars                     Oklahoma City   \n",
       "56909        WV            Alum Creek                        Charleston   \n",
       "57226        WV                 Evans                               NaN   \n",
       "...         ...                   ...                               ...   \n",
       "26001        MN               Hamburg  Minneapolis-St. Paul-Bloomington   \n",
       "26015        MN               Harmony                         Rochester   \n",
       "26023        MN                Hawley                             Fargo   \n",
       "25997        MN            Hackensack                          Brainerd   \n",
       "58258        WY                 Yoder                               NaN   \n",
       "\n",
       "      RegionName  year       zhvi  median_hhi  zhvi_pc  hhi_pc  \n",
       "45477      18610  2019 164,201.83   65,810.00     0.14    0.27  \n",
       "56916      25169  2019  46,390.50   44,115.00     0.04    0.92  \n",
       "40806      74831  2019  81,355.42   39,063.00     0.16    0.20  \n",
       "56909      25003  2019 102,873.75   37,224.00    -0.03    0.07  \n",
       "57226      25241  2019 134,118.08   85,451.00     0.16    0.43  \n",
       "...          ...   ...        ...         ...      ...     ...  \n",
       "26001      55339  2019 217,925.25   88,333.00     0.26    0.34  \n",
       "26015      55939  2019 153,561.42   54,271.00     0.34    0.37  \n",
       "26023      56549  2019 228,107.25   79,191.00     0.21    0.25  \n",
       "25997      56452  2019 218,475.33   54,700.00     0.17    0.17  \n",
       "58258      82244  2019 228,844.33   75,357.00     0.29    0.43  \n",
       "\n",
       "[6315 rows x 9 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_merged.loc[z_merged.zhvi_pc <= z_merged.hhi_pc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for practice\n",
    "\n",
    "1. Which states have the greatest range in home values? Hint: select year, group by state, calculate max - min\n",
    "\n",
    "\n",
    "2. Can you find any cities where the *average* percent change in median income is higher than the *average* percent change in home values?\n",
    "\n",
    "\n",
    "3. Are the most expensive cities (to buy in) the wealthiest (by median income)?\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Answer\n",
    "\n",
    "   a. We need to pick a point in time: let's say 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "z19 = z_means.loc[z_means.year == 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. b. Then we can group by state and use `apply` with a lambda function to find the difference between the largest and smallest values in each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_19_range = z19.groupby('StateName').zhvi.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. c. Finally, we can sort the values in descending order to find the biggest differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateName\n",
       "CA   6,271,268.00\n",
       "NY   4,688,946.17\n",
       "MA   4,152,406.17\n",
       "WA   2,816,108.83\n",
       "FL   2,631,860.42\n",
       "CO   2,563,498.75\n",
       "NJ   2,402,941.08\n",
       "GA   2,389,238.42\n",
       "NV   2,326,124.42\n",
       "SC   1,949,929.25\n",
       "MD   1,795,643.00\n",
       "WY   1,533,227.92\n",
       "AZ   1,529,388.50\n",
       "NH   1,516,832.58\n",
       "CT   1,471,269.50\n",
       "IL   1,342,699.33\n",
       "HI   1,221,715.00\n",
       "ME   1,188,545.83\n",
       "TX   1,185,032.42\n",
       "KY   1,132,649.58\n",
       "VA   1,125,548.75\n",
       "UT   1,109,011.50\n",
       "DC   1,060,699.08\n",
       "DE   1,017,777.08\n",
       "PA     981,529.50\n",
       "NC     953,117.25\n",
       "RI     877,937.42\n",
       "MO     847,964.33\n",
       "OR     744,450.00\n",
       "MT     740,635.25\n",
       "MN     739,840.58\n",
       "IN     696,434.25\n",
       "TN     692,581.67\n",
       "ID     687,698.33\n",
       "NM     685,007.83\n",
       "MI     665,644.58\n",
       "AL     558,244.25\n",
       "KS     514,685.42\n",
       "WI     477,869.25\n",
       "OH     476,425.33\n",
       "VT     472,841.67\n",
       "LA     472,063.42\n",
       "AK     467,253.50\n",
       "NE     449,118.42\n",
       "OK     402,821.25\n",
       "AR     360,262.17\n",
       "IA     358,763.17\n",
       "ND     340,545.33\n",
       "WV     309,750.58\n",
       "SD     291,342.75\n",
       "MS     255,029.92\n",
       "Name: zhvi, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_19_range.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Answer\n",
    "\n",
    "   a. We can group our merged dataset by city and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pc = z_merged.groupby(['City', 'StateName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. b. To compute the mean of two columns at the same time, we can use the `agg` method available on a pandas `GroupBy` object. This method takes a dictionary mapping column names to the name of a built-in pandas method or a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pc = city_pc.agg({'zhvi_pc': 'mean',\n",
    "                             'hhi_pc': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. c. Now we can use `.loc` to find those rows where our mean ZHVI percentage change is smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>zhvi_pc</th>\n",
       "      <th>hhi_pc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th>StateName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbot</th>\n",
       "      <th>ME</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Aberdeen</th>\n",
       "      <th>MD</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abington Township</th>\n",
       "      <th>PA</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abita Springs</th>\n",
       "      <th>LA</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yukon</th>\n",
       "      <th>OK</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeigler</th>\n",
       "      <th>IL</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zenda</th>\n",
       "      <th>KS</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zionsville</th>\n",
       "      <th>IN</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zirconia</th>\n",
       "      <th>NC</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4965 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             zhvi_pc  hhi_pc\n",
       "City              StateName                 \n",
       "Abbot             ME            0.14    0.21\n",
       "Aberdeen          MD            0.07    0.11\n",
       "                  NC            0.17    0.35\n",
       "Abington Township PA            0.12    0.18\n",
       "Abita Springs     LA            0.07    0.24\n",
       "...                              ...     ...\n",
       "Yukon             OK            0.10    0.10\n",
       "Zeigler           IL           -0.17    0.28\n",
       "Zenda             KS           -0.28    0.17\n",
       "Zionsville        IN            0.17    0.27\n",
       "Zirconia          NC            0.38    0.46\n",
       "\n",
       "[4965 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_pc.loc[city_pc.zhvi_pc < city_pc.hhi_pc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Answer\n",
    "  \n",
    "  a. First we group by state and city (to account for cities that may have the same names in different states) and take the mean of the ZHVI. We sort so that the highest numbers are at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi_cities = z_merged.groupby(['StateName', 'City']).zhvi.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. b. We do the same for median income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi_cities = z_merged.groupby(['StateName', 'City']).median_hhi.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. c. For each of these, we take the top 100 rows (after resetting the index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_zhvi_cities = zhvi_cities.reset_index().head(100)\n",
    "top_hhi_cities = hhi_cities.reset_index().head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. d. Now we can use `merge` to find those cities in the top 100 for ZHVI that are also in the top 100 for median income. Since the `StateName` and `City` columns are common to both of the DataFrames we're mering we don't have to specify them as the keys for merging -- pandas will use them by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>City</th>\n",
       "      <th>zhvi</th>\n",
       "      <th>median_hhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>Atherton</td>\n",
       "      <td>6,300,275.67</td>\n",
       "      <td>250,001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>Portola Valley</td>\n",
       "      <td>3,737,899.75</td>\n",
       "      <td>220,625.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>Los Altos</td>\n",
       "      <td>3,422,485.42</td>\n",
       "      <td>226,748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>Ross</td>\n",
       "      <td>3,020,391.08</td>\n",
       "      <td>250,001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WA</td>\n",
       "      <td>Medina</td>\n",
       "      <td>2,874,184.92</td>\n",
       "      <td>192,120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>Saratoga</td>\n",
       "      <td>2,764,594.08</td>\n",
       "      <td>177,041.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FL</td>\n",
       "      <td>Fisher Island</td>\n",
       "      <td>2,671,508.25</td>\n",
       "      <td>223,618.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>2,269,209.00</td>\n",
       "      <td>166,740.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NY</td>\n",
       "      <td>Old Westbury</td>\n",
       "      <td>2,147,580.75</td>\n",
       "      <td>192,266.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CA</td>\n",
       "      <td>Orinda</td>\n",
       "      <td>2,115,631.92</td>\n",
       "      <td>208,640.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA</td>\n",
       "      <td>San Carlos</td>\n",
       "      <td>1,934,709.17</td>\n",
       "      <td>172,048.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NY</td>\n",
       "      <td>Mill Neck</td>\n",
       "      <td>1,885,813.25</td>\n",
       "      <td>237,813.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CA</td>\n",
       "      <td>Alamo</td>\n",
       "      <td>1,845,359.83</td>\n",
       "      <td>226,450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NY</td>\n",
       "      <td>Rye</td>\n",
       "      <td>1,710,087.42</td>\n",
       "      <td>183,871.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA</td>\n",
       "      <td>Danville</td>\n",
       "      <td>1,643,213.79</td>\n",
       "      <td>173,773.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NY</td>\n",
       "      <td>Manhasset</td>\n",
       "      <td>1,604,146.50</td>\n",
       "      <td>187,159.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MA</td>\n",
       "      <td>Weston</td>\n",
       "      <td>1,533,871.75</td>\n",
       "      <td>181,667.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NJ</td>\n",
       "      <td>Short Hills</td>\n",
       "      <td>1,517,835.83</td>\n",
       "      <td>250,001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NY</td>\n",
       "      <td>Purchase</td>\n",
       "      <td>1,371,262.75</td>\n",
       "      <td>202,583.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IL</td>\n",
       "      <td>Kenilworth</td>\n",
       "      <td>1,370,302.58</td>\n",
       "      <td>212,750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CT</td>\n",
       "      <td>Darien</td>\n",
       "      <td>1,344,391.92</td>\n",
       "      <td>210,511.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MA</td>\n",
       "      <td>Wellesley</td>\n",
       "      <td>1,337,503.83</td>\n",
       "      <td>184,222.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StateName            City         zhvi  median_hhi\n",
       "0         CA        Atherton 6,300,275.67  250,001.00\n",
       "1         CA  Portola Valley 3,737,899.75  220,625.00\n",
       "2         CA       Los Altos 3,422,485.42  226,748.00\n",
       "3         CA            Ross 3,020,391.08  250,001.00\n",
       "4         WA          Medina 2,874,184.92  192,120.00\n",
       "5         CA        Saratoga 2,764,594.08  177,041.00\n",
       "6         FL   Fisher Island 2,671,508.25  223,618.00\n",
       "7         CA       Los Gatos 2,269,209.00  166,740.00\n",
       "8         NY    Old Westbury 2,147,580.75  192,266.00\n",
       "9         CA          Orinda 2,115,631.92  208,640.00\n",
       "10        CA      San Carlos 1,934,709.17  172,048.00\n",
       "11        NY       Mill Neck 1,885,813.25  237,813.00\n",
       "12        CA           Alamo 1,845,359.83  226,450.00\n",
       "13        NY             Rye 1,710,087.42  183,871.00\n",
       "14        CA        Danville 1,643,213.79  173,773.50\n",
       "15        NY       Manhasset 1,604,146.50  187,159.00\n",
       "16        MA          Weston 1,533,871.75  181,667.00\n",
       "17        NJ     Short Hills 1,517,835.83  250,001.00\n",
       "18        NY        Purchase 1,371,262.75  202,583.00\n",
       "19        IL      Kenilworth 1,370,302.58  212,750.00\n",
       "20        CT          Darien 1,344,391.92  210,511.00\n",
       "21        MA       Wellesley 1,337,503.83  184,222.50"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_zhvi_cities.merge(top_hhi_cities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
